{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Základy - Hodiny 28-30: Klasifikace v praxi\n",
    "\n",
    "## Obsah:\n",
    "1. **Předzpracování dat pro klasifikaci**\n",
    "2. **Proces trénování modelu**\n",
    "3. **Testování a vyhodnocení modelů**\n",
    "4. **Klasifikace obrázků - CIFAR-10**\n",
    "5. **Pokročilé techniky a optimalizace**\n",
    "6. **Kompletní projekt klasifikace**\n",
    "7. **Interaktivní aplikace**\n",
    "8. **Domácí úkol**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Předzpracování dat pro klasifikaci\n",
    "\n",
    "### 1.1 Důležitost předzpracování\n",
    "\n",
    "Kvalita dat je klíčová pro úspěch klasifikačního modelu. \"Garbage in, garbage out\" - špatná data vedou k špatným výsledkům."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import všech potřebných knihoven\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pro práci s obrázky\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage import feature, transform\n",
    "\n",
    "# Nastavení vizualizace\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Pro interaktivní aplikace\n",
    "import gradio as gr\n",
    "\n",
    "# Pro CIFAR-10\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Vytvoření syntetického datasetu s různými problémy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření datasetu s běžnými problémy\n",
    "def create_problematic_dataset():\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Generování dat\n",
    "    data = {\n",
    "        # Numerické příznaky s různými rozsahy\n",
    "        'age': np.random.randint(18, 80, n_samples),\n",
    "        'income': np.random.exponential(50000, n_samples),  # Velmi zkosené rozdělení\n",
    "        'score': np.random.uniform(0, 100, n_samples),\n",
    "        \n",
    "        # Kategorické příznaky\n",
    "        'education': np.random.choice(['high_school', 'bachelor', 'master', 'phd'], n_samples),\n",
    "        'city': np.random.choice(['Praha', 'Brno', 'Ostrava', 'Plzen', 'Other'], n_samples),\n",
    "        \n",
    "        # Binární příznak\n",
    "        'has_car': np.random.choice([0, 1], n_samples),\n",
    "        \n",
    "        # Příznak s outliers\n",
    "        'spending': np.concatenate([\n",
    "            np.random.normal(5000, 1000, n_samples-20),\n",
    "            np.random.normal(50000, 5000, 20)  # 20 outliers\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    # Přidání chybějících hodnot\n",
    "    for col in ['income', 'score', 'education']:\n",
    "        missing_indices = np.random.choice(n_samples, size=int(0.1*n_samples), replace=False)\n",
    "        if col in ['income', 'score']:\n",
    "            data[col][missing_indices] = np.nan\n",
    "        else:\n",
    "            data[col] = list(data[col])\n",
    "            for idx in missing_indices:\n",
    "                data[col][idx] = np.nan\n",
    "    \n",
    "    # Cílová proměnná\n",
    "    # Pravděpodobnost závisí na několika příznacích\n",
    "    prob = (\n",
    "        (data['age'] > 40).astype(float) * 0.3 +\n",
    "        (np.array([1 if inc > 60000 else 0 for inc in data['income']]) * 0.4) +\n",
    "        (data['has_car'] * 0.3)\n",
    "    )\n",
    "    data['target'] = (prob + np.random.normal(0, 0.2, n_samples) > 0.5).astype(int)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Vytvoření datasetu\n",
    "df = create_problematic_dataset()\n",
    "print(\"Dataset vytvořen!\")\n",
    "print(f\"Rozměry: {df.shape}\")\n",
    "print(f\"\\nPrvních 5 řádků:\")\n",
    "print(df.head())\n",
    "print(f\"\\nInformace o datech:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Explorační analýza dat (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Komplexní EDA\n",
    "def exploratory_data_analysis(df):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # 1. Rozdělení cílové proměnné\n",
    "    df['target'].value_counts().plot(kind='bar', ax=axes[0], color=['skyblue', 'salmon'])\n",
    "    axes[0].set_title('Rozdělení cílové proměnné', fontsize=14)\n",
    "    axes[0].set_xlabel('Třída')\n",
    "    axes[0].set_ylabel('Počet')\n",
    "    \n",
    "    # 2. Chybějící hodnoty\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_data = missing_data[missing_data > 0]\n",
    "    if len(missing_data) > 0:\n",
    "        missing_data.plot(kind='bar', ax=axes[1], color='orange')\n",
    "        axes[1].set_title('Chybějící hodnoty', fontsize=14)\n",
    "        axes[1].set_ylabel('Počet chybějících')\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'Žádné chybějící hodnoty', \n",
    "                    ha='center', va='center', fontsize=14)\n",
    "        axes[1].axis('off')\n",
    "    \n",
    "    # 3. Distribuce věku\n",
    "    df['age'].hist(bins=30, ax=axes[2], color='green', alpha=0.7, edgecolor='black')\n",
    "    axes[2].set_title('Distribuce věku', fontsize=14)\n",
    "    axes[2].set_xlabel('Věk')\n",
    "    axes[2].set_ylabel('Četnost')\n",
    "    \n",
    "    # 4. Distribuce příjmu (log scale)\n",
    "    income_clean = df['income'].dropna()\n",
    "    axes[3].hist(income_clean, bins=50, color='purple', alpha=0.7, edgecolor='black')\n",
    "    axes[3].set_title('Distribuce příjmu', fontsize=14)\n",
    "    axes[3].set_xlabel('Příjem')\n",
    "    axes[3].set_ylabel('Četnost')\n",
    "    axes[3].set_yscale('log')\n",
    "    \n",
    "    # 5. Box plot pro detekci outliers\n",
    "    numerical_cols = ['age', 'income', 'score', 'spending']\n",
    "    df_clean = df[numerical_cols].dropna()\n",
    "    df_clean.boxplot(ax=axes[4])\n",
    "    axes[4].set_title('Boxplot numerických proměnných', fontsize=14)\n",
    "    axes[4].set_xticklabels(axes[4].get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # 6. Korelační matice\n",
    "    corr_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "               center=0, ax=axes[5], cbar_kws={'label': 'Korelace'})\n",
    "    axes[5].set_title('Korelační matice', fontsize=14)\n",
    "    \n",
    "    # 7. Distribuce kategorických proměnných - vzdělání\n",
    "    education_counts = df['education'].value_counts()\n",
    "    axes[6].pie(education_counts.values, labels=education_counts.index, \n",
    "               autopct='%1.1f%%', startangle=90)\n",
    "    axes[6].set_title('Rozdělení podle vzdělání', fontsize=14)\n",
    "    \n",
    "    # 8. Target vs Age\n",
    "    for target in [0, 1]:\n",
    "        subset = df[df['target'] == target]['age']\n",
    "        axes[7].hist(subset, bins=20, alpha=0.5, label=f'Target {target}')\n",
    "    axes[7].set_title('Věk podle cílové proměnné', fontsize=14)\n",
    "    axes[7].set_xlabel('Věk')\n",
    "    axes[7].legend()\n",
    "    \n",
    "    # 9. Target vs Income\n",
    "    df.boxplot(column='income', by='target', ax=axes[8])\n",
    "    axes[8].set_title('Příjem podle cílové proměnné', fontsize=14)\n",
    "    axes[8].set_xlabel('Target')\n",
    "    axes[8].set_ylabel('Příjem')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistické shrnutí\n",
    "    print(\"\\nSTATISTICKÉ SHRNUTÍ:\")\n",
    "    print(\"=\"*50)\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nROZDĚLENÍ CÍLOVÉ PROMĚNNÉ:\")\n",
    "    print(df['target'].value_counts(normalize=True))\n",
    "    \n",
    "    print(\"\\nCHYBĚJÍCÍ HODNOTY:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "exploratory_data_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Kompletní pipeline předzpracování"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Předzpracování dat krok po kroku\n",
    "def preprocess_data(df, show_steps=True):\n",
    "    \"\"\"\n",
    "    Kompletní předzpracování dat včetně vizualizace kroků\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    if show_steps:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.ravel()\n",
    "    \n",
    "    # Krok 1: Ošetření chybějících hodnot\n",
    "    print(\"KROK 1: Ošetření chybějících hodnot\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Numerické proměnné - imputace mediánem\n",
    "    numeric_columns = df_processed.select_dtypes(include=[np.number]).columns\n",
    "    numeric_columns = numeric_columns.drop('target')  # Vyloučíme cílovou proměnnou\n",
    "    \n",
    "    imputer_numeric = SimpleImputer(strategy='median')\n",
    "    df_processed[numeric_columns] = imputer_numeric.fit_transform(df_processed[numeric_columns])\n",
    "    \n",
    "    # Kategorické proměnné - imputace nejčastější hodnotou\n",
    "    categorical_columns = df_processed.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        mode_value = df_processed[col].mode()[0] if not df_processed[col].mode().empty else 'Unknown'\n",
    "        df_processed[col].fillna(mode_value, inplace=True)\n",
    "    \n",
    "    print(f\"Chybějící hodnoty po imputaci: {df_processed.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Krok 2: Ošetření outliers\n",
    "    print(\"\\nKROK 2: Detekce a ošetření outliers\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # IQR metoda pro detekci outliers\n",
    "    for col in numeric_columns:\n",
    "        Q1 = df_processed[col].quantile(0.25)\n",
    "        Q3 = df_processed[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df_processed[(df_processed[col] < lower_bound) | \n",
    "                               (df_processed[col] > upper_bound)][col]\n",
    "        \n",
    "        if len(outliers) > 0:\n",
    "            print(f\"{col}: {len(outliers)} outliers detekováno\")\n",
    "            # Omezení outliers na hranice\n",
    "            df_processed[col] = df_processed[col].clip(lower_bound, upper_bound)\n",
    "    \n",
    "    if show_steps:\n",
    "        # Vizualizace před a po ošetření outliers\n",
    "        df[numeric_columns].boxplot(ax=axes[0])\n",
    "        axes[0].set_title('Před ošetřením outliers', fontsize=12)\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        df_processed[numeric_columns].boxplot(ax=axes[1])\n",
    "        axes[1].set_title('Po ošetření outliers', fontsize=12)\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Krok 3: Encoding kategorických proměnných\n",
    "    print(\"\\nKROK 3: Encoding kategorických proměnných\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # One-hot encoding pro nominální proměnné\n",
    "    df_encoded = pd.get_dummies(df_processed, columns=['city'], prefix='city')\n",
    "    \n",
    "    # Ordinal encoding pro ordinální proměnné\n",
    "    education_mapping = {\n",
    "        'high_school': 1,\n",
    "        'bachelor': 2,\n",
    "        'master': 3,\n",
    "        'phd': 4\n",
    "    }\n",
    "    df_encoded['education_level'] = df_encoded['education'].map(education_mapping)\n",
    "    df_encoded.drop('education', axis=1, inplace=True)\n",
    "    \n",
    "    print(f\"Počet příznaků po encoding: {len(df_encoded.columns)}\")\n",
    "    \n",
    "    # Krok 4: Škálování numerických příznaků\n",
    "    print(\"\\nKROK 4: Škálování příznaků\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Oddělení příznaků a cíle\n",
    "    X = df_encoded.drop('target', axis=1)\n",
    "    y = df_encoded['target']\n",
    "    \n",
    "    # Seznam numerických sloupců pro škálování\n",
    "    numeric_features = ['age', 'income', 'score', 'spending', 'education_level']\n",
    "    \n",
    "    # StandardScaler pro normální rozdělení\n",
    "    scaler_standard = StandardScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numeric_features] = scaler_standard.fit_transform(X[numeric_features])\n",
    "    \n",
    "    if show_steps:\n",
    "        # Vizualizace distribucí před a po škálování\n",
    "        X[numeric_features[:3]].hist(ax=axes[2], bins=20)\n",
    "        axes[2].set_title('Před škálováním', fontsize=12)\n",
    "        \n",
    "        pd.DataFrame(X_scaled[numeric_features[:3]]).hist(ax=axes[3], bins=20)\n",
    "        axes[3].set_title('Po škálování (Standard)', fontsize=12)\n",
    "    \n",
    "    # Krok 5: Feature selection\n",
    "    print(\"\\nKROK 5: Výběr příznaků\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Použití SelectKBest\n",
    "    selector = SelectKBest(score_func=f_classif, k=10)\n",
    "    X_selected = selector.fit_transform(X_scaled, y)\n",
    "    \n",
    "    # Získání názvů vybraných příznaků\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    feature_scores = selector.scores_\n",
    "    \n",
    "    if show_steps:\n",
    "        # Vizualizace důležitosti příznaků\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'score': feature_scores\n",
    "        }).sort_values('score', ascending=False)\n",
    "        \n",
    "        feature_importance.head(10).plot(x='feature', y='score', kind='barh', ax=axes[4])\n",
    "        axes[4].set_title('Top 10 příznaků podle F-score', fontsize=12)\n",
    "        axes[4].set_xlabel('F-score')\n",
    "    \n",
    "    print(f\"Vybrané příznaky: {list(selected_features)}\")\n",
    "    \n",
    "    # Krok 6: Rozdělení na trénovací a testovací data\n",
    "    print(\"\\nKROK 6: Rozdělení dat\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Trénovací set: {X_train.shape}\")\n",
    "    print(f\"Testovací set: {X_test.shape}\")\n",
    "    print(f\"Rozdělení tříd v trénovacím setu:\\n{y_train.value_counts(normalize=True)}\")\n",
    "    \n",
    "    if show_steps:\n",
    "        # Vizualizace rozdělení\n",
    "        train_counts = y_train.value_counts()\n",
    "        test_counts = y_test.value_counts()\n",
    "        \n",
    "        x = np.arange(2)\n",
    "        width = 0.35\n",
    "        \n",
    "        axes[5].bar(x - width/2, train_counts.values, width, label='Train', color='blue', alpha=0.7)\n",
    "        axes[5].bar(x + width/2, test_counts.values, width, label='Test', color='orange', alpha=0.7)\n",
    "        axes[5].set_xlabel('Třída')\n",
    "        axes[5].set_ylabel('Počet vzorků')\n",
    "        axes[5].set_title('Rozdělení tříd v train/test', fontsize=12)\n",
    "        axes[5].set_xticks(x)\n",
    "        axes[5].set_xticklabels(['0', '1'])\n",
    "        axes[5].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler_standard, selector\n",
    "\n",
    "# Provedení předzpracování\n",
    "X_train, X_test, y_train, y_test, scaler, selector = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Proces trénování modelu\n",
    "\n",
    "### 2.1 Výběr a porovnání různých klasifikátorů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trénování a porovnání různých modelů\n",
    "def train_and_compare_models(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Trénování různých klasifikátorů a jejich porovnání\n",
    "    \"\"\"\n",
    "    # Definice modelů\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'SVM': SVC(probability=True, random_state=42),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Vizualizace\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"TRÉNOVÁNÍ A HODNOCENÍ MODELŮ\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for idx, (name, model) in enumerate(models.items()):\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(\"-\" * len(name))\n",
    "        \n",
    "        # Trénování\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predikce\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Metriky\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"Precision: {precision:.3f}\")\n",
    "        print(f\"Recall: {recall:.3f}\")\n",
    "        print(f\"F1-Score: {f1:.3f}\")\n",
    "        print(f\"CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})\")\n",
    "        \n",
    "        # Matice záměn\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Vizualizace matice záměn\n",
    "        ax = axes[idx]\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['0', '1'], yticklabels=['0', '1'], ax=ax)\n",
    "        ax.set_title(f'{name}\\nAccuracy: {accuracy:.3f}', fontsize=12)\n",
    "        ax.set_xlabel('Predikce')\n",
    "        ax.set_ylabel('Skutečnost')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Trénování modelů\n",
    "model_results = train_and_compare_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search pro optimalizaci hyperparametrů\n",
    "def hyperparameter_tuning(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Optimalizace hyperparametrů pomocí Grid Search\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"HYPERPARAMETER TUNING - RANDOM FOREST\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Definice parametrů pro Grid Search\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    # Vytvoření modelu\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"Probíhá Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Výsledky\n",
    "    print(f\"\\nNejlepší parametry: {grid_search.best_params_}\")\n",
    "    print(f\"Nejlepší F1 skóre: {grid_search.best_score_:.3f}\")\n",
    "    \n",
    "    # Vizualizace výsledků Grid Search\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Graf 1: Vliv počtu stromů\n",
    "    n_estimators_scores = results_df.groupby('param_n_estimators')['mean_test_score'].mean()\n",
    "    ax1.plot(n_estimators_scores.index, n_estimators_scores.values, 'bo-', linewidth=2, markersize=8)\n",
    "    ax1.set_xlabel('Počet stromů')\n",
    "    ax1.set_ylabel('Průměrné F1 skóre')\n",
    "    ax1.set_title('Vliv počtu stromů na výkon', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Graf 2: Heatmapa pro dva parametry\n",
    "    pivot_table = results_df.pivot_table(\n",
    "        values='mean_test_score',\n",
    "        index='param_max_depth',\n",
    "        columns='param_min_samples_split'\n",
    "    )\n",
    "    \n",
    "    sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax2)\n",
    "    ax2.set_title('F1 skóre pro různé kombinace parametrů', fontsize=14)\n",
    "    ax2.set_xlabel('min_samples_split')\n",
    "    ax2.set_ylabel('max_depth')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Optimalizace hyperparametrů\n",
    "best_model = hyperparameter_tuning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testování a vyhodnocení modelů\n",
    "\n",
    "### 3.1 Detailní evaluace nejlepšího modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompletní evaluace modelu\n",
    "def comprehensive_model_evaluation(model, X_test, y_test, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Detailní evaluace modelu včetně různých metrik a vizualizací\n",
    "    \"\"\"\n",
    "    # Predikce\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Vytvoření subplotů\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # 1. Matice záměn\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=['Negative', 'Positive'],\n",
    "               yticklabels=['Negative', 'Positive'],\n",
    "               ax=axes[0])\n",
    "    axes[0].set_title(f'Matice záměn - {model_name}', fontsize=14)\n",
    "    axes[0].set_xlabel('Predikce')\n",
    "    axes[0].set_ylabel('Skutečnost')\n",
    "    \n",
    "    # 2. ROC křivka\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    axes[1].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                label=f'ROC křivka (AUC = {roc_auc:.2f})')\n",
    "    axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Náhodný klasifikátor')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_xlabel('False Positive Rate')\n",
    "    axes[1].set_ylabel('True Positive Rate')\n",
    "    axes[1].set_title('ROC křivka', fontsize=14)\n",
    "    axes[1].legend(loc=\"lower right\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Precision-Recall křivka\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    \n",
    "    axes[2].plot(recall_curve, precision_curve, color='green', lw=2)\n",
    "    axes[2].set_xlabel('Recall')\n",
    "    axes[2].set_ylabel('Precision')\n",
    "    axes[2].set_title('Precision-Recall křivka', fontsize=14)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].fill_between(recall_curve, precision_curve, alpha=0.2, color='green')\n",
    "    \n",
    "    # 4. Distribuce pravděpodobností\n",
    "    axes[3].hist(y_pred_proba[y_test == 0], bins=30, alpha=0.5, \n",
    "                label='Negativní třída', color='blue', density=True)\n",
    "    axes[3].hist(y_pred_proba[y_test == 1], bins=30, alpha=0.5, \n",
    "                label='Pozitivní třída', color='red', density=True)\n",
    "    axes[3].axvline(x=0.5, color='black', linestyle='--', label='Práh')\n",
    "    axes[3].set_xlabel('Predikovaná pravděpodobnost')\n",
    "    axes[3].set_ylabel('Hustota')\n",
    "    axes[3].set_title('Distribuce predikovaných pravděpodobností', fontsize=14)\n",
    "    axes[3].legend()\n",
    "    \n",
    "    # 5. Feature importance (pokud model podporuje)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1][:10]\n",
    "        \n",
    "        axes[4].bar(range(10), importances[indices], color='purple', alpha=0.7)\n",
    "        axes[4].set_xlabel('Index příznaku')\n",
    "        axes[4].set_ylabel('Důležitost')\n",
    "        axes[4].set_title('Top 10 nejdůležitějších příznaků', fontsize=14)\n",
    "        axes[4].set_xticks(range(10))\n",
    "        axes[4].set_xticklabels([f'F{i}' for i in indices], rotation=45)\n",
    "    else:\n",
    "        axes[4].text(0.5, 0.5, 'Feature importance\\nnení k dispozici', \n",
    "                    ha='center', va='center', fontsize=14)\n",
    "        axes[4].axis('off')\n",
    "    \n",
    "    # 6. Metriky podle prahu\n",
    "    thresholds_to_test = np.linspace(0.1, 0.9, 9)\n",
    "    metrics_by_threshold = []\n",
    "    \n",
    "    for threshold in thresholds_to_test:\n",
    "        y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
    "        metrics_by_threshold.append({\n",
    "            'threshold': threshold,\n",
    "            'precision': precision_score(y_test, y_pred_threshold, zero_division=0),\n",
    "            'recall': recall_score(y_test, y_pred_threshold),\n",
    "            'f1': f1_score(y_test, y_pred_threshold)\n",
    "        })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_by_threshold)\n",
    "    \n",
    "    axes[5].plot(metrics_df['threshold'], metrics_df['precision'], 'b-', label='Precision', linewidth=2)\n",
    "    axes[5].plot(metrics_df['threshold'], metrics_df['recall'], 'r-', label='Recall', linewidth=2)\n",
    "    axes[5].plot(metrics_df['threshold'], metrics_df['f1'], 'g-', label='F1-Score', linewidth=2)\n",
    "    axes[5].set_xlabel('Práh')\n",
    "    axes[5].set_ylabel('Hodnota metriky')\n",
    "    axes[5].set_title('Metriky podle rozhodovacího prahu', fontsize=14)\n",
    "    axes[5].legend()\n",
    "    axes[5].grid(True, alpha=0.3)\n",
    "    axes[5].axvline(x=0.5, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Klasifikační report\n",
    "    print(\"\\nKLASIFIKAČNÍ REPORT:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n",
    "    \n",
    "    # Další metriky\n",
    "    print(\"\\nDALŠÍ METRIKY:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"AUC-ROC: {roc_auc:.3f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "    \n",
    "    # Analýza chyb\n",
    "    false_positives = ((y_pred == 1) & (y_test == 0)).sum()\n",
    "    false_negatives = ((y_pred == 0) & (y_test == 1)).sum()\n",
    "    \n",
    "    print(f\"\\nFalse Positives: {false_positives}\")\n",
    "    print(f\"False Negatives: {false_negatives}\")\n",
    "\n",
    "# Evaluace nejlepšího modelu\n",
    "comprehensive_model_evaluation(best_model, X_test, y_test, \"Optimized Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Klasifikace obrázků - CIFAR-10\n",
    "\n",
    "### 4.1 Načtení a příprava CIFAR-10 datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření zjednodušené verze CIFAR-10 pro sklearn\n",
    "def prepare_cifar10_subset():\n",
    "    \"\"\"\n",
    "    Příprava malého subsetu CIFAR-10 pro demonstraci\n",
    "    \"\"\"\n",
    "    print(\"Příprava CIFAR-10 subsetu...\")\n",
    "    \n",
    "    # Pro demonstraci vytvoříme syntetická data podobná CIFAR-10\n",
    "    # V reálné aplikaci byste použili skutečný dataset\n",
    "    \n",
    "    n_samples_per_class = 100\n",
    "    n_classes = 10\n",
    "    image_size = 32\n",
    "    n_channels = 3\n",
    "    \n",
    "    # Třídy CIFAR-10\n",
    "    classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    \n",
    "    # Generování syntetických dat (v praxi byste načetli skutečné obrázky)\n",
    "    X_images = []\n",
    "    y_labels = []\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    for class_idx in range(n_classes):\n",
    "        for _ in range(n_samples_per_class):\n",
    "            # Simulace obrázku s různými charakteristikami pro každou třídu\n",
    "            if class_idx in [0, 8]:  # airplane, ship - více modré (nebe/voda)\n",
    "                image = np.random.normal(loc=[0.3, 0.5, 0.8], scale=0.2, \n",
    "                                       size=(image_size, image_size, n_channels))\n",
    "            elif class_idx in [2, 6]:  # bird, frog - více zelené\n",
    "                image = np.random.normal(loc=[0.4, 0.7, 0.3], scale=0.2, \n",
    "                                       size=(image_size, image_size, n_channels))\n",
    "            elif class_idx in [3, 4, 5, 7]:  # animals - hnědé tóny\n",
    "                image = np.random.normal(loc=[0.6, 0.4, 0.3], scale=0.2, \n",
    "                                       size=(image_size, image_size, n_channels))\n",
    "            else:  # vehicles - šedé tóny\n",
    "                image = np.random.normal(loc=[0.5, 0.5, 0.5], scale=0.2, \n",
    "                                       size=(image_size, image_size, n_channels))\n",
    "            \n",
    "            # Přidání některých vzorů\n",
    "            if class_idx % 2 == 0:\n",
    "                # Horizontální pruhy\n",
    "                for i in range(0, image_size, 4):\n",
    "                    image[i:i+2, :, :] *= 1.2\n",
    "            else:\n",
    "                # Vertikální pruhy\n",
    "                for j in range(0, image_size, 4):\n",
    "                    image[:, j:j+2, :] *= 1.2\n",
    "            \n",
    "            # Omezení hodnot na rozsah [0, 1]\n",
    "            image = np.clip(image, 0, 1)\n",
    "            \n",
    "            X_images.append(image)\n",
    "            y_labels.append(class_idx)\n",
    "    \n",
    "    X_images = np.array(X_images)\n",
    "    y_labels = np.array(y_labels)\n",
    "    \n",
    "    # Vizualizace ukázkových obrázků\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(10):\n",
    "        # Náhodný obrázek z každé třídy\n",
    "        idx = np.where(y_labels == i)[0][0]\n",
    "        axes[i].imshow(X_images[idx])\n",
    "        axes[i].set_title(f'{classes[i]}', fontsize=12)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Ukázky obrázků z každé třídy', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return X_images, y_labels, classes\n",
    "\n",
    "# Příprava dat\n",
    "X_cifar, y_cifar, class_names = prepare_cifar10_subset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature extraction pro obrázky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrakce příznaků z obrázků\n",
    "def extract_image_features(images, method='histogram'):\n",
    "    \"\"\"\n",
    "    Extrakce příznaků z obrázků pro použití v sklearn\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for img in images:\n",
    "        if method == 'histogram':\n",
    "            # Barevný histogram\n",
    "            hist_features = []\n",
    "            for channel in range(3):\n",
    "                hist, _ = np.histogram(img[:, :, channel], bins=16, range=(0, 1))\n",
    "                hist_features.extend(hist)\n",
    "            features.append(hist_features)\n",
    "            \n",
    "        elif method == 'statistics':\n",
    "            # Statistické příznaky\n",
    "            stat_features = []\n",
    "            for channel in range(3):\n",
    "                channel_data = img[:, :, channel]\n",
    "                stat_features.extend([\n",
    "                    np.mean(channel_data),\n",
    "                    np.std(channel_data),\n",
    "                    np.min(channel_data),\n",
    "                    np.max(channel_data),\n",
    "                    np.median(channel_data)\n",
    "                ])\n",
    "            features.append(stat_features)\n",
    "            \n",
    "        elif method == 'combined':\n",
    "            # Kombinace různých příznaků\n",
    "            combined_features = []\n",
    "            \n",
    "            # Barevné histogramy\n",
    "            for channel in range(3):\n",
    "                hist, _ = np.histogram(img[:, :, channel], bins=8, range=(0, 1))\n",
    "                combined_features.extend(hist)\n",
    "            \n",
    "            # Statistiky\n",
    "            for channel in range(3):\n",
    "                channel_data = img[:, :, channel]\n",
    "                combined_features.extend([\n",
    "                    np.mean(channel_data),\n",
    "                    np.std(channel_data)\n",
    "                ])\n",
    "            \n",
    "            # Edge detection features\n",
    "            gray = np.mean(img, axis=2)\n",
    "            edges = np.abs(np.diff(gray, axis=0)).mean() + np.abs(np.diff(gray, axis=1)).mean()\n",
    "            combined_features.append(edges)\n",
    "            \n",
    "            features.append(combined_features)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Extrakce příznaků různými metodami\n",
    "print(\"Extrakce příznaků z obrázků...\")\n",
    "\n",
    "# Porovnání různých metod\n",
    "feature_methods = ['histogram', 'statistics', 'combined']\n",
    "feature_results = {}\n",
    "\n",
    "for method in feature_methods:\n",
    "    X_features = extract_image_features(X_cifar, method=method)\n",
    "    print(f\"\\nMetoda '{method}': {X_features.shape[1]} příznaků\")\n",
    "    \n",
    "    # Rozdělení dat\n",
    "    X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(\n",
    "        X_features, y_cifar, test_size=0.3, random_state=42, stratify=y_cifar\n",
    "    )\n",
    "    \n",
    "    # Standardizace\n",
    "    scaler = StandardScaler()\n",
    "    X_train_img_scaled = scaler.fit_transform(X_train_img)\n",
    "    X_test_img_scaled = scaler.transform(X_test_img)\n",
    "    \n",
    "    feature_results[method] = {\n",
    "        'X_train': X_train_img_scaled,\n",
    "        'X_test': X_test_img_scaled,\n",
    "        'y_train': y_train_img,\n",
    "        'y_test': y_test_img,\n",
    "        'scaler': scaler\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Klasifikace obrázků"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifikace obrázků pomocí různých modelů\n",
    "def image_classification_comparison():\n",
    "    \"\"\"\n",
    "    Porovnání různých klasifikátorů na obrázkových datech\n",
    "    \"\"\"\n",
    "    # Použijeme combined features\n",
    "    data = feature_results['combined']\n",
    "    X_train = data['X_train']\n",
    "    X_test = data['X_test']\n",
    "    y_train = data['y_train']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    # Definice modelů\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'SVM': SVC(probability=True, random_state=42),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Vytvoření subplotů\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, (name, model) in enumerate(models.items()):\n",
    "        print(f\"\\nTrénování {name}...\")\n",
    "        \n",
    "        # Trénování\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predikce\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Metriky\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        \n",
    "        # Matice záměn\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Vizualizace\n",
    "        ax = axes[idx]\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "               xticklabels=range(10),\n",
    "               yticklabels=range(10),\n",
    "               title=f'{name}\\nAccuracy: {accuracy:.3f}',\n",
    "               ylabel='Skutečná třída',\n",
    "               xlabel='Predikovaná třída')\n",
    "        \n",
    "        # Rotace popisků\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        \n",
    "        # Přidání textu do buněk\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                       ha=\"center\", va=\"center\",\n",
    "                       color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                       fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Celkové porovnání\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CELKOVÉ POROVNÁNÍ MODELŮ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model_names = list(results.keys())\n",
    "    accuracies = [results[name]['accuracy'] for name in model_names]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(model_names, accuracies, color=['blue', 'green', 'red', 'orange'])\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Porovnání přesnosti modelů na klasifikaci obrázků', fontsize=14)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Přidání hodnot na grafy\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{acc:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Spuštění klasifikace\n",
    "image_classification_results = image_classification_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Vizualizace špatně klasifikovaných obrázků"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analýza chyb klasifikace\n",
    "def analyze_misclassified_images():\n",
    "    \"\"\"\n",
    "    Vizualizace a analýza špatně klasifikovaných obrázků\n",
    "    \"\"\"\n",
    "    # Použijeme nejlepší model\n",
    "    best_model_name = max(image_classification_results, \n",
    "                         key=lambda x: image_classification_results[x]['accuracy'])\n",
    "    best_result = image_classification_results[best_model_name]\n",
    "    \n",
    "    y_pred = best_result['predictions']\n",
    "    y_test = feature_results['combined']['y_test']\n",
    "    \n",
    "    # Najdeme špatně klasifikované\n",
    "    misclassified_idx = np.where(y_pred != y_test)[0]\n",
    "    \n",
    "    print(f\"Počet špatně klasifikovaných obrázků: {len(misclassified_idx)} z {len(y_test)}\")\n",
    "    \n",
    "    # Vizualizace prvních 12 chyb\n",
    "    n_show = min(12, len(misclassified_idx))\n",
    "    \n",
    "    if n_show > 0:\n",
    "        fig, axes = plt.subplots(3, 4, figsize=(15, 12))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        # Získání indexů v původním datasetu\n",
    "        test_indices = np.arange(len(X_cifar))[len(X_cifar)*0.7:]\n",
    "        \n",
    "        for i in range(n_show):\n",
    "            idx = misclassified_idx[i]\n",
    "            original_idx = test_indices[idx]\n",
    "            \n",
    "            axes[i].imshow(X_cifar[original_idx])\n",
    "            axes[i].set_title(f'Skutečnost: {class_names[y_test[idx]]}\\n' +\n",
    "                             f'Predikce: {class_names[y_pred[idx]]}',\n",
    "                             fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        # Skrytí prázdných subplot\n",
    "        for i in range(n_show, 12):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Špatně klasifikované obrázky - {best_model_name}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Matice záměn pro analýzu častých chyb\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Nejčastější záměny\n",
    "    print(\"\\nNejčastější záměny:\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Vytvoření kopie matice záměn bez diagonály\n",
    "    cm_no_diag = cm.copy()\n",
    "    np.fill_diagonal(cm_no_diag, 0)\n",
    "    \n",
    "    # Najdeme 5 největších hodnot\n",
    "    for _ in range(5):\n",
    "        max_idx = np.unravel_index(cm_no_diag.argmax(), cm_no_diag.shape)\n",
    "        if cm_no_diag[max_idx] > 0:\n",
    "            print(f\"{class_names[max_idx[0]]} → {class_names[max_idx[1]]}: \"\n",
    "                  f\"{cm_no_diag[max_idx]} případů\")\n",
    "            cm_no_diag[max_idx] = 0\n",
    "\n",
    "analyze_misclassified_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interaktivní aplikace pro klasifikaci\n",
    "\n",
    "### 5.1 Gradio aplikace pro klasifikaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvoření interaktivní aplikace\n",
    "def create_classification_app():\n",
    "    \"\"\"\n",
    "    Interaktivní aplikace pro klasifikaci dat\n",
    "    \"\"\"\n",
    "    # Příprava modelů\n",
    "    # Použijeme náš nejlepší model z předchozích kroků\n",
    "    \n",
    "    def classify_tabular_data(age, income, score, education, has_car, spending):\n",
    "        \"\"\"\n",
    "        Klasifikace tabulkových dat\n",
    "        \"\"\"\n",
    "        # Vytvoření DataFrame s jedním řádkem\n",
    "        input_data = pd.DataFrame({\n",
    "            'age': [age],\n",
    "            'income': [income],\n",
    "            'score': [score],\n",
    "            'education': [education],\n",
    "            'city': ['Praha'],  # Default hodnota\n",
    "            'has_car': [int(has_car)],\n",
    "            'spending': [spending],\n",
    "            'target': [0]  # Dummy hodnota\n",
    "        })\n",
    "        \n",
    "        # Aplikace stejného předzpracování\n",
    "        # One-hot encoding\n",
    "        input_encoded = pd.get_dummies(input_data, columns=['city'], prefix='city')\n",
    "        \n",
    "        # Ordinal encoding pro education\n",
    "        education_mapping = {\n",
    "            'high_school': 1,\n",
    "            'bachelor': 2,\n",
    "            'master': 3,\n",
    "            'phd': 4\n",
    "        }\n",
    "        input_encoded['education_level'] = input_encoded['education'].map(education_mapping)\n",
    "        input_encoded.drop(['education', 'target'], axis=1, inplace=True)\n",
    "        \n",
    "        # Zajištění správného pořadí sloupců\n",
    "        expected_columns = ['age', 'income', 'score', 'has_car', 'spending', \n",
    "                           'education_level', 'city_Brno', 'city_Ostrava', \n",
    "                           'city_Other', 'city_Plzen', 'city_Praha']\n",
    "        \n",
    "        # Přidání chybějících sloupců\n",
    "        for col in expected_columns:\n",
    "            if col not in input_encoded.columns:\n",
    "                input_encoded[col] = 0\n",
    "        \n",
    "        input_encoded = input_encoded[expected_columns]\n",
    "        \n",
    "        # Škálování\n",
    "        numeric_features = ['age', 'income', 'score', 'spending', 'education_level']\n",
    "        input_encoded[numeric_features] = scaler.transform(input_encoded[numeric_features])\n",
    "        \n",
    "        # Feature selection\n",
    "        input_selected = selector.transform(input_encoded)\n",
    "        \n",
    "        # Predikce\n",
    "        prediction = best_model.predict(input_selected)[0]\n",
    "        probabilities = best_model.predict_proba(input_selected)[0]\n",
    "        \n",
    "        # Vytvoření grafu\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Graf pravděpodobností\n",
    "        classes = ['Třída 0', 'Třída 1']\n",
    "        colors = ['blue', 'red']\n",
    "        bars = ax1.bar(classes, probabilities, color=colors, alpha=0.7)\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.set_ylabel('Pravděpodobnost')\n",
    "        ax1.set_title('Pravděpodobnosti tříd', fontsize=14)\n",
    "        \n",
    "        # Přidání hodnot\n",
    "        for bar, prob in zip(bars, probabilities):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{prob:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Důvěra v predikci\n",
    "        confidence = max(probabilities)\n",
    "        ax2.pie([confidence, 1-confidence], labels=['Důvěra', 'Nejistota'],\n",
    "               colors=['green', 'lightgray'], autopct='%1.1f%%', startangle=90)\n",
    "        ax2.set_title('Důvěra v predikci', fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Textový výstup\n",
    "        result_text = f\"\"\"## Výsledky klasifikace\n",
    "\n",
    "**Predikovaná třída:** {prediction}\n",
    "**Důvěra:** {confidence:.1%}\n",
    "\n",
    "### Pravděpodobnosti:\n",
    "- Třída 0: {probabilities[0]:.3f}\n",
    "- Třída 1: {probabilities[1]:.3f}\n",
    "\n",
    "### Interpretace:\n",
    "\"\"\"\n",
    "        \n",
    "        if confidence > 0.8:\n",
    "            result_text += \"Model je velmi jistý ve své predikci.\"\n",
    "        elif confidence > 0.6:\n",
    "            result_text += \"Model je relativně jistý, ale existuje určitá nejistota.\"\n",
    "        else:\n",
    "            result_text += \"Model si není příliš jistý - predikce je na hraně.\"\n",
    "        \n",
    "        return fig, result_text\n",
    "    \n",
    "    # Vytvoření Gradio interface\n",
    "    with gr.Blocks(title=\"Klasifikátor\") as demo:\n",
    "        gr.Markdown(\"# 🤖 Interaktivní klasifikátor\")\n",
    "        gr.Markdown(\"\"\"Zadejte hodnoty pro klasifikaci. Model předpoví třídu a zobrazí svou důvěru v predikci.\"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                age_input = gr.Slider(minimum=18, maximum=80, value=35, \n",
    "                                     label=\"Věk\", step=1)\n",
    "                income_input = gr.Number(value=50000, label=\"Příjem\")\n",
    "                score_input = gr.Slider(minimum=0, maximum=100, value=75, \n",
    "                                       label=\"Skóre\")\n",
    "                education_input = gr.Dropdown(\n",
    "                    choices=['high_school', 'bachelor', 'master', 'phd'],\n",
    "                    value='bachelor',\n",
    "                    label=\"Vzdělání\"\n",
    "                )\n",
    "                has_car_input = gr.Checkbox(value=True, label=\"Vlastní auto\")\n",
    "                spending_input = gr.Number(value=5000, label=\"Výdaje\")\n",
    "                \n",
    "                classify_btn = gr.Button(\"🔍 Klasifikovat\", variant=\"primary\")\n",
    "            \n",
    "            with gr.Column():\n",
    "                output_text = gr.Markdown(\"### Výsledky se zobrazí zde...\")\n",
    "        \n",
    "        output_plot = gr.Plot(label=\"Vizualizace\")\n",
    "        \n",
    "        classify_btn.click(\n",
    "            classify_tabular_data,\n",
    "            inputs=[age_input, income_input, score_input, education_input, \n",
    "                   has_car_input, spending_input],\n",
    "            outputs=[output_plot, output_text]\n",
    "        )\n",
    "        \n",
    "        gr.Markdown(\"\"\"### 📊 O aplikaci\n",
    "        \n",
    "Tato aplikace demonstruje proces klasifikace v praxi:\n",
    "1. **Předzpracování dat** - škálování a encoding\n",
    "2. **Feature selection** - výběr důležitých příznaků\n",
    "3. **Predikce** - použití natrénovaného modelu\n",
    "4. **Interpretace** - zobrazení pravděpodobností a důvěry\n",
    "        \"\"\")\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Spuštění aplikace\n",
    "app = create_classification_app()\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Shrnutí a klíčové koncepty\n",
    "\n",
    "### Co jsme se naučili:\n",
    "\n",
    "1. **Předzpracování dat**\n",
    "   - Ošetření chybějících hodnot\n",
    "   - Detekce a ošetření outliers\n",
    "   - Encoding kategorických proměnných\n",
    "   - Škálování příznaků\n",
    "   - Feature selection\n",
    "\n",
    "2. **Trénování modelu**\n",
    "   - Výběr vhodného klasifikátoru\n",
    "   - Cross-validation\n",
    "   - Hyperparameter tuning\n",
    "   - Ensemble metody\n",
    "\n",
    "3. **Evaluace modelu**\n",
    "   - Matice záměn\n",
    "   - ROC křivka a AUC\n",
    "   - Precision, Recall, F1-Score\n",
    "   - Analýza chyb\n",
    "\n",
    "4. **Klasifikace obrázků**\n",
    "   - Feature extraction\n",
    "   - Práce s vysokodimenzionálními daty\n",
    "   - Transfer learning (koncept)\n",
    "\n",
    "### Best practices:\n",
    "\n",
    "- **Vždy začněte s EDA** - pochopte svá data\n",
    "- **Nezapomeňte na preprocessing** - kvalita dat je klíčová\n",
    "- **Použijte cross-validation** - pro robustní odhady\n",
    "- **Porovnejte více modelů** - žádný není univerzálně nejlepší\n",
    "- **Interpretujte výsledky** - nestačí jen vysoká přesnost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Domácí úkol\n",
    "\n",
    "### Úkol 1: Pokročilé předzpracování\n",
    "Implementujte:\n",
    "- PCA pro redukci dimenzionality\n",
    "- SMOTE pro vyvážení tříd\n",
    "- Feature engineering - vytvoření nových příznaků\n",
    "- Porovnejte výsledky s původním přístupem\n",
    "\n",
    "### Úkol 2: Ensemble metody\n",
    "Vytvořte:\n",
    "- Voting classifier kombinující různé modely\n",
    "- Stacking s meta-learnerem\n",
    "- Porovnejte s jednotlivými modely\n",
    "\n",
    "### Úkol 3: Real-world dataset\n",
    "Stáhněte skutečný dataset (např. z Kaggle):\n",
    "- Proveďte kompletní analýzu\n",
    "- Vytvořte pipeline pro preprocessing\n",
    "- Natrénujte a vyhodnoťte model\n",
    "- Vytvořte prezentaci výsledků\n",
    "\n",
    "### Bonusový úkol: AutoML\n",
    "Vyzkoušejte AutoML nástroj:\n",
    "- Použijte např. AutoSklearn nebo TPOT\n",
    "- Porovnejte s manuálním přístupem\n",
    "- Analyzujte, co AutoML vybral\n",
    "\n",
    "---\n",
    "\n",
    "💡 **Tip**: Dokumentujte svůj proces! Dobrá dokumentace je stejně důležitá jako dobrý kód."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}