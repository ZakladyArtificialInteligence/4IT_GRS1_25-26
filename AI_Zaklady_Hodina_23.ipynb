{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Z√°klady - Hodina 23: Neurƒçitost a predikce\n",
    "\n",
    "## Obsah:\n",
    "1. **Co je to nejistota v AI?**\n",
    "2. **Pravdƒõpodobnostn√≠ modely**\n",
    "3. **Bayesovo uva≈æov√°n√≠**\n",
    "4. **Predikƒçn√≠ modely a pr√°ce s nejistotou**\n",
    "5. **Praktick√© aplikace**\n",
    "6. **Dom√°c√≠ √∫kol**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Co je to nejistota?\n",
    "\n",
    "### 1.1 Zdroje nejistoty v AI\n",
    "\n",
    "Nejistota v AI poch√°z√≠ z nƒõkolika zdroj≈Ø:\n",
    "\n",
    "1. **Epistemick√° nejistota** - nedostatek znalost√≠ o syst√©mu\n",
    "2. **Aleatorick√° nejistota** - inherentn√≠ n√°hodnost v datech\n",
    "3. **Chybƒõj√≠c√≠ data** - ne√∫pln√© informace\n",
    "4. **≈†um v datech** - mƒõ≈ôic√≠ chyby, nep≈ôesnosti\n",
    "5. **Modelov√° nejistota** - nejistota v parametrech modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pot≈ôebn√Ωch knihoven\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Nastaven√≠ vizualizace\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Pro interaktivn√≠ aplikace\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Vizualizace r≈Øzn√Ωch typ≈Ø nejistoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrace r≈Øzn√Ωch typ≈Ø nejistoty\n",
    "np.random.seed(42)\n",
    "\n",
    "# Vytvo≈ôen√≠ dat s r≈Øzn√Ωmi typy nejistoty\n",
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "# 1. Data bez nejistoty (ide√°ln√≠ p≈ô√≠pad)\n",
    "y_ideal = 2 * x + 3\n",
    "\n",
    "# 2. Aleatorick√° nejistota (n√°hodn√Ω ≈°um)\n",
    "noise = np.random.normal(0, 2, size=x.shape)\n",
    "y_aleatory = y_ideal + noise\n",
    "\n",
    "# 3. Epistemick√° nejistota (systematick√° chyba)\n",
    "y_epistemic = 2.5 * x + 2  # ≈†patn√© parametry modelu\n",
    "\n",
    "# 4. Kombinovan√° nejistota\n",
    "y_combined = y_epistemic + noise\n",
    "\n",
    "# Vizualizace\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Graf 1: Ide√°ln√≠ data\n",
    "axes[0].plot(x, y_ideal, 'b-', linewidth=2, label='Skuteƒçn√° funkce')\n",
    "axes[0].set_title('Ide√°ln√≠ data (bez nejistoty)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Y')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Graf 2: Aleatorick√° nejistota\n",
    "axes[1].scatter(x, y_aleatory, alpha=0.6, s=30, label='Data s ≈°umem')\n",
    "axes[1].plot(x, y_ideal, 'r--', linewidth=2, label='Skuteƒçn√° funkce')\n",
    "axes[1].set_title('Aleatorick√° nejistota (n√°hodn√Ω ≈°um)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('Y')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Graf 3: Epistemick√° nejistota\n",
    "axes[2].plot(x, y_ideal, 'b-', linewidth=2, label='Skuteƒçn√° funkce')\n",
    "axes[2].plot(x, y_epistemic, 'g-', linewidth=2, label='≈†patn√Ω model')\n",
    "axes[2].fill_between(x, y_ideal, y_epistemic, alpha=0.3, color='red', label='Modelov√° chyba')\n",
    "axes[2].set_title('Epistemick√° nejistota (chyba modelu)', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('X')\n",
    "axes[2].set_ylabel('Y')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Graf 4: Kombinovan√° nejistota\n",
    "axes[3].scatter(x, y_combined, alpha=0.6, s=30, color='purple', label='Data s kombinovanou nejistotou')\n",
    "axes[3].plot(x, y_ideal, 'b--', linewidth=2, label='Skuteƒçn√° funkce')\n",
    "axes[3].plot(x, y_epistemic, 'g--', linewidth=2, label='≈†patn√Ω model')\n",
    "axes[3].set_title('Kombinovan√° nejistota', fontsize=14, fontweight='bold')\n",
    "axes[3].set_xlabel('X')\n",
    "axes[3].set_ylabel('Y')\n",
    "axes[3].legend()\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TYPY NEJISTOTY V AI:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. ALEATORICK√Å NEJISTOTA:\")\n",
    "print(\"   - P≈ôirozen√° n√°hodnost v datech\")\n",
    "print(\"   - Nelze ji odstranit v√≠ce daty\")\n",
    "print(\"   - P≈ô√≠klad: h√°zen√≠ kostkou, kvantov√© jevy\")\n",
    "print(\"\\n2. EPISTEMICK√Å NEJISTOTA:\")\n",
    "print(\"   - Nedostatek znalost√≠ o syst√©mu\")\n",
    "print(\"   - Lze sn√≠≈æit z√≠sk√°n√≠m v√≠ce dat nebo lep≈°√≠m modelem\")\n",
    "print(\"   - P≈ô√≠klad: nezn√°m√© parametry modelu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Pr√°ce s chybƒõj√≠c√≠mi daty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvo≈ôen√≠ datasetu s chybƒõj√≠c√≠mi hodnotami\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generov√°n√≠ syntetick√Ωch dat\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "\n",
    "# Vytvo≈ôen√≠ kompletn√≠ch dat\n",
    "X_complete = np.random.randn(n_samples, n_features)\n",
    "# Line√°rn√≠ z√°vislost s ≈°umem\n",
    "y_complete = 2*X_complete[:, 0] - 1.5*X_complete[:, 1] + 0.5*X_complete[:, 2] + np.random.randn(n_samples)*0.5\n",
    "\n",
    "# P≈ôid√°n√≠ chybƒõj√≠c√≠ch hodnot (20% n√°hodnƒõ)\n",
    "missing_mask = np.random.random((n_samples, n_features)) < 0.2\n",
    "X_missing = X_complete.copy()\n",
    "X_missing[missing_mask] = np.nan\n",
    "\n",
    "# Vytvo≈ôen√≠ DataFrame pro lep≈°√≠ pr√°ci\n",
    "feature_names = [f'Feature_{i+1}' for i in range(n_features)]\n",
    "df_complete = pd.DataFrame(X_complete, columns=feature_names)\n",
    "df_missing = pd.DataFrame(X_missing, columns=feature_names)\n",
    "df_missing['Target'] = y_complete\n",
    "\n",
    "# Vizualizace chybƒõj√≠c√≠ch dat\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Heatmapa chybƒõj√≠c√≠ch hodnot\n",
    "missing_data = df_missing.isnull()\n",
    "sns.heatmap(missing_data.head(50), cbar=True, yticklabels=False, \n",
    "            cmap='viridis', ax=ax1)\n",
    "ax1.set_title('Vzor chybƒõj√≠c√≠ch dat (prvn√≠ch 50 vzork≈Ø)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Promƒõnn√©')\n",
    "\n",
    "# Sloupcov√Ω graf procenta chybƒõj√≠c√≠ch hodnot\n",
    "missing_percent = (missing_data.sum() / len(df_missing)) * 100\n",
    "missing_percent.plot(kind='bar', ax=ax2, color='coral')\n",
    "ax2.set_title('Procento chybƒõj√≠c√≠ch hodnot pro ka≈ædou promƒõnnou', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Promƒõnn√©')\n",
    "ax2.set_ylabel('Procento chybƒõj√≠c√≠ch hodnot')\n",
    "ax2.set_ylim(0, 30)\n",
    "\n",
    "# P≈ôid√°n√≠ hodnot na graf\n",
    "for i, v in enumerate(missing_percent):\n",
    "    ax2.text(i, v + 0.5, f'{v:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCelkov√Ω poƒçet chybƒõj√≠c√≠ch hodnot: {missing_data.sum().sum()}\")\n",
    "print(f\"Procento chybƒõj√≠c√≠ch dat: {(missing_data.sum().sum() / (n_samples * n_features)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pravdƒõpodobnostn√≠ modely\n",
    "\n",
    "### 2.1 Proƒç pravdƒõpodobnostn√≠ p≈ô√≠stup?\n",
    "\n",
    "Pravdƒõpodobnostn√≠ modely n√°m umo≈æ≈àuj√≠:\n",
    "- Kvantifikovat nejistotu v p≈ôedpovƒõd√≠ch\n",
    "- Rozhodovat se na z√°kladƒõ rizika\n",
    "- Kombinovat r≈Øzn√© zdroje informac√≠\n",
    "- Aktualizovat p≈ôesvƒõdƒçen√≠ s nov√Ωmi daty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porovn√°n√≠ deterministick√©ho a pravdƒõpodobnostn√≠ho modelu\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "\n",
    "# Vytvo≈ôen√≠ neline√°rn√≠ch dat s r≈Øznou nejistotou\n",
    "np.random.seed(42)\n",
    "X_train = np.sort(np.random.uniform(0, 10, 30))\n",
    "y_train = np.sin(X_train) + 0.1 * X_train + np.random.normal(0, 0.2, X_train.shape)\n",
    "\n",
    "# Oblasti s r≈Øznou hustotou dat (r≈Øzn√° nejistota)\n",
    "mask_sparse = (X_train > 6) & (X_train < 8)\n",
    "X_train = X_train[~mask_sparse]\n",
    "y_train = y_train[~mask_sparse]\n",
    "\n",
    "X_test = np.linspace(0, 10, 200).reshape(-1, 1)\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "\n",
    "# 1. Deterministick√Ω model (Linear Regression)\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# 2. Pravdƒõpodobnostn√≠ model (Gaussian Process)\n",
    "kernel = ConstantKernel(1.0) * RBF(length_scale=1.0) + WhiteKernel(noise_level=0.1)\n",
    "gp_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1)\n",
    "gp_model.fit(X_train, y_train)\n",
    "y_pred_gp, y_std_gp = gp_model.predict(X_test, return_std=True)\n",
    "\n",
    "# Vizualizace\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Graf 1: Deterministick√Ω model\n",
    "ax1.scatter(X_train, y_train, c='red', s=50, zorder=10, \n",
    "           edgecolors='black', label='Tr√©novac√≠ data')\n",
    "ax1.plot(X_test, y_pred_lr, 'b-', linewidth=2, label='Line√°rn√≠ regrese')\n",
    "ax1.set_title('Deterministick√Ω model (Line√°rn√≠ regrese)', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axvspan(6, 8, alpha=0.2, color='gray', label='Oblast bez dat')\n",
    "\n",
    "# Graf 2: Pravdƒõpodobnostn√≠ model\n",
    "ax2.scatter(X_train, y_train, c='red', s=50, zorder=10, \n",
    "           edgecolors='black', label='Tr√©novac√≠ data')\n",
    "ax2.plot(X_test, y_pred_gp, 'b-', linewidth=2, label='Gaussovsk√Ω proces (st≈ôedn√≠ hodnota)')\n",
    "ax2.fill_between(X_test.ravel(), \n",
    "                y_pred_gp - 2*y_std_gp, \n",
    "                y_pred_gp + 2*y_std_gp, \n",
    "                alpha=0.3, color='blue', label='95% interval spolehlivosti')\n",
    "ax2.set_title('Pravdƒõpodobnostn√≠ model (Gaussovsk√Ω proces)', fontsize=16, fontweight='bold')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axvspan(6, 8, alpha=0.2, color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"KL√çƒåOV√â ROZD√çLY:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. DETERMINISTICK√ù MODEL:\")\n",
    "print(\"   - Poskytuje pouze bodovou p≈ôedpovƒõƒè\")\n",
    "print(\"   - Ne≈ô√≠k√° nic o spolehlivosti p≈ôedpovƒõdi\")\n",
    "print(\"   - Stejn√° jistota v≈°ude (i v oblastech bez dat)\")\n",
    "print(\"\\n2. PRAVDƒöPODOBNOSTN√ç MODEL:\")\n",
    "print(\"   - Poskytuje p≈ôedpovƒõƒè s intervalem spolehlivosti\")\n",
    "print(\"   - Nejistota se zvy≈°uje v oblastech bez dat\")\n",
    "print(\"   - Umo≈æ≈àuje kvantifikovat riziko rozhodnut√≠\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pravdƒõpodobnostn√≠ klasifikace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vytvo≈ôen√≠ klasifikaƒçn√≠ho probl√©mu s p≈ôekr√Ωvaj√≠c√≠mi se t≈ô√≠dami\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Generov√°n√≠ dat\n",
    "X_class, y_class = make_classification(n_samples=500, n_features=2, n_redundant=0,\n",
    "                                       n_informative=2, n_clusters_per_class=1,\n",
    "                                       flip_y=0.1, class_sep=0.5, random_state=42)\n",
    "\n",
    "# Rozdƒõlen√≠ na tr√©novac√≠ a testovac√≠\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_class, y_class, \n",
    "                                                            test_size=0.3, random_state=42)\n",
    "\n",
    "# Tr√©nov√°n√≠ modelu\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_c, y_train_c)\n",
    "\n",
    "# P≈ôedpovƒõdi s pravdƒõpodobnostmi\n",
    "y_pred_proba = log_reg.predict_proba(X_test_c)\n",
    "y_pred_class = log_reg.predict(X_test_c)\n",
    "\n",
    "# Vytvo≈ôen√≠ m≈ô√≠≈æky pro vizualizaci rozhodovac√≠ hranice\n",
    "h = 0.02\n",
    "x_min, x_max = X_class[:, 0].min() - 1, X_class[:, 0].max() + 1\n",
    "y_min, y_max = X_class[:, 1].min() - 1, X_class[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z_proba = log_reg.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "Z_proba = Z_proba.reshape(xx.shape)\n",
    "\n",
    "# Vizualizace\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Graf 1: Tr√©novac√≠ data a rozhodovac√≠ hranice\n",
    "contour = axes[0].contourf(xx, yy, Z_proba, levels=20, cmap='RdBu_r', alpha=0.8)\n",
    "axes[0].scatter(X_train_c[:, 0], X_train_c[:, 1], c=y_train_c, \n",
    "               cmap='RdBu', edgecolors='black', s=50)\n",
    "axes[0].set_title('Pravdƒõpodobnostn√≠ mapa klasifikace', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "cbar = plt.colorbar(contour, ax=axes[0])\n",
    "cbar.set_label('P(Class 1)', rotation=270, labelpad=20)\n",
    "\n",
    "# Graf 2: Nejistota v p≈ôedpovƒõd√≠ch\n",
    "uncertainty = np.minimum(Z_proba, 1-Z_proba) * 2  # Nejvy≈°≈°√≠ nejistota kdy≈æ P=0.5\n",
    "im = axes[1].contourf(xx, yy, uncertainty, levels=20, cmap='viridis')\n",
    "axes[1].scatter(X_test_c[:, 0], X_test_c[:, 1], c=y_test_c, \n",
    "               cmap='RdBu', edgecolors='black', s=50)\n",
    "axes[1].set_title('Mapa nejistoty p≈ôedpovƒõd√≠', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "cbar2 = plt.colorbar(im, ax=axes[1])\n",
    "cbar2.set_label('Nejistota', rotation=270, labelpad=20)\n",
    "\n",
    "# Graf 3: Histogram pravdƒõpodobnost√≠\n",
    "axes[2].hist(y_pred_proba[:, 1], bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[2].axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Rozhodovac√≠ pr√°h')\n",
    "axes[2].set_title('Distribuce p≈ôedpovƒõzen√Ωch pravdƒõpodobnost√≠', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('P(Class 1)')\n",
    "axes[2].set_ylabel('Poƒçet vzork≈Ø')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Anal√Ωza nejist√Ωch p≈ôedpovƒõd√≠\n",
    "uncertain_mask = (y_pred_proba[:, 1] > 0.4) & (y_pred_proba[:, 1] < 0.6)\n",
    "print(f\"\\nPoƒçet nejist√Ωch p≈ôedpovƒõd√≠ (0.4 < P < 0.6): {uncertain_mask.sum()} z {len(y_test_c)}\")\n",
    "print(f\"Procento nejist√Ωch p≈ôedpovƒõd√≠: {uncertain_mask.sum()/len(y_test_c)*100:.1f}%\")\n",
    "print(f\"\\nP≈ôesnost na jist√Ωch p≈ôedpovƒõd√≠ch: {accuracy_score(y_test_c[~uncertain_mask], y_pred_class[~uncertain_mask]):.3f}\")\n",
    "print(f\"P≈ôesnost na nejist√Ωch p≈ôedpovƒõd√≠ch: {accuracy_score(y_test_c[uncertain_mask], y_pred_class[uncertain_mask]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bayesovo uva≈æov√°n√≠\n",
    "\n",
    "### 3.1 Bayesova vƒõta v kontextu AI\n",
    "\n",
    "Bayesova vƒõta n√°m umo≈æ≈àuje aktualizovat na≈°e p≈ôesvƒõdƒçen√≠ na z√°kladƒõ nov√Ωch d≈Økaz≈Ø:\n",
    "\n",
    "$$P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)}$$\n",
    "\n",
    "kde:\n",
    "- P(H|E) - posteriorn√≠ pravdƒõpodobnost (po pozorov√°n√≠ d≈Økaz≈Ø)\n",
    "- P(H) - apriorn√≠ pravdƒõpodobnost (p≈ôed pozorov√°n√≠m)\n",
    "- P(E|H) - vƒõrohodnost (likelihood)\n",
    "- P(E) - margin√°ln√≠ pravdƒõpodobnost d≈Økaz≈Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P≈ô√≠klad: Bayesovsk√° aktualizace pro detekci spamu\n",
    "\n",
    "def bayesian_spam_detector():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BAYESOVSK√ù SPAM DETEKTOR\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Poƒç√°teƒçn√≠ pravdƒõpodobnosti (prior)\n",
    "    P_spam_prior = 0.3  # 30% email≈Ø je spam\n",
    "    P_ham_prior = 0.7   # 70% email≈Ø je ham (ne-spam)\n",
    "    \n",
    "    # Pravdƒõpodobnosti slov v spamu a hamu\n",
    "    spam_words = {\n",
    "        'zdarma': 0.9,\n",
    "        'v√Ωhra': 0.8,\n",
    "        'kliknƒõte': 0.7,\n",
    "        'ihned': 0.6,\n",
    "        'pr√°ce': 0.2,\n",
    "        'sch≈Øzka': 0.1\n",
    "    }\n",
    "    \n",
    "    ham_words = {\n",
    "        'zdarma': 0.1,\n",
    "        'v√Ωhra': 0.05,\n",
    "        'kliknƒõte': 0.1,\n",
    "        'ihned': 0.2,\n",
    "        'pr√°ce': 0.7,\n",
    "        'sch≈Øzka': 0.8\n",
    "    }\n",
    "    \n",
    "    # Testovac√≠ emaily\n",
    "    test_emails = [\n",
    "        ['zdarma', 'v√Ωhra', 'kliknƒõte'],\n",
    "        ['pr√°ce', 'sch≈Øzka'],\n",
    "        ['ihned', 'kliknƒõte', 'zdarma'],\n",
    "        ['sch≈Øzka', 'pr√°ce', 'ihned']\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, email_words in enumerate(test_emails):\n",
    "        # V√Ωpoƒçet likelihood\n",
    "        P_words_given_spam = 1\n",
    "        P_words_given_ham = 1\n",
    "        \n",
    "        for word in email_words:\n",
    "            P_words_given_spam *= spam_words.get(word, 0.01)\n",
    "            P_words_given_ham *= ham_words.get(word, 0.01)\n",
    "        \n",
    "        # Bayesova vƒõta\n",
    "        P_words = P_words_given_spam * P_spam_prior + P_words_given_ham * P_ham_prior\n",
    "        P_spam_posterior = (P_words_given_spam * P_spam_prior) / P_words\n",
    "        P_ham_posterior = (P_words_given_ham * P_ham_prior) / P_words\n",
    "        \n",
    "        # Vizualizace\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Sloupcov√Ω graf\n",
    "        categories = ['Prior', 'Posterior']\n",
    "        spam_probs = [P_spam_prior, P_spam_posterior]\n",
    "        ham_probs = [P_ham_prior, P_ham_posterior]\n",
    "        \n",
    "        x = np.arange(len(categories))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax.bar(x - width/2, spam_probs, width, label='Spam', color='red', alpha=0.7)\n",
    "        bars2 = ax.bar(x + width/2, ham_probs, width, label='Ham', color='green', alpha=0.7)\n",
    "        \n",
    "        ax.set_ylabel('Pravdƒõpodobnost')\n",
    "        ax.set_title(f'Email {idx+1}: {\" + \".join(email_words)}', fontsize=12, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(categories)\n",
    "        ax.legend()\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # P≈ôid√°n√≠ hodnot\n",
    "        for bars, values in [(bars1, spam_probs), (bars2, ham_probs)]:\n",
    "            for bar, val in zip(bars, values):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                       f'{val:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # V√Ωsledek klasifikace\n",
    "        classification = \"SPAM\" if P_spam_posterior > 0.5 else \"HAM\"\n",
    "        color = 'red' if classification == \"SPAM\" else 'green'\n",
    "        ax.text(0.5, 0.85, f'Klasifikace: {classification}', \n",
    "               transform=ax.transAxes, ha='center', fontsize=14, \n",
    "               fontweight='bold', color=color,\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle('Bayesovsk√° aktualizace pro detekci spamu', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nV√Ωsledky klasifikace:\")\n",
    "    for idx, email_words in enumerate(test_emails):\n",
    "        print(f\"Email {idx+1} ({', '.join(email_words)}): \", end=\"\")\n",
    "        \n",
    "        # P≈ôepoƒçet pro v√Ωpis\n",
    "        P_words_given_spam = 1\n",
    "        P_words_given_ham = 1\n",
    "        for word in email_words:\n",
    "            P_words_given_spam *= spam_words.get(word, 0.01)\n",
    "            P_words_given_ham *= ham_words.get(word, 0.01)\n",
    "        P_words = P_words_given_spam * P_spam_prior + P_words_given_ham * P_ham_prior\n",
    "        P_spam_posterior = (P_words_given_spam * P_spam_prior) / P_words\n",
    "        \n",
    "        classification = \"SPAM\" if P_spam_posterior > 0.5 else \"HAM\"\n",
    "        print(f\"{classification} (P(spam) = {P_spam_posterior:.3f})\")\n",
    "\n",
    "bayesian_spam_detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sekvenƒçn√≠ Bayesovsk√° aktualizace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrace postupn√© aktualizace p≈ôesvƒõdƒçen√≠\n",
    "def sequential_bayesian_update():\n",
    "    # Sc√©n√°≈ô: Testov√°n√≠, zda je mince f√©rov√°\n",
    "    # H1: Mince je f√©rov√° (P(hlava) = 0.5)\n",
    "    # H2: Mince je zkreslen√° (P(hlava) = 0.7)\n",
    "    \n",
    "    # Poƒç√°teƒçn√≠ p≈ôesvƒõdƒçen√≠ (uniformn√≠ prior)\n",
    "    prior_fair = 0.5\n",
    "    prior_biased = 0.5\n",
    "    \n",
    "    # Pravdƒõpodobnosti pro ka≈ædou hypot√©zu\n",
    "    p_heads_fair = 0.5\n",
    "    p_heads_biased = 0.7\n",
    "    \n",
    "    # Simulace hod≈Ø\n",
    "    np.random.seed(42)\n",
    "    n_flips = 50\n",
    "    # Simulujeme zkreslenou minci\n",
    "    flips = np.random.random(n_flips) < 0.7  # True = hlava\n",
    "    \n",
    "    # Ukl√°d√°n√≠ posterior≈Ø\n",
    "    posteriors_fair = [prior_fair]\n",
    "    posteriors_biased = [prior_biased]\n",
    "    \n",
    "    # Sekvenƒçn√≠ aktualizace\n",
    "    for flip in flips:\n",
    "        # Likelihood\n",
    "        if flip:  # Hlava\n",
    "            likelihood_fair = p_heads_fair\n",
    "            likelihood_biased = p_heads_biased\n",
    "        else:  # Orel\n",
    "            likelihood_fair = 1 - p_heads_fair\n",
    "            likelihood_biased = 1 - p_heads_biased\n",
    "        \n",
    "        # Aktualizace pomoc√≠ Bayesovy vƒõty\n",
    "        evidence = likelihood_fair * posteriors_fair[-1] + likelihood_biased * posteriors_biased[-1]\n",
    "        \n",
    "        posterior_fair = (likelihood_fair * posteriors_fair[-1]) / evidence\n",
    "        posterior_biased = (likelihood_biased * posteriors_biased[-1]) / evidence\n",
    "        \n",
    "        posteriors_fair.append(posterior_fair)\n",
    "        posteriors_biased.append(posterior_biased)\n",
    "    \n",
    "    # Vizualizace\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Graf 1: V√Ωvoj posteriorn√≠ch pravdƒõpodobnost√≠\n",
    "    x = range(len(posteriors_fair))\n",
    "    ax1.plot(x, posteriors_fair, 'b-', linewidth=2, label='P(F√©rov√° mince)')\n",
    "    ax1.plot(x, posteriors_biased, 'r-', linewidth=2, label='P(Zkreslen√° mince)')\n",
    "    ax1.fill_between(x, 0, posteriors_fair, alpha=0.3, color='blue')\n",
    "    ax1.fill_between(x, posteriors_fair, 1, alpha=0.3, color='red')\n",
    "    ax1.set_xlabel('Poƒçet hod≈Ø')\n",
    "    ax1.set_ylabel('Posteriorn√≠ pravdƒõpodobnost')\n",
    "    ax1.set_title('Bayesovsk√° aktualizace p≈ôesvƒõdƒçen√≠ o f√©rovosti mince', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # Graf 2: Kumulativn√≠ poƒçet hlav\n",
    "    cumsum_heads = np.cumsum(flips)\n",
    "    cumsum_total = np.arange(1, len(flips) + 1)\n",
    "    observed_ratio = cumsum_heads / cumsum_total\n",
    "    \n",
    "    ax2.plot(cumsum_total, observed_ratio, 'g-', linewidth=2, \n",
    "            label='Pozorovan√Ω pomƒõr hlav')\n",
    "    ax2.axhline(y=0.5, color='blue', linestyle='--', linewidth=2, \n",
    "               label='Oƒçek√°v√°no pro f√©rovou minci')\n",
    "    ax2.axhline(y=0.7, color='red', linestyle='--', linewidth=2, \n",
    "               label='Oƒçek√°v√°no pro zkreslenou minci')\n",
    "    ax2.set_xlabel('Poƒçet hod≈Ø')\n",
    "    ax2.set_ylabel('Pomƒõr hlav')\n",
    "    ax2.set_title('Pozorovan√Ω pomƒõr hlav v ƒçase', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0.3, 0.9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Fin√°ln√≠ v√Ωsledky\n",
    "    print(f\"\\nPo {n_flips} hodech:\")\n",
    "    print(f\"Poƒçet hlav: {sum(flips)} ({sum(flips)/n_flips:.1%})\")\n",
    "    print(f\"\\nFin√°ln√≠ posteriorn√≠ pravdƒõpodobnosti:\")\n",
    "    print(f\"P(F√©rov√° mince | data) = {posteriors_fair[-1]:.4f}\")\n",
    "    print(f\"P(Zkreslen√° mince | data) = {posteriors_biased[-1]:.4f}\")\n",
    "    \n",
    "    if posteriors_biased[-1] > posteriors_fair[-1]:\n",
    "        print(\"\\nZ√°vƒõr: Mince je pravdƒõpodobnƒõ ZKRESLEN√Å\")\n",
    "    else:\n",
    "        print(\"\\nZ√°vƒõr: Mince je pravdƒõpodobnƒõ F√âROV√Å\")\n",
    "\n",
    "sequential_bayesian_update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predikƒçn√≠ modely s nejistotou\n",
    "\n",
    "### 4.1 Pr√°ce s chybƒõj√≠c√≠mi daty v predikƒçn√≠ch modelech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porovn√°n√≠ r≈Øzn√Ωch strategi√≠ pro pr√°ci s chybƒõj√≠c√≠mi daty\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Pou≈æijeme d≈ô√≠ve vytvo≈ôen√° data s chybƒõj√≠c√≠mi hodnotami\n",
    "X_train_missing, X_test_missing, y_train, y_test = train_test_split(\n",
    "    X_missing, y_complete, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# R≈Øzn√© strategie imputace\n",
    "strategies = {\n",
    "    'Odstranƒõn√≠ ≈ô√°dk≈Ø': None,\n",
    "    'Pr≈Ømƒõr': SimpleImputer(strategy='mean'),\n",
    "    'Medi√°n': SimpleImputer(strategy='median'),\n",
    "    'KNN Imputer': KNNImputer(n_neighbors=5),\n",
    "    'Iterativn√≠': IterativeImputer(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, imputer in strategies.items():\n",
    "    if name == 'Odstranƒõn√≠ ≈ô√°dk≈Ø':\n",
    "        # Odstranƒõn√≠ ≈ô√°dk≈Ø s chybƒõj√≠c√≠mi hodnotami\n",
    "        mask_train = ~np.isnan(X_train_missing).any(axis=1)\n",
    "        mask_test = ~np.isnan(X_test_missing).any(axis=1)\n",
    "        X_train_imp = X_train_missing[mask_train]\n",
    "        X_test_imp = X_test_missing[mask_test]\n",
    "        y_train_imp = y_train[mask_train]\n",
    "        y_test_imp = y_test[mask_test]\n",
    "    else:\n",
    "        # Imputace\n",
    "        X_train_imp = imputer.fit_transform(X_train_missing)\n",
    "        X_test_imp = imputer.transform(X_test_missing)\n",
    "        y_train_imp = y_train\n",
    "        y_test_imp = y_test\n",
    "    \n",
    "    # Tr√©nov√°n√≠ modelu\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Pro regresi p≈ôevedeme na klasifikaci\n",
    "    y_train_class = (y_train_imp > np.median(y_train_imp)).astype(int)\n",
    "    y_test_class = (y_test_imp > np.median(y_test_imp)).astype(int)\n",
    "    \n",
    "    model.fit(X_train_imp, y_train_class)\n",
    "    \n",
    "    # Predikce s pravdƒõpodobnostmi\n",
    "    y_pred_proba = model.predict_proba(X_test_imp)\n",
    "    y_pred = model.predict(X_test_imp)\n",
    "    \n",
    "    # Ulo≈æen√≠ v√Ωsledk≈Ø\n",
    "    accuracy = accuracy_score(y_test_class, y_pred)\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'train_size': len(X_train_imp),\n",
    "        'test_size': len(X_test_imp),\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "\n",
    "# Vizualizace v√Ωsledk≈Ø\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Graf 1: Porovn√°n√≠ p≈ôesnost√≠\n",
    "names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in names]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(names)))\n",
    "\n",
    "bars = ax1.bar(range(len(names)), accuracies, color=colors)\n",
    "ax1.set_xticks(range(len(names)))\n",
    "ax1.set_xticklabels(names, rotation=45, ha='right')\n",
    "ax1.set_ylabel('P≈ôesnost')\n",
    "ax1.set_title('Porovn√°n√≠ strategi√≠ pro chybƒõj√≠c√≠ data', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# P≈ôid√°n√≠ hodnot\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "            f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Graf 2: Velikost dataset≈Ø po zpracov√°n√≠\n",
    "train_sizes = [results[name]['train_size'] for name in names]\n",
    "test_sizes = [results[name]['test_size'] for name in names]\n",
    "\n",
    "x = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax2.bar(x - width/2, train_sizes, width, label='Tr√©novac√≠', color='lightblue')\n",
    "bars2 = ax2.bar(x + width/2, test_sizes, width, label='Testovac√≠', color='lightcoral')\n",
    "\n",
    "ax2.set_ylabel('Poƒçet vzork≈Ø')\n",
    "ax2.set_title('Velikost datasetu po zpracov√°n√≠', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(names, rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nShrnut√≠ v√Ωsledk≈Ø:\")\n",
    "print(\"=\" * 60)\n",
    "for name in names:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  P≈ôesnost: {results[name]['accuracy']:.3f}\")\n",
    "    print(f\"  Tr√©novac√≠ vzorky: {results[name]['train_size']}\")\n",
    "    print(f\"  Testovac√≠ vzorky: {results[name]['test_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Kvantifikace nejistoty v predikƒçn√≠ch modelech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble metody pro kvantifikaci nejistoty\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vytvo≈ôen√≠ neline√°rn√≠ch dat\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "X = np.sort(np.random.uniform(0, 10, n_samples))\n",
    "y_true = np.sin(X) + 0.1 * X**2\n",
    "noise = np.random.normal(0, 0.5, n_samples)\n",
    "y = y_true + noise\n",
    "\n",
    "# P≈ôid√°n√≠ oblasti s vƒõt≈°√≠ nejistotou (m√©nƒõ dat)\n",
    "mask = (X > 3) & (X < 5)\n",
    "X_train = X[~mask].reshape(-1, 1)\n",
    "y_train = y[~mask]\n",
    "\n",
    "# Test data\n",
    "X_test = np.linspace(0, 10, 300).reshape(-1, 1)\n",
    "\n",
    "# Random Forest s v√≠ce stromy pro lep≈°√≠ odhad nejistoty\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predikce - pr≈Ømƒõr p≈ôes v≈°echny stromy\n",
    "y_pred_mean = rf.predict(X_test)\n",
    "\n",
    "# Z√≠sk√°n√≠ predikc√≠ z jednotliv√Ωch strom≈Ø\n",
    "predictions_trees = np.array([tree.predict(X_test) for tree in rf.estimators_])\n",
    "\n",
    "# V√Ωpoƒçet nejistoty (std p≈ôes stromy)\n",
    "y_pred_std = np.std(predictions_trees, axis=0)\n",
    "\n",
    "# Bayesovsk√° ridge regrese pro porovn√°n√≠\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "br = BayesianRidge()\n",
    "br.fit(X_train, y_train)\n",
    "y_pred_br, y_std_br = br.predict(X_test, return_std=True)\n",
    "\n",
    "# Vizualizace\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# Graf 1: Random Forest s nejistotou\n",
    "ax1.scatter(X_train, y_train, c='red', s=50, alpha=0.7, \n",
    "           edgecolors='black', label='Tr√©novac√≠ data')\n",
    "ax1.plot(X_test, y_pred_mean, 'b-', linewidth=2, label='Random Forest predikce')\n",
    "ax1.fill_between(X_test.ravel(), \n",
    "                y_pred_mean - 2*y_pred_std, \n",
    "                y_pred_mean + 2*y_pred_std, \n",
    "                alpha=0.3, color='blue', label='¬±2œÉ nejistota')\n",
    "ax1.axvspan(3, 5, alpha=0.1, color='gray', label='Oblast s chybƒõj√≠c√≠mi daty')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_title('Random Forest - Kvantifikace nejistoty pomoc√≠ ensemble', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Graf 2: Bayesovsk√° regrese\n",
    "ax2.scatter(X_train, y_train, c='red', s=50, alpha=0.7, \n",
    "           edgecolors='black', label='Tr√©novac√≠ data')\n",
    "ax2.plot(X_test, y_pred_br, 'g-', linewidth=2, label='Bayesovsk√° ridge predikce')\n",
    "ax2.fill_between(X_test.ravel(), \n",
    "                y_pred_br - 2*y_std_br, \n",
    "                y_pred_br + 2*y_std_br, \n",
    "                alpha=0.3, color='green', label='¬±2œÉ nejistota')\n",
    "ax2.axvspan(3, 5, alpha=0.1, color='gray', label='Oblast s chybƒõj√≠c√≠mi daty')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_title('Bayesovsk√° Ridge Regrese - P≈ôirozen√° kvantifikace nejistoty', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Anal√Ωza nejistoty v r≈Øzn√Ωch oblastech\n",
    "regions = {\n",
    "    'Oblast s daty (0-3)': (X_test.ravel() >= 0) & (X_test.ravel() <= 3),\n",
    "    'Oblast bez dat (3-5)': (X_test.ravel() > 3) & (X_test.ravel() < 5),\n",
    "    'Oblast s daty (5-10)': (X_test.ravel() >= 5) & (X_test.ravel() <= 10)\n",
    "}\n",
    "\n",
    "print(\"\\nPr≈Ømƒõrn√° nejistota v r≈Øzn√Ωch oblastech:\")\n",
    "print(\"=\" * 60)\n",
    "for region_name, mask in regions.items():\n",
    "    rf_uncertainty = np.mean(y_pred_std[mask])\n",
    "    br_uncertainty = np.mean(y_std_br[mask])\n",
    "    print(f\"\\n{region_name}:\")\n",
    "    print(f\"  Random Forest œÉ: {rf_uncertainty:.3f}\")\n",
    "    print(f\"  Bayesovsk√° regrese œÉ: {br_uncertainty:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interaktivn√≠ aplikace - Simul√°tor nejistoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_simulator(model_type, noise_level, missing_data_percent, n_samples):\n",
    "    \"\"\"\n",
    "    Interaktivn√≠ simul√°tor pro demonstraci vlivu r≈Øzn√Ωch faktor≈Ø na nejistotu\n",
    "    \"\"\"\n",
    "    np.random.seed(None)  # N√°hodnost p≈ôi ka≈æd√©m spu≈°tƒõn√≠\n",
    "    \n",
    "    # Generov√°n√≠ dat\n",
    "    X = np.linspace(0, 10, n_samples)\n",
    "    y_true = np.sin(1.5 * X) + 0.1 * X\n",
    "    noise = np.random.normal(0, noise_level, n_samples)\n",
    "    y = y_true + noise\n",
    "    \n",
    "    # N√°hodn√© odstranƒõn√≠ dat\n",
    "    if missing_data_percent > 0:\n",
    "        n_missing = int(n_samples * missing_data_percent / 100)\n",
    "        missing_indices = np.random.choice(n_samples, n_missing, replace=False)\n",
    "        mask = np.ones(n_samples, dtype=bool)\n",
    "        mask[missing_indices] = False\n",
    "        X_train = X[mask].reshape(-1, 1)\n",
    "        y_train = y[mask]\n",
    "    else:\n",
    "        X_train = X.reshape(-1, 1)\n",
    "        y_train = y\n",
    "    \n",
    "    X_test = np.linspace(-1, 11, 300).reshape(-1, 1)\n",
    "    \n",
    "    # V√Ωbƒõr modelu\n",
    "    if model_type == \"Gaussovsk√Ω proces\":\n",
    "        from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "        from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "        \n",
    "        kernel = RBF(length_scale=1.0) + WhiteKernel(noise_level=noise_level)\n",
    "        model = GaussianProcessRegressor(kernel=kernel, alpha=0.1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred, y_std = model.predict(X_test, return_std=True)\n",
    "        \n",
    "    elif model_type == \"Random Forest\":\n",
    "        model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Z√≠sk√°n√≠ nejistoty z ensemble\n",
    "        predictions = np.array([tree.predict(X_test) for tree in model.estimators_])\n",
    "        y_pred = np.mean(predictions, axis=0)\n",
    "        y_std = np.std(predictions, axis=0)\n",
    "        \n",
    "    else:  # Bayesovsk√° regrese\n",
    "        model = BayesianRidge()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred, y_std = model.predict(X_test, return_std=True)\n",
    "    \n",
    "    # Vizualizace\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Graf 1: Predikce s nejistotou\n",
    "    ax1.scatter(X_train, y_train, c='red', s=50, alpha=0.7, \n",
    "               edgecolors='black', label='Tr√©novac√≠ data', zorder=5)\n",
    "    ax1.plot(X_test, y_pred, 'b-', linewidth=2, label=f'{model_type} predikce')\n",
    "    ax1.fill_between(X_test.ravel(), \n",
    "                    y_pred - 2*y_std, \n",
    "                    y_pred + 2*y_std, \n",
    "                    alpha=0.3, color='blue', label='95% interval spolehlivosti')\n",
    "    \n",
    "    # Oznaƒçen√≠ extrapolace\n",
    "    ax1.axvspan(-1, 0, alpha=0.1, color='orange', label='Extrapolace')\n",
    "    ax1.axvspan(10, 11, alpha=0.1, color='orange')\n",
    "    \n",
    "    ax1.set_xlabel('X', fontsize=12)\n",
    "    ax1.set_ylabel('Y', fontsize=12)\n",
    "    ax1.set_title(f'{model_type} - Predikce s kvantifikovanou nejistotou', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(-1, 11)\n",
    "    \n",
    "    # Graf 2: Mapa nejistoty\n",
    "    ax2.plot(X_test, y_std, 'g-', linewidth=3, label='Standardn√≠ odchylka')\n",
    "    ax2.fill_between(X_test.ravel(), 0, y_std, alpha=0.3, color='green')\n",
    "    ax2.set_xlabel('X', fontsize=12)\n",
    "    ax2.set_ylabel('Nejistota (œÉ)', fontsize=12)\n",
    "    ax2.set_title('Prostorov√© rozdƒõlen√≠ nejistoty', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(-1, 11)\n",
    "    \n",
    "    # Oznaƒçen√≠ oblast√≠\n",
    "    ax2.axvspan(-1, 0, alpha=0.1, color='orange')\n",
    "    ax2.axvspan(10, 11, alpha=0.1, color='orange')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Statistiky\n",
    "    avg_uncertainty = np.mean(y_std)\n",
    "    max_uncertainty = np.max(y_std)\n",
    "    min_uncertainty = np.min(y_std)\n",
    "    \n",
    "    stats_text = f\"\"\"### Statistiky nejistoty:\n",
    "    \n",
    "**Model:** {model_type}\n",
    "**√örove≈à ≈°umu:** {noise_level:.2f}\n",
    "**Chybƒõj√≠c√≠ data:** {missing_data_percent:.0f}%\n",
    "**Poƒçet tr√©novac√≠ch vzork≈Ø:** {len(X_train)}\n",
    "\n",
    "**Pr≈Ømƒõrn√° nejistota (œÉ):** {avg_uncertainty:.3f}\n",
    "**Maxim√°ln√≠ nejistota:** {max_uncertainty:.3f}\n",
    "**Minim√°ln√≠ nejistota:** {min_uncertainty:.3f}\n",
    "\n",
    "**Pozorov√°n√≠:**\n",
    "- Nejistota se zvy≈°uje v oblastech s m√©nƒõ daty\n",
    "- Extrapolace mimo tr√©novac√≠ oblast m√° vysokou nejistotu\n",
    "- R≈Øzn√© modely kvantifikuj√≠ nejistotu r≈Øznƒõ\n",
    "\"\"\"\n",
    "    \n",
    "    return fig, stats_text\n",
    "\n",
    "# Vytvo≈ôen√≠ Gradio rozhran√≠\n",
    "with gr.Blocks(title=\"Simul√°tor nejistoty v AI\") as demo:\n",
    "    gr.Markdown(\"# üéØ Simul√°tor nejistoty v AI modelech\")\n",
    "    gr.Markdown(\"\"\"Experimentujte s r≈Øzn√Ωmi faktory ovliv≈àuj√≠c√≠mi nejistotu v predikƒçn√≠ch modelech.\n",
    "    Pozorujte, jak se mƒõn√≠ interval spolehlivosti v z√°vislosti na:\n",
    "    - Typu modelu\n",
    "    - √örovni ≈°umu v datech\n",
    "    - Mno≈æstv√≠ chybƒõj√≠c√≠ch dat\n",
    "    - Poƒçtu tr√©novac√≠ch vzork≈Ø\"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            model_choice = gr.Radio(\n",
    "                choices=[\"Gaussovsk√Ω proces\", \"Random Forest\", \"Bayesovsk√° regrese\"],\n",
    "                value=\"Gaussovsk√Ω proces\",\n",
    "                label=\"Typ modelu\"\n",
    "            )\n",
    "            \n",
    "            noise = gr.Slider(\n",
    "                minimum=0,\n",
    "                maximum=1,\n",
    "                value=0.3,\n",
    "                step=0.05,\n",
    "                label=\"√örove≈à ≈°umu v datech\"\n",
    "            )\n",
    "            \n",
    "            missing = gr.Slider(\n",
    "                minimum=0,\n",
    "                maximum=70,\n",
    "                value=20,\n",
    "                step=5,\n",
    "                label=\"Procento chybƒõj√≠c√≠ch dat (%)\"\n",
    "            )\n",
    "            \n",
    "            samples = gr.Slider(\n",
    "                minimum=20,\n",
    "                maximum=200,\n",
    "                value=50,\n",
    "                step=10,\n",
    "                label=\"Poƒçet vzork≈Ø\"\n",
    "            )\n",
    "            \n",
    "            simulate_btn = gr.Button(\"üöÄ Spustit simulaci\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            stats_output = gr.Markdown(\"### Zde se zobraz√≠ statistiky...\")\n",
    "    \n",
    "    plot_output = gr.Plot(label=\"Vizualizace nejistoty\")\n",
    "    \n",
    "    simulate_btn.click(\n",
    "        uncertainty_simulator,\n",
    "        inputs=[model_choice, noise, missing, samples],\n",
    "        outputs=[plot_output, stats_output]\n",
    "    )\n",
    "    \n",
    "    gr.Markdown(\"\"\"### üìö Vysvƒõtlen√≠ model≈Ø:\n",
    "    \n",
    "- **Gaussovsk√Ω proces**: Neparametrick√Ω model s p≈ôirozenou kvantifikac√≠ nejistoty\n",
    "- **Random Forest**: Ensemble strom≈Ø - nejistota z variance predikc√≠\n",
    "- **Bayesovsk√° regrese**: Pravdƒõpodobnostn√≠ line√°rn√≠ model s posteriorn√≠m rozdƒõlen\n",
    "    \"\"\")\n",
    "\n",
    "# Spu≈°tƒõn√≠ aplikace\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Shrnut√≠ a kl√≠ƒçov√© koncepty\n",
    "\n",
    "### Co jsme se nauƒçili:\n",
    "\n",
    "1. **Zdroje nejistoty v AI**\n",
    "   - Aleatorick√° nejistota (p≈ôirozen√° n√°hodnost)\n",
    "   - Epistemick√° nejistota (nedostatek znalost√≠)\n",
    "   - Chybƒõj√≠c√≠ data a ≈°um\n",
    "\n",
    "2. **Pravdƒõpodobnostn√≠ modely**\n",
    "   - Poskytuj√≠ nejen predikci, ale i m√≠ru jistoty\n",
    "   - Umo≈æ≈àuj√≠ kvantifikovat riziko\n",
    "   - D≈Øle≈æit√© pro rozhodov√°n√≠ v re√°ln√Ωch aplikac√≠ch\n",
    "\n",
    "3. **Bayesovo uva≈æov√°n√≠**\n",
    "   - Aktualizace p≈ôesvƒõdƒçen√≠ s nov√Ωmi daty\n",
    "   - Kombinace apriorn√≠ch znalost√≠ s pozorov√°n√≠mi\n",
    "   - Sekvenƒçn√≠ uƒçen√≠ a adaptace\n",
    "\n",
    "4. **Praktick√© metody**\n",
    "   - Strategie pro pr√°ci s chybƒõj√≠c√≠mi daty\n",
    "   - Ensemble metody pro odhad nejistoty\n",
    "   - Bayesovsk√© modely s p≈ôirozenou kvantifikac√≠\n",
    "\n",
    "### Kl√≠ƒçov√© principy:\n",
    "\n",
    "- **Nejistota nen√≠ chyba** - je to p≈ôirozen√° souƒç√°st predikce\n",
    "- **Kvantifikace nejistoty** umo≈æ≈àuje lep≈°√≠ rozhodov√°n√≠\n",
    "- **Bayesovsk√Ω p≈ô√≠stup** poskytuje principi√°ln√≠ framework\n",
    "- **R≈Øzn√© modely** maj√≠ r≈Øzn√© zp≈Øsoby pr√°ce s nejistotou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dom√°c√≠ √∫kol\n",
    "\n",
    "### √ökol 1: Bayesovsk√Ω detektor anom√°li√≠\n",
    "Implementujte syst√©m, kter√Ω:\n",
    "- Postupnƒõ se uƒç√≠ norm√°ln√≠ chov√°n√≠ syst√©mu\n",
    "- Detekuje anom√°lie s kvantifikac√≠ jistoty\n",
    "- Aktualizuje sv√© p≈ôesvƒõdƒçen√≠ s nov√Ωmi daty\n",
    "- Vizualizuje v√Ωvoj detekce v ƒçase\n",
    "\n",
    "### √ökol 2: Predikce s odm√≠tnut√≠m\n",
    "Vytvo≈ôte klasifik√°tor, kter√Ω:\n",
    "- M≈Ø≈æe odm√≠tnout klasifikaci p≈ôi vysok√© nejistotƒõ\n",
    "- Optimalizuje pr√°h odm√≠tnut√≠ pro minimalizaci chyb\n",
    "- Porovn√° v√Ωkon s r≈Øzn√Ωmi prahy\n",
    "\n",
    "### √ökol 3: Aktivn√≠ uƒçen√≠\n",
    "Implementujte syst√©m, kter√Ω:\n",
    "- Identifikuje vzorky s nejvy≈°≈°√≠ nejistotou\n",
    "- Po≈æ√°d√° o jejich oznaƒçen√≠ (simulovanƒõ)\n",
    "- Uk√°≈æe, jak se zlep≈°uje s aktivn√≠m v√Ωbƒõrem dat\n",
    "\n",
    "### Bonusov√Ω √∫kol: Ensemble nejistoty\n",
    "Vytvo≈ôte vlastn√≠ ensemble model, kter√Ω:\n",
    "- Kombinuje r≈Øzn√© typy model≈Ø\n",
    "- Agreguje jejich nejistoty\n",
    "- Poskytuje robustnƒõj≈°√≠ odhady\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Tip**: P≈ôi ≈ôe≈°en√≠ √∫kol≈Ø se zamƒõ≈ôte na praktickou interpretaci nejistoty a jej√≠ vyu≈æit√≠ pro lep≈°√≠ rozhodov√°n√≠!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}