{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Hodina 9: Mini projekt - NÃ¡vrh jednoduchÃ©ho projektu s AI\n",
    "\n",
    "## Obsah hodiny\n",
    "- PlÃ¡novÃ¡nÃ­ AI projektu\n",
    "- VÃ½bÄ›r vhodnÃ½ch nÃ¡strojÅ¯\n",
    "- Implementace chatbota s transformery\n",
    "- VytvoÅ™enÃ­ AI asistenta pro studenty\n",
    "- Deployment s Gradio a Ollama\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Instalace potÅ™ebnÃ½ch knihoven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Instalace knihoven pro projekt\n",
    "!pip install transformers torch gradio datasets ollama huggingface_hub -q\n",
    "!pip install langchain chromadb sentence-transformers -q\n",
    "!pip install streamlit plotly pandas -q\n",
    "\n",
    "import torch\n",
    "import gradio as gr\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"âœ… Knihovny nainstalovÃ¡ny!\")\n",
    "print(f\"PyTorch verze: {torch.__version__}\")\n",
    "print(f\"CUDA dostupnÃ¡: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_planning"
   },
   "source": [
    "## 1. PlÃ¡novÃ¡nÃ­ projektu\n",
    "\n",
    "### ğŸ¯ CÃ­l projektu: AI StudijnÃ­ Asistent\n",
    "\n",
    "VytvoÅ™Ã­me inteligentnÃ­ho asistenta, kterÃ½ pomÅ¯Å¾e studentÅ¯m s uÄenÃ­m:\n",
    "- ğŸ“š OdpovÃ­dÃ¡nÃ­ na otÃ¡zky\n",
    "- ğŸ“ GenerovÃ¡nÃ­ studijnÃ­ch materiÃ¡lÅ¯\n",
    "- ğŸ§  VytvÃ¡Å™enÃ­ kvÃ­zÅ¯\n",
    "- ğŸ“Š SledovÃ¡nÃ­ pokroku\n",
    "- ğŸ’¬ KonverzaÄnÃ­ rozhranÃ­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "project_structure"
   },
   "outputs": [],
   "source": [
    "# Definice struktury projektu\n",
    "class ProjectPlanner:\n",
    "    def __init__(self, project_name):\n",
    "        self.project_name = project_name\n",
    "        self.components = []\n",
    "        self.timeline = []\n",
    "        self.tech_stack = []\n",
    "        \n",
    "    def add_component(self, name, description, priority):\n",
    "        self.components.append({\n",
    "            'name': name,\n",
    "            'description': description,\n",
    "            'priority': priority,\n",
    "            'status': 'planned'\n",
    "        })\n",
    "    \n",
    "    def add_tech(self, technology, purpose):\n",
    "        self.tech_stack.append({\n",
    "            'technology': technology,\n",
    "            'purpose': purpose\n",
    "        })\n",
    "    \n",
    "    def visualize_plan(self):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Graf 1: Komponenty podle priority\n",
    "        components_df = pd.DataFrame(self.components)\n",
    "        priority_counts = components_df['priority'].value_counts()\n",
    "        \n",
    "        colors = {'vysokÃ¡': '#FF6B6B', 'stÅ™ednÃ­': '#4ECDC4', 'nÃ­zkÃ¡': '#45B7D1'}\n",
    "        pie_colors = [colors[p] for p in priority_counts.index]\n",
    "        \n",
    "        ax1.pie(priority_counts.values, labels=priority_counts.index, \n",
    "                colors=pie_colors, autopct='%1.0f%%', startangle=90)\n",
    "        ax1.set_title('Komponenty podle priority', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Graf 2: TechnologickÃ½ stack\n",
    "        tech_names = [t['technology'] for t in self.tech_stack]\n",
    "        y_positions = np.arange(len(tech_names))\n",
    "        \n",
    "        ax2.barh(y_positions, [1]*len(tech_names), color='#96CEB4')\n",
    "        ax2.set_yticks(y_positions)\n",
    "        ax2.set_yticklabels(tech_names)\n",
    "        ax2.set_xlabel('VyuÅ¾itÃ­ v projektu')\n",
    "        ax2.set_title('TechnologickÃ½ stack', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlim(0, 1.2)\n",
    "        \n",
    "        # PÅ™idÃ¡nÃ­ ÃºÄelu technologiÃ­\n",
    "        for i, tech in enumerate(self.tech_stack):\n",
    "            ax2.text(0.02, i, tech['purpose'], va='center', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# VytvoÅ™enÃ­ plÃ¡nu projektu\n",
    "planner = ProjectPlanner(\"AI StudijnÃ­ Asistent\")\n",
    "\n",
    "# PÅ™idÃ¡nÃ­ komponent\n",
    "planner.add_component(\"Chatbot Interface\", \"KonverzaÄnÃ­ rozhranÃ­ pro studenty\", \"vysokÃ¡\")\n",
    "planner.add_component(\"Question Answering\", \"OdpovÃ­dÃ¡nÃ­ na studijnÃ­ otÃ¡zky\", \"vysokÃ¡\")\n",
    "planner.add_component(\"Study Material Generator\", \"GenerovÃ¡nÃ­ poznÃ¡mek a shrnutÃ­\", \"vysokÃ¡\")\n",
    "planner.add_component(\"Quiz Creator\", \"AutomatickÃ© vytvÃ¡Å™enÃ­ testÅ¯\", \"stÅ™ednÃ­\")\n",
    "planner.add_component(\"Progress Tracker\", \"SledovÃ¡nÃ­ pokroku studenta\", \"stÅ™ednÃ­\")\n",
    "planner.add_component(\"Voice Assistant\", \"HlasovÃ© ovlÃ¡dÃ¡nÃ­\", \"nÃ­zkÃ¡\")\n",
    "planner.add_component(\"PDF Analyzer\", \"AnalÃ½za studijnÃ­ch materiÃ¡lÅ¯\", \"stÅ™ednÃ­\")\n",
    "\n",
    "# PÅ™idÃ¡nÃ­ technologiÃ­\n",
    "planner.add_tech(\"Transformers (Hugging Face)\", \"NLP modely pro generovÃ¡nÃ­ textu\")\n",
    "planner.add_tech(\"Gradio\", \"WebovÃ© uÅ¾ivatelskÃ© rozhranÃ­\")\n",
    "planner.add_tech(\"LangChain\", \"Orchestrace LLM workflows\")\n",
    "planner.add_tech(\"ChromaDB\", \"VektorovÃ¡ databÃ¡ze pro RAG\")\n",
    "planner.add_tech(\"Ollama\", \"LokÃ¡lnÃ­ LLM deployment\")\n",
    "planner.add_tech(\"PyTorch\", \"Deep learning framework\")\n",
    "\n",
    "print(\"ğŸ“‹ PLÃN PROJEKTU: AI StudijnÃ­ Asistent\\n\")\n",
    "print(\"Komponenty projektu:\")\n",
    "for comp in planner.components:\n",
    "    emoji = \"ğŸ”´\" if comp['priority'] == 'vysokÃ¡' else \"ğŸŸ¡\" if comp['priority'] == 'stÅ™ednÃ­' else \"ğŸ”µ\"\n",
    "    print(f\"{emoji} {comp['name']}: {comp['description']}\")\n",
    "\n",
    "print(\"\\nTehnologickÃ½ stack:\")\n",
    "for tech in planner.tech_stack:\n",
    "    print(f\"  â€¢ {tech['technology']}: {tech['purpose']}\")\n",
    "\n",
    "planner.visualize_plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chatbot_implementation"
   },
   "source": [
    "## 2. Implementace AI Chatbota s Transformery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "transformer_chatbot"
   },
   "outputs": [],
   "source": [
    "# VytvoÅ™enÃ­ AI chatbota pomocÃ­ transformerÅ¯\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "class StudyAssistantBot:\n",
    "    def __init__(self, model_name=\"microsoft/DialoGPT-small\"):\n",
    "        print(f\"ğŸ¤– Inicializuji AI asistenta s modelem {model_name}...\")\n",
    "        \n",
    "        # NaÄtenÃ­ modelu a tokenizeru\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        \n",
    "        # NastavenÃ­ pad tokenu\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Historie konverzace\n",
    "        self.conversation_history = []\n",
    "        self.chat_history_ids = None\n",
    "        \n",
    "        # StudijnÃ­ kontext\n",
    "        self.study_context = {\n",
    "            'subject': None,\n",
    "            'topics': [],\n",
    "            'questions_asked': 0,\n",
    "            'correct_answers': 0\n",
    "        }\n",
    "        \n",
    "        print(\"âœ… AI asistent pÅ™ipraven!\")\n",
    "    \n",
    "    def set_study_context(self, subject, topics):\n",
    "        \"\"\"NastavenÃ­ studijnÃ­ho kontextu\"\"\"\n",
    "        self.study_context['subject'] = subject\n",
    "        self.study_context['topics'] = topics\n",
    "        \n",
    "    def generate_response(self, user_input, max_length=200):\n",
    "        \"\"\"GenerovÃ¡nÃ­ odpovÄ›di pomocÃ­ transformeru\"\"\"\n",
    "        # PÅ™idÃ¡nÃ­ vstupu do historie\n",
    "        self.conversation_history.append(f\"Student: {user_input}\")\n",
    "        \n",
    "        # Tokenizace vstupu\n",
    "        new_user_input_ids = self.tokenizer.encode(\n",
    "            user_input + self.tokenizer.eos_token, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # PÅ™ipojenÃ­ k historii chatu\n",
    "        if self.chat_history_ids is not None:\n",
    "            bot_input_ids = torch.cat([self.chat_history_ids, new_user_input_ids], dim=-1)\n",
    "        else:\n",
    "            bot_input_ids = new_user_input_ids\n",
    "        \n",
    "        # OmezenÃ­ dÃ©lky historie\n",
    "        if bot_input_ids.shape[1] > 1000:\n",
    "            bot_input_ids = bot_input_ids[:, -1000:]\n",
    "        \n",
    "        # GenerovÃ¡nÃ­ odpovÄ›di\n",
    "        with torch.no_grad():\n",
    "            chat_history_ids = self.model.generate(\n",
    "                bot_input_ids,\n",
    "                max_length=bot_input_ids.shape[1] + max_length,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                do_sample=True,\n",
    "                temperature=0.8,\n",
    "                top_p=0.9,\n",
    "                no_repeat_ngram_size=3\n",
    "            )\n",
    "        \n",
    "        # DekÃ³dovÃ¡nÃ­ odpovÄ›di\n",
    "        response = self.tokenizer.decode(\n",
    "            chat_history_ids[:, bot_input_ids.shape[-1]:][0], \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        # Aktualizace historie\n",
    "        self.chat_history_ids = chat_history_ids\n",
    "        self.conversation_history.append(f\"Asistent: {response}\")\n",
    "        \n",
    "        # PÅ™idÃ¡nÃ­ studijnÃ­ho kontextu\n",
    "        if self.study_context['subject']:\n",
    "            response = self._enhance_with_study_context(user_input, response)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _enhance_with_study_context(self, question, response):\n",
    "        \"\"\"VylepÅ¡enÃ­ odpovÄ›di podle studijnÃ­ho kontextu\"\"\"\n",
    "        # JednoduchÃ¡ logika pro vylepÅ¡enÃ­ odpovÄ›dÃ­\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        if \"co je\" in question_lower or \"vysvÄ›tli\" in question_lower:\n",
    "            response += f\"\\n\\nğŸ’¡ Tip: PÅ™i studiu {self.study_context['subject']} je dÅ¯leÅ¾itÃ© pochopit zÃ¡kladnÃ­ koncepty.\"\n",
    "        \n",
    "        elif \"jak\" in question_lower:\n",
    "            response += \"\\n\\nğŸ“ DoporuÄuji si udÄ›lat poznÃ¡mky a procviÄit na pÅ™Ã­kladech.\"\n",
    "        \n",
    "        elif \"proÄ\" in question_lower:\n",
    "            response += \"\\n\\nğŸ” Zkuste se zamyslet nad praktickÃ½mi aplikacemi tohoto konceptu.\"\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def generate_quiz_question(self, topic):\n",
    "        \"\"\"GenerovÃ¡nÃ­ kvÃ­zovÃ© otÃ¡zky\"\"\"\n",
    "        prompt = f\"VytvoÅ™ jednu otÃ¡zku s moÅ¾nostmi a, b, c, d na tÃ©ma {topic}:\"\n",
    "        \n",
    "        # Simulace generovÃ¡nÃ­ otÃ¡zky (v reÃ¡lnÃ© aplikaci by se pouÅ¾il specializovanÃ½ model)\n",
    "        questions = [\n",
    "            {\n",
    "                \"question\": f\"Co je hlavnÃ­ charakteristika {topic}?\",\n",
    "                \"options\": [\n",
    "                    \"a) PrvnÃ­ moÅ¾nost\",\n",
    "                    \"b) DruhÃ¡ moÅ¾nost\",\n",
    "                    \"c) TÅ™etÃ­ moÅ¾nost\",\n",
    "                    \"d) ÄŒtvrtÃ¡ moÅ¾nost\"\n",
    "                ],\n",
    "                \"correct\": \"a\"\n",
    "            },\n",
    "            {\n",
    "                \"question\": f\"KterÃ½ z nÃ¡sledujÃ­cÃ­ch vÃ½rokÅ¯ o {topic} je pravdivÃ½?\",\n",
    "                \"options\": [\n",
    "                    \"a) VÃ½rok 1\",\n",
    "                    \"b) VÃ½rok 2\",\n",
    "                    \"c) VÃ½rok 3\",\n",
    "                    \"d) VÃ½rok 4\"\n",
    "                ],\n",
    "                \"correct\": \"b\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        return np.random.choice(questions)\n",
    "    \n",
    "    def get_study_summary(self):\n",
    "        \"\"\"ZÃ­skÃ¡nÃ­ shrnutÃ­ studia\"\"\"\n",
    "        if self.study_context['questions_asked'] == 0:\n",
    "            return \"ZatÃ­m jste nezaÄali studovat.\"\n",
    "        \n",
    "        accuracy = (self.study_context['correct_answers'] / \n",
    "                   self.study_context['questions_asked'] * 100)\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "        ğŸ“Š **ShrnutÃ­ vaÅ¡eho studia**\n",
    "        \n",
    "        PÅ™edmÄ›t: {self.study_context['subject']}\n",
    "        TÃ©mata: {', '.join(self.study_context['topics'])}\n",
    "        ZodpovÄ›zenÃ© otÃ¡zky: {self.study_context['questions_asked']}\n",
    "        SprÃ¡vnÃ© odpovÄ›di: {self.study_context['correct_answers']}\n",
    "        ÃšspÄ›Å¡nost: {accuracy:.1f}%\n",
    "        \n",
    "        {self._get_performance_feedback(accuracy)}\n",
    "        \"\"\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _get_performance_feedback(self, accuracy):\n",
    "        \"\"\"ZpÄ›tnÃ¡ vazba podle vÃ½konu\"\"\"\n",
    "        if accuracy >= 90:\n",
    "            return \"ğŸŒŸ VÃ½bornÄ›! MÃ¡te skvÄ›lÃ© znalosti!\"\n",
    "        elif accuracy >= 70:\n",
    "            return \"ğŸ‘ DobÅ™e! JeÅ¡tÄ› trochu procviÄit a budete expert!\"\n",
    "        elif accuracy >= 50:\n",
    "            return \"ğŸ“š PrÅ¯mÄ›r. DoporuÄuji vÃ­ce procviÄovat.\"\n",
    "        else:\n",
    "            return \"ğŸ’ª NevzdÃ¡vejte se! KaÅ¾dÃ½ zaÄÃ­nal od nuly.\"\n",
    "\n",
    "# VytvoÅ™enÃ­ instance asistenta\n",
    "print(\"ğŸ“ VYTVÃÅ˜ENÃ AI STUDIJNÃHO ASISTENTA\\n\")\n",
    "assistant = StudyAssistantBot()\n",
    "\n",
    "# NastavenÃ­ studijnÃ­ho kontextu\n",
    "assistant.set_study_context(\"UmÄ›lÃ¡ inteligence\", [\"Neural Networks\", \"Machine Learning\", \"Deep Learning\"])\n",
    "\n",
    "# Test konverzace\n",
    "print(\"\\nğŸ’¬ UkÃ¡zka konverzace:\\n\")\n",
    "\n",
    "test_questions = [\n",
    "    \"Ahoj, jsem student a potÅ™ebuji pomoc s uÄenÃ­m.\",\n",
    "    \"Co je to neuronovÃ¡ sÃ­Å¥?\",\n",
    "    \"Jak funguje machine learning?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"ğŸ‘¤ Student: {question}\")\n",
    "    response = assistant.generate_response(question)\n",
    "    print(f\"ğŸ¤– Asistent: {response}\\n\")\n",
    "\n",
    "# GenerovÃ¡nÃ­ kvÃ­zovÃ© otÃ¡zky\n",
    "print(\"\\nğŸ“ UkÃ¡zka kvÃ­zovÃ© otÃ¡zky:\")\n",
    "quiz = assistant.generate_quiz_question(\"neuronovÃ© sÃ­tÄ›\")\n",
    "print(f\"\\nOtÃ¡zka: {quiz['question']}\")\n",
    "for option in quiz['options']:\n",
    "    print(f\"  {option}\")\n",
    "print(f\"\\n(SprÃ¡vnÃ¡ odpovÄ›Ä: {quiz['correct']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rag_implementation"
   },
   "source": [
    "## 3. RAG (Retrieval-Augmented Generation) SystÃ©m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rag_system"
   },
   "outputs": [],
   "source": [
    "# Implementace RAG systÃ©mu pro pÅ™esnÃ© odpovÄ›di\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import numpy as np\n",
    "\n",
    "class StudyRAGSystem:\n",
    "    def __init__(self):\n",
    "        print(\"ğŸ“š Inicializuji RAG systÃ©m pro studijnÃ­ materiÃ¡ly...\")\n",
    "        \n",
    "        # Inicializace embedding modelu\n",
    "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Inicializace ChromaDB\n",
    "        self.chroma_client = chromadb.Client(Settings(\n",
    "            anonymized_telemetry=False,\n",
    "            persist_directory=\"./study_db\"\n",
    "        ))\n",
    "        \n",
    "        # VytvoÅ™enÃ­ kolekce\n",
    "        try:\n",
    "            self.collection = self.chroma_client.create_collection(\n",
    "                name=\"study_materials\",\n",
    "                metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "        except:\n",
    "            self.collection = self.chroma_client.get_collection(\"study_materials\")\n",
    "        \n",
    "        print(\"âœ… RAG systÃ©m pÅ™ipraven!\")\n",
    "    \n",
    "    def add_study_material(self, text, metadata=None):\n",
    "        \"\"\"PÅ™idÃ¡nÃ­ studijnÃ­ho materiÃ¡lu do databÃ¡ze\"\"\"\n",
    "        # RozdÄ›lenÃ­ textu na chunks\n",
    "        chunks = self._split_text(text, chunk_size=200)\n",
    "        \n",
    "        # VytvoÅ™enÃ­ embeddings\n",
    "        embeddings = self.embedder.encode(chunks)\n",
    "        \n",
    "        # PÅ™idÃ¡nÃ­ do databÃ¡ze\n",
    "        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "            self.collection.add(\n",
    "                embeddings=[embedding.tolist()],\n",
    "                documents=[chunk],\n",
    "                metadatas=[metadata or {}],\n",
    "                ids=[f\"chunk_{len(self.collection.get()['ids'])}_{i}\"]\n",
    "            )\n",
    "        \n",
    "        print(f\"âœ… PÅ™idÃ¡no {len(chunks)} ÄÃ¡stÃ­ textu do databÃ¡ze\")\n",
    "    \n",
    "    def _split_text(self, text, chunk_size=200):\n",
    "        \"\"\"RozdÄ›lenÃ­ textu na menÅ¡Ã­ ÄÃ¡sti\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(words), chunk_size):\n",
    "            chunk = ' '.join(words[i:i+chunk_size])\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def search(self, query, n_results=3):\n",
    "        \"\"\"VyhledÃ¡nÃ­ relevantnÃ­ch materiÃ¡lÅ¯\"\"\"\n",
    "        # VytvoÅ™enÃ­ embedding pro dotaz\n",
    "        query_embedding = self.embedder.encode([query])[0]\n",
    "        \n",
    "        # VyhledÃ¡nÃ­ v databÃ¡zi\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_answer(self, query, context_docs):\n",
    "        \"\"\"GenerovÃ¡nÃ­ odpovÄ›di na zÃ¡kladÄ› kontextu\"\"\"\n",
    "        # SpojenÃ­ relevantnÃ­ch dokumentÅ¯\n",
    "        context = \"\\n\\n\".join(context_docs)\n",
    "        \n",
    "        # JednoduchÃ¡ Å¡ablona pro odpovÄ›Ä\n",
    "        answer_template = f\"\"\"\n",
    "        Na zÃ¡kladÄ› dostupnÃ½ch materiÃ¡lÅ¯:\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        OdpovÄ›Ä na otÃ¡zku \"{query}\":\n",
    "        \"\"\"\n",
    "        \n",
    "        # V reÃ¡lnÃ© aplikaci by se pouÅ¾il LLM pro generovÃ¡nÃ­ odpovÄ›di\n",
    "        # Pro demo ÃºÄely vrÃ¡tÃ­me strukturovanou odpovÄ›Ä\n",
    "        return self._simple_answer_generation(query, context)\n",
    "    \n",
    "    def _simple_answer_generation(self, query, context):\n",
    "        \"\"\"JednoduchÃ¡ generace odpovÄ›di (simulace)\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        if \"co je\" in query_lower:\n",
    "            return f\"Na zÃ¡kladÄ› studijnÃ­ch materiÃ¡lÅ¯: {context[:200]}...\"\n",
    "        elif \"jak\" in query_lower:\n",
    "            return f\"Postup podle materiÃ¡lÅ¯: {context[:200]}...\"\n",
    "        elif \"proÄ\" in query_lower:\n",
    "            return f\"DÅ¯vod je nÃ¡sledujÃ­cÃ­: {context[:200]}...\"\n",
    "        else:\n",
    "            return f\"RelevantnÃ­ informace: {context[:200]}...\"\n",
    "\n",
    "# VytvoÅ™enÃ­ RAG systÃ©mu\n",
    "rag_system = StudyRAGSystem()\n",
    "\n",
    "# PÅ™idÃ¡nÃ­ studijnÃ­ch materiÃ¡lÅ¯\n",
    "study_materials = [\n",
    "    \"\"\"\n",
    "    NeuronovÃ© sÃ­tÄ› jsou vÃ½poÄetnÃ­ modely inspirovanÃ© biologickÃ½m mozkem. \n",
    "    SklÃ¡dajÃ­ se z vrstev neuronÅ¯, kterÃ© jsou vzÃ¡jemnÄ› propojeny vahami. \n",
    "    KaÅ¾dÃ½ neuron pÅ™ijÃ­mÃ¡ vstupy, aplikuje na nÄ› vÃ¡hy, seÄte je a \n",
    "    vÃ½sledek proÅ¾ene aktivaÄnÃ­ funkcÃ­. UÄenÃ­ probÃ­hÃ¡ pomocÃ­ algoritmu \n",
    "    zpÄ›tnÃ© propagace, kterÃ½ upravuje vÃ¡hy na zÃ¡kladÄ› chyby predikce.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    StrojovÃ© uÄenÃ­ je podoblast umÄ›lÃ© inteligence, kterÃ¡ umoÅ¾Åˆuje \n",
    "    poÄÃ­taÄÅ¯m uÄit se z dat bez explicitnÃ­ho programovÃ¡nÃ­. ExistujÃ­ \n",
    "    tÅ™i hlavnÃ­ typy: uÄenÃ­ s uÄitelem (supervised learning), uÄenÃ­ \n",
    "    bez uÄitele (unsupervised learning) a posilovanÃ© uÄenÃ­ \n",
    "    (reinforcement learning). KaÅ¾dÃ½ typ mÃ¡ svÃ© specifickÃ© pouÅ¾itÃ­.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep learning je specializovanÃ¡ oblast strojovÃ©ho uÄenÃ­ vyuÅ¾Ã­vajÃ­cÃ­ \n",
    "    hlubokÃ© neuronovÃ© sÃ­tÄ› s mnoha vrstvami. Tyto sÃ­tÄ› dokÃ¡Å¾Ã­ \n",
    "    automaticky extrahovat hierarchickÃ© features z dat. NejznÃ¡mÄ›jÅ¡Ã­ \n",
    "    architektury zahrnujÃ­ CNN pro zpracovÃ¡nÃ­ obrazu, RNN pro \n",
    "    sekvenÄnÃ­ data a Transformery pro NLP Ãºlohy.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“¥ PÅ™idÃ¡vÃ¡m studijnÃ­ materiÃ¡ly do databÃ¡ze...\")\n",
    "for i, material in enumerate(study_materials):\n",
    "    rag_system.add_study_material(\n",
    "        material, \n",
    "        metadata={\"topic\": [\"Neural Networks\", \"Machine Learning\", \"Deep Learning\"][i]}\n",
    "    )\n",
    "\n",
    "# Test vyhledÃ¡vÃ¡nÃ­\n",
    "print(\"\\nğŸ” Test RAG systÃ©mu:\\n\")\n",
    "\n",
    "test_queries = [\n",
    "    \"Co jsou neuronovÃ© sÃ­tÄ›?\",\n",
    "    \"JakÃ© jsou typy strojovÃ©ho uÄenÃ­?\",\n",
    "    \"Co je deep learning?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"â“ Dotaz: {query}\")\n",
    "    \n",
    "    # VyhledÃ¡nÃ­ relevantnÃ­ch dokumentÅ¯\n",
    "    results = rag_system.search(query, n_results=2)\n",
    "    \n",
    "    if results['documents'][0]:\n",
    "        # GenerovÃ¡nÃ­ odpovÄ›di\n",
    "        answer = rag_system.generate_answer(query, results['documents'][0])\n",
    "        print(f\"ğŸ’¡ OdpovÄ›Ä: {answer}\")\n",
    "    else:\n",
    "        print(\"âŒ Nenalezeny Å¾Ã¡dnÃ© relevantnÃ­ materiÃ¡ly\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gradio_interface"
   },
   "source": [
    "## 4. VytvoÅ™enÃ­ interaktivnÃ­ho rozhranÃ­ s Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gradio_app"
   },
   "outputs": [],
   "source": [
    "# KompletnÃ­ Gradio aplikace pro AI StudijnÃ­ho Asistenta\n",
    "import gradio as gr\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class StudyAssistantApp:\n",
    "    def __init__(self):\n",
    "        self.assistant = StudyAssistantBot()\n",
    "        self.rag_system = StudyRAGSystem()\n",
    "        self.study_history = []\n",
    "        self.current_quiz = None\n",
    "        \n",
    "    def chat_interface(self, message, history):\n",
    "        \"\"\"ChatovacÃ­ rozhranÃ­\"\"\"\n",
    "        # ZÃ­skÃ¡nÃ­ odpovÄ›di od asistenta\n",
    "        response = self.assistant.generate_response(message)\n",
    "        \n",
    "        # UloÅ¾enÃ­ do historie\n",
    "        self.study_history.append({\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'question': message,\n",
    "            'answer': response\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def rag_search(self, query):\n",
    "        \"\"\"RAG vyhledÃ¡vÃ¡nÃ­\"\"\"\n",
    "        results = self.rag_system.search(query)\n",
    "        \n",
    "        if results['documents'][0]:\n",
    "            answer = self.rag_system.generate_answer(query, results['documents'][0])\n",
    "            sources = \"\\n\\nğŸ“š Zdroje:\\n\" + \"\\n\".join([f\"- {doc[:100]}...\" for doc in results['documents'][0]])\n",
    "            return answer + sources\n",
    "        else:\n",
    "            return \"Nenalezeny Å¾Ã¡dnÃ© relevantnÃ­ materiÃ¡ly. Zkuste pÅ™eformulovat dotaz.\"\n",
    "    \n",
    "    def generate_quiz(self, topic, difficulty):\n",
    "        \"\"\"GenerovÃ¡nÃ­ kvÃ­zu\"\"\"\n",
    "        # GenerovÃ¡nÃ­ otÃ¡zek podle obtÃ­Å¾nosti\n",
    "        num_questions = {\"LehkÃ¡\": 3, \"StÅ™ednÃ­\": 5, \"TÄ›Å¾kÃ¡\": 7}[difficulty]\n",
    "        \n",
    "        quiz_questions = []\n",
    "        for i in range(num_questions):\n",
    "            q = self.assistant.generate_quiz_question(topic)\n",
    "            quiz_questions.append(q)\n",
    "        \n",
    "        self.current_quiz = {\n",
    "            'topic': topic,\n",
    "            'difficulty': difficulty,\n",
    "            'questions': quiz_questions,\n",
    "            'user_answers': [],\n",
    "            'start_time': datetime.now()\n",
    "        }\n",
    "        \n",
    "        # FormÃ¡tovÃ¡nÃ­ kvÃ­zu pro zobrazenÃ­\n",
    "        quiz_text = f\"ğŸ“ **KvÃ­z: {topic}** (ObtÃ­Å¾nost: {difficulty})\\n\\n\"\n",
    "        \n",
    "        for i, q in enumerate(quiz_questions, 1):\n",
    "            quiz_text += f\"**OtÃ¡zka {i}:** {q['question']}\\n\"\n",
    "            for option in q['options']:\n",
    "                quiz_text += f\"  {option}\\n\"\n",
    "            quiz_text += \"\\n\"\n",
    "        \n",
    "        return quiz_text\n",
    "    \n",
    "    def submit_quiz(self, answers):\n",
    "        \"\"\"VyhodnocenÃ­ kvÃ­zu\"\"\"\n",
    "        if not self.current_quiz:\n",
    "            return \"Nejprve vygenerujte kvÃ­z!\"\n",
    "        \n",
    "        # ParsovÃ¡nÃ­ odpovÄ›dÃ­\n",
    "        user_answers = answers.strip().split(',')\n",
    "        correct_count = 0\n",
    "        \n",
    "        results = f\"ğŸ“Š **VÃ½sledky kvÃ­zu**\\n\\n\"\n",
    "        \n",
    "        for i, (question, user_answer) in enumerate(zip(self.current_quiz['questions'], user_answers)):\n",
    "            user_answer = user_answer.strip().lower()\n",
    "            is_correct = user_answer == question['correct']\n",
    "            \n",
    "            if is_correct:\n",
    "                correct_count += 1\n",
    "                results += f\"âœ… OtÃ¡zka {i+1}: SprÃ¡vnÄ›!\\n\"\n",
    "            else:\n",
    "                results += f\"âŒ OtÃ¡zka {i+1}: Å patnÄ› (sprÃ¡vnÃ¡ odpovÄ›Ä: {question['correct']})\\n\"\n",
    "        \n",
    "        # CelkovÃ© hodnocenÃ­\n",
    "        total = len(self.current_quiz['questions'])\n",
    "        percentage = (correct_count / total) * 100\n",
    "        \n",
    "        results += f\"\\n**CelkovÃ© skÃ³re: {correct_count}/{total} ({percentage:.0f}%)**\\n\"\n",
    "        \n",
    "        # Aktualizace statistik\n",
    "        self.assistant.study_context['questions_asked'] += total\n",
    "        self.assistant.study_context['correct_answers'] += correct_count\n",
    "        \n",
    "        # DoporuÄenÃ­\n",
    "        if percentage >= 80:\n",
    "            results += \"\\nğŸ‰ VÃ½bornÄ›! PokraÄujte na dalÅ¡Ã­ tÃ©ma.\"\n",
    "        elif percentage >= 60:\n",
    "            results += \"\\nğŸ‘ DobÅ™e! JeÅ¡tÄ› trochu procviÄit problematickÃ© oblasti.\"\n",
    "        else:\n",
    "            results += \"\\nğŸ“š DoporuÄuji znovu prostudovat toto tÃ©ma.\"\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def add_study_material(self, file):\n",
    "        \"\"\"PÅ™idÃ¡nÃ­ studijnÃ­ho materiÃ¡lu\"\"\"\n",
    "        if file is None:\n",
    "            return \"ProsÃ­m nahrajte soubor.\"\n",
    "        \n",
    "        try:\n",
    "            # ÄŒtenÃ­ souboru\n",
    "            content = file.read().decode('utf-8')\n",
    "            \n",
    "            # PÅ™idÃ¡nÃ­ do RAG systÃ©mu\n",
    "            self.rag_system.add_study_material(content)\n",
    "            \n",
    "            return f\"âœ… MateriÃ¡l ÃºspÄ›Å¡nÄ› pÅ™idÃ¡n! DÃ©lka: {len(content)} znakÅ¯\"\n",
    "        except Exception as e:\n",
    "            return f\"âŒ Chyba pÅ™i zpracovÃ¡nÃ­ souboru: {str(e)}\"\n",
    "    \n",
    "    def get_study_progress(self):\n",
    "        \"\"\"ZÃ­skÃ¡nÃ­ studijnÃ­ho pokroku\"\"\"\n",
    "        return self.assistant.get_study_summary()\n",
    "\n",
    "# VytvoÅ™enÃ­ aplikace\n",
    "app = StudyAssistantApp()\n",
    "\n",
    "# VytvoÅ™enÃ­ Gradio interface\n",
    "with gr.Blocks(title=\"AI StudijnÃ­ Asistent\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # ğŸ“ AI StudijnÃ­ Asistent\n",
    "    \n",
    "    VÃ¡Å¡ osobnÃ­ AI asistent pro efektivnÃ­ uÄenÃ­!\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        # Tab 1: Chat\n",
    "        with gr.Tab(\"ğŸ’¬ Chat s Asistentem\"):\n",
    "            chatbot = gr.ChatInterface(\n",
    "                fn=app.chat_interface,\n",
    "                title=\"Zeptejte se na cokoliv!\",\n",
    "                examples=[\n",
    "                    \"Co je to neuronovÃ¡ sÃ­Å¥?\",\n",
    "                    \"Jak se uÄit efektivnÄ›?\",\n",
    "                    \"VysvÄ›tli mi gradient descent\",\n",
    "                    \"JakÃ½ je rozdÃ­l mezi AI a ML?\"\n",
    "                ],\n",
    "                retry_btn=\"ğŸ”„ Zkusit znovu\",\n",
    "                undo_btn=\"â†©ï¸ VrÃ¡tit\",\n",
    "                clear_btn=\"ğŸ—‘ï¸ Vymazat\"\n",
    "            )\n",
    "        \n",
    "        # Tab 2: RAG VyhledÃ¡vÃ¡nÃ­\n",
    "        with gr.Tab(\"ğŸ” VyhledÃ¡vÃ¡nÃ­ v materiÃ¡lech\"):\n",
    "            with gr.Row():\n",
    "                search_input = gr.Textbox(\n",
    "                    label=\"Zadejte dotaz\",\n",
    "                    placeholder=\"NapÅ™. 'Jak funguje backpropagation?'\",\n",
    "                    lines=2\n",
    "                )\n",
    "                search_btn = gr.Button(\"ğŸ” Vyhledat\", variant=\"primary\")\n",
    "            \n",
    "            search_output = gr.Textbox(\n",
    "                label=\"VÃ½sledky vyhledÃ¡vÃ¡nÃ­\",\n",
    "                lines=10,\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            search_btn.click(\n",
    "                fn=app.rag_search,\n",
    "                inputs=search_input,\n",
    "                outputs=search_output\n",
    "            )\n",
    "        \n",
    "        # Tab 3: KvÃ­zy\n",
    "        with gr.Tab(\"ğŸ“ KvÃ­zy a testy\"):\n",
    "            with gr.Row():\n",
    "                quiz_topic = gr.Textbox(\n",
    "                    label=\"TÃ©ma kvÃ­zu\",\n",
    "                    placeholder=\"NapÅ™. 'NeuronovÃ© sÃ­tÄ›'\"\n",
    "                )\n",
    "                quiz_difficulty = gr.Radio(\n",
    "                    [\"LehkÃ¡\", \"StÅ™ednÃ­\", \"TÄ›Å¾kÃ¡\"],\n",
    "                    label=\"ObtÃ­Å¾nost\",\n",
    "                    value=\"StÅ™ednÃ­\"\n",
    "                )\n",
    "                generate_quiz_btn = gr.Button(\"ğŸ² Generovat kvÃ­z\", variant=\"primary\")\n",
    "            \n",
    "            quiz_display = gr.Textbox(\n",
    "                label=\"KvÃ­z\",\n",
    "                lines=15,\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                quiz_answers = gr.Textbox(\n",
    "                    label=\"VaÅ¡e odpovÄ›di (oddÄ›lenÃ© ÄÃ¡rkou)\",\n",
    "                    placeholder=\"a, b, c, d, a\"\n",
    "                )\n",
    "                submit_quiz_btn = gr.Button(\"ğŸ“Š Vyhodnotit\", variant=\"secondary\")\n",
    "            \n",
    "            quiz_results = gr.Textbox(\n",
    "                label=\"VÃ½sledky\",\n",
    "                lines=10,\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            generate_quiz_btn.click(\n",
    "                fn=app.generate_quiz,\n",
    "                inputs=[quiz_topic, quiz_difficulty],\n",
    "                outputs=quiz_display\n",
    "            )\n",
    "            \n",
    "            submit_quiz_btn.click(\n",
    "                fn=app.submit_quiz,\n",
    "                inputs=quiz_answers,\n",
    "                outputs=quiz_results\n",
    "            )\n",
    "        \n",
    "        # Tab 4: SprÃ¡va materiÃ¡lÅ¯\n",
    "        with gr.Tab(\"ğŸ“š SprÃ¡va materiÃ¡lÅ¯\"):\n",
    "            gr.Markdown(\"### Nahrajte studijnÃ­ materiÃ¡ly\")\n",
    "            \n",
    "            file_upload = gr.File(\n",
    "                label=\"Vyberte textovÃ½ soubor\",\n",
    "                file_types=[\".txt\", \".md\"],\n",
    "                type=\"binary\"\n",
    "            )\n",
    "            \n",
    "            upload_btn = gr.Button(\"ğŸ“¤ NahrÃ¡t materiÃ¡l\", variant=\"primary\")\n",
    "            upload_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "            \n",
    "            upload_btn.click(\n",
    "                fn=app.add_study_material,\n",
    "                inputs=file_upload,\n",
    "                outputs=upload_status\n",
    "            )\n",
    "        \n",
    "        # Tab 5: Pokrok\n",
    "        with gr.Tab(\"ğŸ“Š MÅ¯j pokrok\"):\n",
    "            refresh_btn = gr.Button(\"ğŸ”„ Aktualizovat\", variant=\"primary\")\n",
    "            progress_display = gr.Textbox(\n",
    "                label=\"StudijnÃ­ pokrok\",\n",
    "                lines=15,\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            refresh_btn.click(\n",
    "                fn=app.get_study_progress,\n",
    "                outputs=progress_display\n",
    "            )\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    \n",
    "    ### ğŸš€ Tipy pro efektivnÃ­ studium:\n",
    "    - Ptejte se na konkrÃ©tnÃ­ otÃ¡zky\n",
    "    - ProcviÄujte pomocÃ­ kvÃ­zÅ¯\n",
    "    - Nahrajte vlastnÃ­ studijnÃ­ materiÃ¡ly\n",
    "    - Sledujte svÅ¯j pokrok\n",
    "    \n",
    "    VytvoÅ™eno s â¤ï¸ pomocÃ­ AI\n",
    "    \"\"\")\n",
    "\n",
    "# SpuÅ¡tÄ›nÃ­ aplikace\n",
    "print(\"\\nğŸš€ SpouÅ¡tÃ­m AI StudijnÃ­ho Asistenta...\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ollama_integration"
   },
   "source": [
    "## 5. Integrace s Ollama pro lokÃ¡lnÃ­ deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ollama_setup"
   },
   "outputs": [],
   "source": [
    "# Skript pro lokÃ¡lnÃ­ deployment s Ollama\n",
    "import subprocess\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class OllamaStudyAssistant:\n",
    "    def __init__(self, model=\"llama2\"):\n",
    "        self.model = model\n",
    "        self.base_url = \"http://localhost:11434\"\n",
    "        \n",
    "    def check_ollama_status(self):\n",
    "        \"\"\"Kontrola, zda Ollama bÄ›Å¾Ã­\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
    "            if response.status_code == 200:\n",
    "                print(\"âœ… Ollama server bÄ›Å¾Ã­\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"âŒ Ollama server neodpovÃ­dÃ¡\")\n",
    "                return False\n",
    "        except:\n",
    "            print(\"âŒ Nelze se pÅ™ipojit k Ollama serveru\")\n",
    "            return False\n",
    "    \n",
    "    def list_models(self):\n",
    "        \"\"\"Seznam dostupnÃ½ch modelÅ¯\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
    "            if response.status_code == 200:\n",
    "                models = response.json().get('models', [])\n",
    "                print(\"ğŸ“‹ DostupnÃ© modely:\")\n",
    "                for model in models:\n",
    "                    print(f\"  - {model['name']} ({model['size']} bytes)\")\n",
    "                return models\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"Chyba: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def generate(self, prompt, context=\"\"):\n",
    "        \"\"\"GenerovÃ¡nÃ­ odpovÄ›di pomocÃ­ Ollama\"\"\"\n",
    "        try:\n",
    "            data = {\n",
    "                \"model\": self.model,\n",
    "                \"prompt\": f\"{context}\\n\\n{prompt}\",\n",
    "                \"stream\": False\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/api/generate\",\n",
    "                json=data\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()['response']\n",
    "            else:\n",
    "                return f\"Chyba: {response.status_code}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Chyba pÅ™i generovÃ¡nÃ­: {e}\"\n",
    "    \n",
    "    def create_study_prompt(self, question, subject):\n",
    "        \"\"\"VytvoÅ™enÃ­ promptu pro studijnÃ­ho asistenta\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Jsi AI studijnÃ­ asistent specializovanÃ½ na pÅ™edmÄ›t: {subject}.\n",
    "        \n",
    "        TvÃ½m Ãºkolem je:\n",
    "        1. OdpovÃ­dat jasnÄ› a srozumitelnÄ›\n",
    "        2. PouÅ¾Ã­vat pÅ™Ã­klady\n",
    "        3. Strukturovat odpovÄ›di\n",
    "        4. BÃ½t trpÄ›livÃ½ a nÃ¡pomocnÃ½\n",
    "        \n",
    "        OtÃ¡zka studenta: {question}\n",
    "        \n",
    "        OdpovÄ›Ä:\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "# VytvoÅ™enÃ­ deployment skriptu\n",
    "deployment_script = '''\n",
    "#!/bin/bash\n",
    "\n",
    "# AI StudijnÃ­ Asistent - Deployment Script\n",
    "\n",
    "echo \"ğŸš€ Instalace AI StudijnÃ­ho Asistenta\"\n",
    "\n",
    "# 1. Kontrola Ollama\n",
    "if ! command -v ollama &> /dev/null; then\n",
    "    echo \"ğŸ“¥ Instaluji Ollama...\"\n",
    "    curl -fsSL https://ollama.ai/install.sh | sh\n",
    "fi\n",
    "\n",
    "# 2. StaÅ¾enÃ­ modelu\n",
    "echo \"ğŸ“¥ Stahuji model llama2...\"\n",
    "ollama pull llama2\n",
    "\n",
    "# 3. SpuÅ¡tÄ›nÃ­ Ollama serveru\n",
    "echo \"ğŸ–¥ï¸ SpouÅ¡tÃ­m Ollama server...\"\n",
    "ollama serve &\n",
    "\n",
    "# 4. VytvoÅ™enÃ­ Python prostÅ™edÃ­\n",
    "echo \"ğŸ VytvÃ¡Å™Ã­m Python prostÅ™edÃ­...\"\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "\n",
    "# 5. Instalace zÃ¡vislostÃ­\n",
    "echo \"ğŸ“¦ Instaluji zÃ¡vislosti...\"\n",
    "pip install gradio transformers torch ollama chromadb sentence-transformers\n",
    "\n",
    "# 6. SpuÅ¡tÄ›nÃ­ aplikace\n",
    "echo \"ğŸ“ SpouÅ¡tÃ­m AI StudijnÃ­ho Asistenta...\"\n",
    "python study_assistant.py\n",
    "'''\n",
    "\n",
    "# UloÅ¾enÃ­ deployment skriptu\n",
    "with open('deploy_assistant.sh', 'w') as f:\n",
    "    f.write(deployment_script)\n",
    "\n",
    "print(\"ğŸ“„ Deployment skript vytvoÅ™en: deploy_assistant.sh\")\n",
    "\n",
    "# Test Ollama (pokud je dostupnÃ¡)\n",
    "print(\"\\nğŸ” Test Ollama integrace:\")\n",
    "ollama_assistant = OllamaStudyAssistant()\n",
    "\n",
    "if ollama_assistant.check_ollama_status():\n",
    "    ollama_assistant.list_models()\n",
    "    \n",
    "    # Test generovÃ¡nÃ­\n",
    "    test_prompt = ollama_assistant.create_study_prompt(\n",
    "        \"Co je to gradient descent?\",\n",
    "        \"StrojovÃ© uÄenÃ­\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ¤– TestovacÃ­ odpovÄ›Ä:\")\n",
    "    # response = ollama_assistant.generate(test_prompt)\n",
    "    # print(response)\n",
    "else:\n",
    "    print(\"\\nğŸ’¡ Pro lokÃ¡lnÃ­ deployment:\")\n",
    "    print(\"1. Nainstalujte Ollama: https://ollama.ai\")\n",
    "    print(\"2. StÃ¡hnÄ›te model: ollama pull llama2\")\n",
    "    print(\"3. SpusÅ¥te server: ollama serve\")\n",
    "    print(\"4. SpusÅ¥te skript: bash deploy_assistant.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_summary"
   },
   "source": [
    "## 6. ShrnutÃ­ projektu a dalÅ¡Ã­ kroky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "project_documentation"
   },
   "outputs": [],
   "source": [
    "# VytvoÅ™enÃ­ dokumentace projektu\n",
    "project_documentation = \"\"\"\n",
    "# ğŸ“ AI StudijnÃ­ Asistent - Dokumentace\n",
    "\n",
    "## ğŸ“‹ PÅ™ehled projektu\n",
    "\n",
    "AI StudijnÃ­ Asistent je komplexnÃ­ aplikace vyuÅ¾Ã­vajÃ­cÃ­ nejmodernÄ›jÅ¡Ã­ technologie \n",
    "umÄ›lÃ© inteligence pro podporu studentÅ¯ pÅ™i uÄenÃ­.\n",
    "\n",
    "## ğŸ› ï¸ Technologie\n",
    "\n",
    "- **Transformers**: Hugging Face modely pro NLP\n",
    "- **Gradio**: InteraktivnÃ­ webovÃ© rozhranÃ­\n",
    "- **ChromaDB**: VektorovÃ¡ databÃ¡ze pro RAG\n",
    "- **Ollama**: LokÃ¡lnÃ­ deployment LLM\n",
    "- **PyTorch**: Deep learning framework\n",
    "\n",
    "## ğŸš€ Funkce\n",
    "\n",
    "1. **Chatbot**: KonverzaÄnÃ­ asistent pro zodpovÃ­dÃ¡nÃ­ otÃ¡zek\n",
    "2. **RAG systÃ©m**: VyhledÃ¡vÃ¡nÃ­ v studijnÃ­ch materiÃ¡lech\n",
    "3. **GenerÃ¡tor kvÃ­zÅ¯**: AutomatickÃ© vytvÃ¡Å™enÃ­ testÅ¯\n",
    "4. **SledovÃ¡nÃ­ pokroku**: Statistiky a analÃ½zy uÄenÃ­\n",
    "5. **SprÃ¡va materiÃ¡lÅ¯**: Upload a organizace studijnÃ­ch zdrojÅ¯\n",
    "\n",
    "## ğŸ“¦ Instalace\n",
    "\n",
    "```bash\n",
    "# KlonovÃ¡nÃ­ repozitÃ¡Å™e\n",
    "git clone https://github.com/your-username/ai-study-assistant.git\n",
    "cd ai-study-assistant\n",
    "\n",
    "# Instalace zÃ¡vislostÃ­\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# SpuÅ¡tÄ›nÃ­ aplikace\n",
    "python app.py\n",
    "```\n",
    "\n",
    "## ğŸ¯ PouÅ¾itÃ­\n",
    "\n",
    "1. SpusÅ¥te aplikaci\n",
    "2. OtevÅ™ete webovÃ½ prohlÃ­Å¾eÄ na http://localhost:7860\n",
    "3. ZaÄnÄ›te chatovat s asistentem\n",
    "4. Nahrajte studijnÃ­ materiÃ¡ly\n",
    "5. Generujte kvÃ­zy a sledujte pokrok\n",
    "\n",
    "## ğŸ”§ Konfigurace\n",
    "\n",
    "Upravte `config.yaml` pro:\n",
    "- VÃ½bÄ›r modelu\n",
    "- NastavenÃ­ RAG parametrÅ¯\n",
    "- UI pÅ™izpÅ¯sobenÃ­\n",
    "\n",
    "## ğŸ“ˆ BudoucÃ­ vylepÅ¡enÃ­\n",
    "\n",
    "- [ ] Podpora vÃ­ce jazykÅ¯\n",
    "- [ ] HlasovÃ© ovlÃ¡dÃ¡nÃ­\n",
    "- [ ] Export studijnÃ­ch materiÃ¡lÅ¯\n",
    "- [ ] MobilnÃ­ aplikace\n",
    "- [ ] Integrace s LMS systÃ©my\n",
    "\n",
    "## ğŸ‘¥ PÅ™ispÃ­vÃ¡nÃ­\n",
    "\n",
    "PÅ™Ã­spÄ›vky jsou vÃ­tÃ¡ny! ProsÃ­m:\n",
    "1. ForknÄ›te repozitÃ¡Å™\n",
    "2. VytvoÅ™te feature branch\n",
    "3. Commitujte zmÄ›ny\n",
    "4. PushnÄ›te branch\n",
    "5. OtevÅ™ete Pull Request\n",
    "\n",
    "## ğŸ“„ Licence\n",
    "\n",
    "MIT License - volnÄ› k pouÅ¾itÃ­ pro vzdÄ›lÃ¡vacÃ­ ÃºÄely\n",
    "\n",
    "## ğŸ™ PodÄ›kovÃ¡nÃ­\n",
    "\n",
    "- Hugging Face za transformery\n",
    "- Gradio tÃ½m za skvÄ›lÃ© UI\n",
    "- Ollama za lokÃ¡lnÃ­ LLM\n",
    "- VÅ¡em pÅ™ispÄ›vatelÅ¯m\n",
    "\"\"\"\n",
    "\n",
    "# UloÅ¾enÃ­ dokumentace\n",
    "with open('README.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(project_documentation)\n",
    "\n",
    "print(\"ğŸ“„ Dokumentace vytvoÅ™ena: README.md\")\n",
    "\n",
    "# VytvoÅ™enÃ­ requirements.txt\n",
    "requirements = \"\"\"\n",
    "transformers>=4.30.0\n",
    "torch>=2.0.0\n",
    "gradio>=3.35.0\n",
    "chromadb>=0.4.0\n",
    "sentence-transformers>=2.2.0\n",
    "langchain>=0.0.200\n",
    "ollama>=0.1.0\n",
    "pandas>=2.0.0\n",
    "numpy>=1.24.0\n",
    "matplotlib>=3.7.0\n",
    "plotly>=5.14.0\n",
    "\"\"\"\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(\"ğŸ“¦ Requirements vytvoÅ™eny: requirements.txt\")\n",
    "\n",
    "# FinÃ¡lnÃ­ shrnutÃ­\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ PROJEKT ÃšSPÄšÅ NÄš DOKONÄŒEN!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nğŸ“Š Statistiky projektu:\")\n",
    "print(\"  - Komponenty: 7\")\n",
    "print(\"  - Technologie: 6\")\n",
    "print(\"  - Å˜Ã¡dky kÃ³du: ~1000\")\n",
    "print(\"  - Funkce: Chat, RAG, KvÃ­zy, Progress tracking\")\n",
    "print(\"\\nğŸš€ DalÅ¡Ã­ kroky:\")\n",
    "print(\"  1. Otestovat s reÃ¡lnÃ½mi studenty\")\n",
    "print(\"  2. VylepÅ¡it UI/UX\")\n",
    "print(\"  3. PÅ™idat vÃ­ce modelÅ¯\")\n",
    "print(\"  4. Implementovat mobilnÃ­ verzi\")\n",
    "print(\"  5. Integrovat s uÄebnÃ­mi platformami\")\n",
    "print(\"\\nğŸ’¡ Tip: Zkuste aplikaci rozÅ¡Ã­Å™it o vlastnÃ­ funkce!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercises"
   },
   "source": [
    "## 7. CviÄenÃ­ a Ãºkoly\n",
    "\n",
    "### Ãškol 1: RozÅ¡Ã­Å™enÃ­ funkcionalit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise_extension"
   },
   "outputs": [],
   "source": [
    "# Ãškol: PÅ™idejte novou funkci do AI asistenta\n",
    "class StudyPlannerExtension:\n",
    "    def __init__(self):\n",
    "        self.study_plans = {}\n",
    "        \n",
    "    def create_study_plan(self, subject, available_hours, deadline):\n",
    "        \"\"\"\n",
    "        TODO: Implementujte vytvÃ¡Å™enÃ­ studijnÃ­ho plÃ¡nu\n",
    "        - RozdÄ›lte tÃ©ma na menÅ¡Ã­ ÄÃ¡sti\n",
    "        - Alokujte Äas pro kaÅ¾dou ÄÃ¡st\n",
    "        - VytvoÅ™te harmonogram\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def track_progress(self, plan_id, completed_section):\n",
    "        \"\"\"\n",
    "        TODO: Sledujte pokrok ve studijnÃ­m plÃ¡nu\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_recommendations(self, student_performance):\n",
    "        \"\"\"\n",
    "        TODO: Generujte personalizovanÃ¡ doporuÄenÃ­\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# Implementujte rozÅ¡Ã­Å™enÃ­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## 8. ShrnutÃ­\n",
    "\n",
    "### Co jsme vytvoÅ™ili:\n",
    "- âœ… KompletnÃ­ AI studijnÃ­ asistent\n",
    "- âœ… Chatbot s transformery\n",
    "- âœ… RAG systÃ©m pro pÅ™esnÃ© odpovÄ›di\n",
    "- âœ… GenerÃ¡tor kvÃ­zÅ¯\n",
    "- âœ… InteraktivnÃ­ Gradio rozhranÃ­\n",
    "- âœ… Integrace s Ollama\n",
    "\n",
    "### NauÄenÃ© dovednosti:\n",
    "1. **PlÃ¡novÃ¡nÃ­ AI projektu**\n",
    "2. **PrÃ¡ce s transformery**\n",
    "3. **Implementace RAG**\n",
    "4. **VytvÃ¡Å™enÃ­ UI s Gradio**\n",
    "5. **Deployment s Ollama**\n",
    "\n",
    "### PÅ™Ã­Å¡tÄ›:\n",
    "V dalÅ¡Ã­ hodinÄ› shrneme vÅ¡e, co jsme se nauÄili!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "homework"
   },
   "source": [
    "## 9. DomÃ¡cÃ­ Ãºkol\n",
    "\n",
    "1. **VylepÅ¡ete chatbota**:\n",
    "   - PÅ™idejte podporu pro vÃ­ce pÅ™edmÄ›tÅ¯\n",
    "   - Implementujte pamÄ›Å¥ konverzace\n",
    "   - VylepÅ¡ete generovÃ¡nÃ­ odpovÄ›dÃ­\n",
    "\n",
    "2. **RozÅ¡iÅ™te RAG systÃ©m**:\n",
    "   - PÅ™idejte podporu PDF souborÅ¯\n",
    "   - Implementujte hodnocenÃ­ relevance\n",
    "   - VytvoÅ™te vizualizaci vÃ½sledkÅ¯\n",
    "\n",
    "3. **VytvoÅ™te mobilnÃ­ verzi**:\n",
    "   - PouÅ¾ijte Gradio mobile support\n",
    "   - Optimalizujte UI pro mobily\n",
    "   - PÅ™idejte offline podporu\n",
    "\n",
    "4. **NapiÅ¡te dokumentaci**:\n",
    "   - UÅ¾ivatelskÃ½ manuÃ¡l\n",
    "   - API dokumentace\n",
    "   - InstalaÄnÃ­ video nÃ¡vod\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ† VÃ½zva**: Publikujte vÃ¡Å¡ projekt na GitHub a sdÃ­lejte s komunitou!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hodina 9 â€” Mini projekt: krÃ¡tkÃ© shrnutÃ­ (ELI10)\n",
    "\n",
    "Dnes si vybereme jednoduchÃ½ problÃ©m a vytvoÅ™Ã­me malÃ½ prototyp. Projekt by mÄ›l bÃ½t dost malÃ½, aby ho bylo moÅ¾nÃ© dokonÄit bÄ›hem jednÃ© nebo dvou hodin. DoporuÄenÃ­: klasifikace malÃ©ho datasetu (napÅ™. Iris) s jednoduchÃ½m uÅ¾ivatelskÃ½m rozhranÃ­m pÅ™es Gradio, nebo hra, kterou ovlÃ¡dÃ¡ jednoduchÃ½ algoritmus.\n",
    "\n",
    "NÃ­Å¾e je krÃ¡tkÃ¡ kostra projektu, kterou mÅ¯Å¾ete zkopÃ­rovat a upravit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-project scaffold: Iris classifier (very small prototype)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print('Accuracy on Iris test set:', acc)\n",
    "assert acc >= 0.8  # simple sanity check â€” many runs will satisfy this\n",
    "\n",
    "# Next steps: wrap `clf.predict` into a Gradio interface or save the model for use in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ãškoly pro mini projekt:\n",
    "\n",
    "1) Zvolte problÃ©m (klasifikace, jednoduchÃ¡ hra nebo detekce) a napiÅ¡te krÃ¡tkÃ½ popis cÃ­le projektu.\n",
    "2) Implementujte prototyp (pÅ™. Iris classifier nebo jednoduchÃ© Gradio UI pro hru).\n",
    "3) PÅ™ipravte krÃ¡tkou prezentaci (2â€“3 slidy nebo 5 minut), kde vysvÄ›tlÃ­te, jak problÃ©m Å™eÅ¡Ã­te a jakÃ© metody jste pouÅ¾ili.\n",
    "4) VolitelnÄ›: nasdÃ­lejte Gradio demo online pro snadnÃ© testovÃ¡nÃ­ ostatnÃ­mi."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
