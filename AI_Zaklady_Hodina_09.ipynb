{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Hodina 9: Mini projekt - N√°vrh jednoduch√©ho projektu s AI\n",
    "\n",
    "## Obsah hodiny\n",
    "- Pl√°nov√°n√≠ AI projektu\n",
    "- V√Ωbƒõr vhodn√Ωch n√°stroj≈Ø\n",
    "- Implementace chatbota s transformery\n",
    "- Vytvo≈ôen√≠ AI asistenta pro studenty\n",
    "- Deployment s Gradio a Ollama\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Instalace pot≈ôebn√Ωch knihoven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Instalace knihoven pro projekt\n",
    "!pip install transformers torch gradio datasets ollama huggingface_hub -q\n",
    "!pip install langchain chromadb sentence-transformers -q\n",
    "!pip install streamlit plotly pandas -q\n",
    "\n",
    "import torch\n",
    "import gradio as gr\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ Knihovny nainstalov√°ny!\")\n",
    "print(f\"PyTorch verze: {torch.__version__}\")\n",
    "print(f\"CUDA dostupn√°: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_planning"
   },
   "source": [
    "## 1. Pl√°nov√°n√≠ projektu\n",
    "\n",
    "### üéØ C√≠l projektu: AI Studijn√≠ Asistent\n",
    "\n",
    "Vytvo≈ô√≠me inteligentn√≠ho asistenta, kter√Ω pom≈Ø≈æe student≈Øm s uƒçen√≠m:\n",
    "- üìö Odpov√≠d√°n√≠ na ot√°zky\n",
    "- üìù Generov√°n√≠ studijn√≠ch materi√°l≈Ø\n",
    "- üß† Vytv√°≈ôen√≠ kv√≠z≈Ø\n",
    "- üìä Sledov√°n√≠ pokroku\n",
    "- üí¨ Konverzaƒçn√≠ rozhran√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "project_structure"
   },
   "outputs": [],
   "source": [
    "# Definice struktury projektu\n",
    "class ProjectPlanner:\n",
    "    def __init__(self, project_name):\n",
    "        self.project_name = project_name\n",
    "        self.components = []\n",
    "        self.timeline = []\n",
    "        self.tech_stack = []\n",
    "        \n",
    "    def add_component(self, name, description, priority):\n",
    "        self.components.append({\n",
    "            'name': name,\n",
    "            'description': description,\n",
    "            'priority': priority,\n",
    "            'status': 'planned'\n",
    "        })\n",
    "    \n",
    "    def add_tech(self, technology, purpose):\n",
    "        self.tech_stack.append({\n",
    "            'technology': technology,\n",
    "            'purpose': purpose\n",
    "        })\n",
    "    \n",
    "    def visualize_plan(self):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Graf 1: Komponenty podle priority\n",
    "        components_df = pd.DataFrame(self.components)\n",
    "        priority_counts = components_df['priority'].value_counts()\n",
    "        \n",
    "        colors = {'vysok√°': '#FF6B6B', 'st≈ôedn√≠': '#4ECDC4', 'n√≠zk√°': '#45B7D1'}\n",
    "        pie_colors = [colors[p] for p in priority_counts.index]\n",
    "        \n",
    "        ax1.pie(priority_counts.values, labels=priority_counts.index, \n",
    "                colors=pie_colors, autopct='%1.0f%%', startangle=90)\n",
    "        ax1.set_title('Komponenty podle priority', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Graf 2: Technologick√Ω stack\n",
    "        tech_names = [t['technology'] for t in self.tech_stack]\n",
    "        y_positions = np.arange(len(tech_names))\n",
    "        \n",
    "        ax2.barh(y_positions, [1]*len(tech_names), color='#96CEB4')\n",
    "        ax2.set_yticks(y_positions)\n",
    "        ax2.set_yticklabels(tech_names)\n",
    "        ax2.set_xlabel('Vyu≈æit√≠ v projektu')\n",
    "        ax2.set_title('Technologick√Ω stack', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlim(0, 1.2)\n",
    "        \n",
    "        # P≈ôid√°n√≠ √∫ƒçelu technologi√≠\n",
    "        for i, tech in enumerate(self.tech_stack):\n",
    "            ax2.text(0.02, i, tech['purpose'], va='center', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Vytvo≈ôen√≠ pl√°nu projektu\n",
    "planner = ProjectPlanner(\"AI Studijn√≠ Asistent\")\n",
    "\n",
    "# P≈ôid√°n√≠ komponent\n",
    "planner.add_component(\"Chatbot Interface\", \"Konverzaƒçn√≠ rozhran√≠ pro studenty\", \"vysok√°\")\n",
    "planner.add_component(\"Question Answering\", \"Odpov√≠d√°n√≠ na studijn√≠ ot√°zky\", \"vysok√°\")\n",
    "planner.add_component(\"Study Material Generator\", \"Generov√°n√≠ pozn√°mek a shrnut√≠\", \"vysok√°\")\n",
    "planner.add_component(\"Quiz Creator\", \"Automatick√© vytv√°≈ôen√≠ test≈Ø\", \"st≈ôedn√≠\")\n",
    "planner.add_component(\"Progress Tracker\", \"Sledov√°n√≠ pokroku studenta\", \"st≈ôedn√≠\")\n",
    "planner.add_component(\"Voice Assistant\", \"Hlasov√© ovl√°d√°n√≠\", \"n√≠zk√°\")\n",
    "planner.add_component(\"PDF Analyzer\", \"Anal√Ωza studijn√≠ch materi√°l≈Ø\", \"st≈ôedn√≠\")\n",
    "\n",
    "# P≈ôid√°n√≠ technologi√≠\n",
    "planner.add_tech(\"Transformers (Hugging Face)\", \"NLP modely pro generov√°n√≠ textu\")\n",
    "planner.add_tech(\"Gradio\", \"Webov√© u≈æivatelsk√© rozhran√≠\")\n",
    "planner.add_tech(\"LangChain\", \"Orchestrace LLM workflows\")\n",
    "planner.add_tech(\"ChromaDB\", \"Vektorov√° datab√°ze pro RAG\")\n",
    "planner.add_tech(\"Ollama\", \"Lok√°ln√≠ LLM deployment\")\n",
    "planner.add_tech(\"PyTorch\", \"Deep learning framework\")\n",
    "\n",
    "print(\"üìã PL√ÅN PROJEKTU: AI Studijn√≠ Asistent\\n\")\n",
    "print(\"Komponenty projektu:\")\n",
    "for comp in planner.components:\n",
    "    emoji = \"üî¥\" if comp['priority'] == 'vysok√°' else \"üü°\" if comp['priority'] == 'st≈ôedn√≠' else \"üîµ\"\n",
    "    print(f\"{emoji} {comp['name']}: {comp['description']}\")\n",
    "\n",
    "print(\"\\nTehnologick√Ω stack:\")\n",
    "for tech in planner.tech_stack:\n",
    "    print(f\"  ‚Ä¢ {tech['technology']}: {tech['purpose']}\")\n",
    "\n",
    "planner.visualize_plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chatbot_implementation"
   },
   "source": [
    "## 2. Implementace AI Chatbota s Transformery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "transformer_chatbot"
   },
   "outputs": [],
   "source": [
    "# Vytvo≈ôen√≠ AI chatbota pomoc√≠ transformer≈Ø\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "class StudyAssistantBot:\n",
    "    def __init__(self, model_name=\"microsoft/DialoGPT-small\"):\n",
    "        print(f\"ü§ñ Inicializuji AI asistenta s modelem {model_name}...\")\n",
    "        \n",
    "        # Naƒçten√≠ modelu a tokenizeru\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        \n",
    "        # Nastaven√≠ pad tokenu\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Historie konverzace\n",
    "        self.conversation_history = []\n",
    "        self.chat_history_ids = None\n",
    "        \n",
    "        # Studijn√≠ kontext\n",
    "        self.study_context = {\n",
    "            'subject': None,\n",
    "            'topics': [],\n",
    "            'questions_asked': 0,\n",
    "            'correct_answers': 0\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ AI asistent p≈ôipraven!\")\n",
    "    \n",
    "    def set_study_context(self, subject, topics):\n",
    "        \"\"\"Nastaven√≠ studijn√≠ho kontextu\"\"\"\n",
    "        self.study_context['subject'] = subject\n",
    "        self.study_context['topics'] = topics\n",
    "        \n",
    "    def generate_response(self, user_input, max_length=200):\n",
    "        \"\"\"Generov√°n√≠ odpovƒõdi pomoc√≠ transformeru\"\"\"\n",
    "        # P≈ôid√°n√≠ vstupu do historie\n",
    "        self.conversation_history.append(f\"Student: {user_input}\")\n",
    "        \n",
    "        # Tokenizace vstupu\n",
    "        new_user_input_ids = self.tokenizer.encode(\n",
    "            user_input + self.tokenizer.eos_token, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # P≈ôipojen√≠ k historii chatu\n",
    "        if self.chat_history_ids is not None:\n",
    "            bot_input_ids = torch.cat([self.chat_history_ids, new_user_input_ids], dim=-1)\n",
    "        else:\n",
    "            bot_input_ids = new_user_input_ids\n",
    "        \n",
    "        # Omezen√≠ d√©lky historie\n",
    "        if bot_input_ids.shape[1] > 1000:\n",
    "            bot_input_ids = bot_input_ids[:, -1000:]\n",
    "        \n",
    "        # Generov√°n√≠ odpovƒõdi\n",
    "        with torch.no_grad():\n",
    "            chat_history_ids = self.model.generate(\n",
    "                bot_input_ids,\n",
    "                max_length=bot_input_ids.shape[1] + max_length,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                do_sample=True,\n",
    "                temperature=0.8,\n",
    "                top_p=0.9,\n",
    "                no_repeat_ngram_size=3\n",
    "            )\n",
    "        \n",
    "        # Dek√≥dov√°n√≠ odpovƒõdi\n",
    "        response = self.tokenizer.decode(\n",
    "            chat_history_ids[:, bot_input_ids.shape[-1]:][0], \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        # Aktualizace historie\n",
    "        self.chat_history_ids = chat_history_ids\n",
    "        self.conversation_history.append(f\"Asistent: {response}\")\n",
    "        \n",
    "        # P≈ôid√°n√≠ studijn√≠ho kontextu\n",
    "        if self.study_context['subject']:\n",
    "            response = self._enhance_with_study_context(user_input, response)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _enhance_with_study_context(self, question, response):\n",
    "        \"\"\"Vylep≈°en√≠ odpovƒõdi podle studijn√≠ho kontextu\"\"\"\n",
    "        # Jednoduch√° logika pro vylep≈°en√≠ odpovƒõd√≠\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        if \"co je\" in question_lower or \"vysvƒõtli\" in question_lower:\n",
    "            response += f\"\\n\\nüí° Tip: P≈ôi studiu {self.study_context['subject']} je d≈Øle≈æit√© pochopit z√°kladn√≠ koncepty.\"\n",
    "        \n",
    "        elif \"jak\" in question_lower:\n",
    "            response += \"\\n\\nüìù Doporuƒçuji si udƒõlat pozn√°mky a procviƒçit na p≈ô√≠kladech.\"\n",
    "        \n",
    "        elif \"proƒç\" in question_lower:\n",
    "            response += \"\\n\\nüîç Zkuste se zamyslet nad praktick√Ωmi aplikacemi tohoto konceptu.\"\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def generate_quiz_question(self, topic):\n",
    "        \"\"\"Generov√°n√≠ kv√≠zov√© ot√°zky\"\"\"\n",
    "        prompt = f\"Vytvo≈ô jednu ot√°zku s mo≈ænostmi a, b, c, d na t√©ma {topic}:\"\n",
    "        \n",
    "        # Simulace generov√°n√≠ ot√°zky (v re√°ln√© aplikaci by se pou≈æil specializovan√Ω model)\n",
    "        questions = [\n",
    "            {\n",
    "                \"question\": f\"Co je hlavn√≠ charakteristika {topic}?\",\n",
    "                \"options\": [\n",
    "                    \"a) Prvn√≠ mo≈ænost\",\n",
    "                    \"b) Druh√° mo≈ænost\",\n",
    "                    \"c) T≈ôet√≠ mo≈ænost\",\n",
    "                    \"d) ƒåtvrt√° mo≈ænost\"\n",
    "                ],\n",
    "                \"correct\": \"a\"\n",
    "            },\n",
    "            {\n",
    "                \"question\": f\"Kter√Ω z n√°sleduj√≠c√≠ch v√Ωrok≈Ø o {topic} je pravdiv√Ω?\",\n",
    "                \"options\": [\n",
    "                    \"a) V√Ωrok 1\",\n",
    "                    \"b) V√Ωrok 2\",\n",
    "                    \"c) V√Ωrok 3\",\n",
    "                    \"d) V√Ωrok 4\"\n",
    "                ],\n",
    "                \"correct\": \"b\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        return np.random.choice(questions)\n",
    "    \n",
    "    def get_study_summary(self):\n",
    "        \"\"\"Z√≠sk√°n√≠ shrnut√≠ studia\"\"\"\n",
    "        if self.study_context['questions_asked'] == 0:\n",
    "            return \"Zat√≠m jste nezaƒçali studovat.\"\n",
    "        \n",
    "        accuracy = (self.study_context['correct_answers'] / \n",
    "                   self.study_context['questions_asked'] * 100)\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "        üìä **Shrnut√≠ va≈°eho studia**\n",
    "        \n",
    "        P≈ôedmƒõt: {self.study_context['subject']}\n",
    "        T√©mata: {', '.join(self.study_context['topics'])}\n",
    "        Zodpovƒõzen√© ot√°zky: {self.study_context['questions_asked']}\n",
    "        Spr√°vn√© odpovƒõdi: {self.study_context['correct_answers']}\n",
    "        √öspƒõ≈°nost: {accuracy:.1f}%\n",
    "        \n",
    "        {self._get_performance_feedback(accuracy)}\n",
    "        \"\"\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _get_performance_feedback(self, accuracy):\n",
    "        \"\"\"Zpƒõtn√° vazba podle v√Ωkonu\"\"\"\n",
    "        if accuracy >= 90:\n",
    "            return \"üåü V√Ωbornƒõ! M√°te skvƒõl√© znalosti!\"\n",
    "        elif accuracy >= 70:\n",
    "            return \"üëç Dob≈ôe! Je≈°tƒõ trochu procviƒçit a budete expert!\"\n",
    "        elif accuracy >= 50:\n",
    "            return \"üìö Pr≈Ømƒõr. Doporuƒçuji v√≠ce procviƒçovat.\"\n",
    "        else:\n",
    "            return \"üí™ Nevzd√°vejte se! Ka≈æd√Ω zaƒç√≠nal od nuly.\"\n",
    "\n",
    "# Vytvo≈ôen√≠ instance asistenta\n",
    "print(\"üéì VYTV√Å≈òEN√ç AI STUDIJN√çHO ASISTENTA\\n\")\n",
    "assistant = StudyAssistantBot()\n",
    "\n",
    "# Nastaven√≠ studijn√≠ho kontextu\n",
    "assistant.set_study_context(\"Umƒõl√° inteligence\", [\"Neural Networks\", \"Machine Learning\", \"Deep Learning\"])\n",
    "\n",
    "# Test konverzace\n",
    "print(\"\\nüí¨ Uk√°zka konverzace:\\n\")\n",
    "\n",
    "test_questions = [\n",
    "    \"Ahoj, jsem student a pot≈ôebuji pomoc s uƒçen√≠m.\",\n",
    "    \"Co je to neuronov√° s√≠≈•?\",\n",
    "    \"Jak funguje machine learning?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"üë§ Student: {question}\")\n",
    "    response = assistant.generate_response(question)\n",
    "    print(f\"ü§ñ Asistent: {response}\\n\")\n",
    "\n",
    "# Generov√°n√≠ kv√≠zov√© ot√°zky\n",
    "print(\"\\nüìù Uk√°zka kv√≠zov√© ot√°zky:\")\n",
    "quiz = assistant.generate_quiz_question(\"neuronov√© s√≠tƒõ\")\n",
    "print(f\"\\nOt√°zka: {quiz['question']}\")\n",
    "for option in quiz['options']:\n",
    "    print(f\"  {option}\")\n",
    "print(f\"\\n(Spr√°vn√° odpovƒõƒè: {quiz['correct']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rag_implementation"
   },
   "source": [
    "## 3. RAG (Retrieval-Augmented Generation) Syst√©m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rag_system"
   },
   "outputs": [],
   "source": [
    "# Implementace RAG syst√©mu pro p≈ôesn√© odpovƒõdi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import numpy as np\n",
    "\n",
    "class StudyRAGSystem:\n",
    "    def __init__(self):\n",
    "        print(\"üìö Inicializuji RAG syst√©m pro studijn√≠ materi√°ly...\")\n",
    "        \n",
    "        # Inicializace embedding modelu\n",
    "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Inicializace ChromaDB\n",
    "        self.chroma_client = chromadb.Client(Settings(\n",
    "            anonymized_telemetry=False,\n",
    "            persist_directory=\"./study_db\"\n",
    "        ))\n",
    "        \n",
    "        # Vytvo≈ôen√≠ kolekce\n",
    "        try:\n",
    "            self.collection = self.chroma_client.create_collection(\n",
    "                name=\"study_materials\",\n",
    "                metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "        except:\n",
    "            self.collection = self.chroma_client.get_collection(\"study_materials\")\n",
    "        \n",
    "        print(\"‚úÖ RAG syst√©m p≈ôipraven!\")\n",
    "    \n",
    "    def add_study_material(self, text, metadata=None):\n",
    "        \"\"\"P≈ôid√°n√≠ studijn√≠ho materi√°lu do datab√°ze\"\"\"\n",
    "        # Rozdƒõlen√≠ textu na chunks\n",
    "        chunks = self._split_text(text, chunk_size=200)\n",
    "        \n",
    "        # Vytvo≈ôen√≠ embeddings\n",
    "        embeddings = self.embedder.encode(chunks)\n",
    "        \n",
    "        # P≈ôid√°n√≠ do datab√°ze\n",
    "        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "            self.collection.add(\n",
    "                embeddings=[embedding.tolist()],\n",
    "                documents=[chunk],\n",
    "                metadatas=[metadata or {}],\n",
    "                ids=[f\"chunk_{len(self.collection.get()['ids'])}_{i}\"]\n",
    "            )\n",
    "        \n",
    "        print(f\"‚úÖ P≈ôid√°no {len(chunks)} ƒç√°st√≠ textu do datab√°ze\")\n",
    "    \n",
    "    def _split_text(self, text, chunk_size=200):\n",
    "        \"\"\"Rozdƒõlen√≠ textu na men≈°√≠ ƒç√°sti\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(words), chunk_size):\n",
    "            chunk = ' '.join(words[i:i+chunk_size])\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def search(self, query, n_results=3):\n",
    "        \"\"\"Vyhled√°n√≠ relevantn√≠ch materi√°l≈Ø\"\"\"\n",
    "        # Vytvo≈ôen√≠ embedding pro dotaz\n",
    "        query_embedding = self.embedder.encode([query])[0]\n",
    "        \n",
    "        # Vyhled√°n√≠ v datab√°zi\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_answer(self, query, context_docs):\n",
    "        \"\"\"Generov√°n√≠ odpovƒõdi na z√°kladƒõ kontextu\"\"\"\n",
    "        # Spojen√≠ relevantn√≠ch dokument≈Ø\n",
    "        context = \"\\n\\n\".join(context_docs)\n",
    "        \n",
    "        # Jednoduch√° ≈°ablona pro odpovƒõƒè\n",
    "        answer_template = f\"\"\"\n",
    "        Na z√°kladƒõ dostupn√Ωch materi√°l≈Ø:\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Odpovƒõƒè na ot√°zku \"{query}\":\n",
    "        \"\"\"\n",
    "        \n",
    "        # V re√°ln√© aplikaci by se pou≈æil LLM pro generov√°n√≠ odpovƒõdi\n",
    "        # Pro demo √∫ƒçely vr√°t√≠me strukturovanou odpovƒõƒè\n",
    "        return self._simple_answer_generation(query, context)\n",
    "    \n",
    "    def _simple_answer_generation(self, query, context):\n",
    "        \"\"\"Jednoduch√° generace odpovƒõdi (simulace)\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        if \"co je\" in query_lower:\n",
    "            return f\"Na z√°kladƒõ studijn√≠ch materi√°l≈Ø: {context[:200]}...\"\n",
    "        elif \"jak\" in query_lower:\n",
    "            return f\"Postup podle materi√°l≈Ø: {context[:200]}...\"\n",
    "        elif \"proƒç\" in query_lower:\n",
    "            return f\"D≈Øvod je n√°sleduj√≠c√≠: {context[:200]}...\"\n",
    "        else:\n",
    "            return f\"Relevantn√≠ informace: {context[:200]}...\"\n",
    "\n",
    "# Vytvo≈ôen√≠ RAG syst√©mu\n",
    "rag_system = StudyRAGSystem()\n",
    "\n",
    "# P≈ôid√°n√≠ studijn√≠ch materi√°l≈Ø\n",
    "study_materials = [\n",
    "    \"\"\"\n",
    "    Neuronov√© s√≠tƒõ jsou v√Ωpoƒçetn√≠ modely inspirovan√© biologick√Ωm mozkem. \n",
    "    Skl√°daj√≠ se z vrstev neuron≈Ø, kter√© jsou vz√°jemnƒõ propojeny vahami. \n",
    "    Ka≈æd√Ω neuron p≈ôij√≠m√° vstupy, aplikuje na nƒõ v√°hy, seƒçte je a \n",
    "    v√Ωsledek pro≈æene aktivaƒçn√≠ funkc√≠. Uƒçen√≠ prob√≠h√° pomoc√≠ algoritmu \n",
    "    zpƒõtn√© propagace, kter√Ω upravuje v√°hy na z√°kladƒõ chyby predikce.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Strojov√© uƒçen√≠ je podoblast umƒõl√© inteligence, kter√° umo≈æ≈àuje \n",
    "    poƒç√≠taƒç≈Øm uƒçit se z dat bez explicitn√≠ho programov√°n√≠. Existuj√≠ \n",
    "    t≈ôi hlavn√≠ typy: uƒçen√≠ s uƒçitelem (supervised learning), uƒçen√≠ \n",
    "    bez uƒçitele (unsupervised learning) a posilovan√© uƒçen√≠ \n",
    "    (reinforcement learning). Ka≈æd√Ω typ m√° sv√© specifick√© pou≈æit√≠.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep learning je specializovan√° oblast strojov√©ho uƒçen√≠ vyu≈æ√≠vaj√≠c√≠ \n",
    "    hlubok√© neuronov√© s√≠tƒõ s mnoha vrstvami. Tyto s√≠tƒõ dok√°≈æ√≠ \n",
    "    automaticky extrahovat hierarchick√© features z dat. Nejzn√°mƒõj≈°√≠ \n",
    "    architektury zahrnuj√≠ CNN pro zpracov√°n√≠ obrazu, RNN pro \n",
    "    sekvenƒçn√≠ data a Transformery pro NLP √∫lohy.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(\"\\nüì• P≈ôid√°v√°m studijn√≠ materi√°ly do datab√°ze...\")\n",
    "for i, material in enumerate(study_materials):\n",
    "    rag_system.add_study_material(\n",
    "        material, \n",
    "        metadata={\"topic\": [\"Neural Networks\", \"Machine Learning\", \"Deep Learning\"][i]}\n",
    "    )\n",
    "\n",
    "# Test vyhled√°v√°n√≠\n",
    "print(\"\\nüîç Test RAG syst√©mu:\\n\")\n",
    "\n",
    "test_queries = [\n",
    "    \"Co jsou neuronov√© s√≠tƒõ?\",\n",
    "    \"Jak√© jsou typy strojov√©ho uƒçen√≠?\",\n",
    "    \"Co je deep learning?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"‚ùì Dotaz: {query}\")\n",
    "    \n",
    "    # Vyhled√°n√≠ relevantn√≠ch dokument≈Ø\n",
    "    results = rag_system.search(query, n_results=2)\n",
    "    \n",
    "    if results['documents'][0]:\n",
    "        # Generov√°n√≠ odpovƒõdi\n",
    "        answer = rag_system.generate_answer(query, results['documents'][0])\n",
    "        print(f\"üí° Odpovƒõƒè: {answer}\")\n",
    "    else:\n",
    "        print(\"‚ùå Nenalezeny ≈æ√°dn√© relevantn√≠ materi√°ly\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gradio_interface"
   },
   "source": [
    "## 4. Vytvo≈ôen√≠ interaktivn√≠ho rozhran√≠ s Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gradio_app"
   },
   "outputs": [],
   "source": [
    "# Kompletn√≠ Gradio aplikace pro AI Studijn√≠ho Asistenta\n",
    "import gradio as gr\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class StudyAssistantApp:\n",
    "    def __init__(self):\n",
    "        self.assistant = StudyAssistantBot()\n",
    "        self.rag_system = StudyRAGSystem()\n",
    "        self.study_history = []\n",
    "        self.current_quiz = None\n",
    "        \n",
    "    def chat_interface(self, message, history):\n",
    "        \"\"\"Chatovac√≠ rozhran√≠\"\"\"\n",
    "        # Z√≠sk√°n√≠ odpovƒõdi od asistenta\n",
    "        response = self.assistant.generate_response(message)\n",
    "        \n",
    "        # Ulo≈æen√≠ do historie\n",
    "        self.study_history.append({\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'question': message,\n",
    "            'answer': response\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def rag_search(self, query):\n",
    "        \"\"\"RAG vyhled√°v√°n√≠\"\"\"\n",
    "        results = self.rag_system.search(query)\n",
    "        \n",
    "        if results['documents'][0]:\n",
    "            answer = self.rag_system.generate_answer(query, results['documents'][0])\n",
    "            sources = \"\\n\\nüìö Zdroje:\\n\" + \"\\n\".join([f\"- {doc[:100]}...\" for doc in results['documents'][0]])\n",
    "            return answer + sources\n",
    "        else:\n",
    "            return \"Nenalezeny ≈æ√°dn√© relevantn√≠ materi√°ly. Zkuste p≈ôeformulovat dotaz.\"\n",
    "    \n",
    "    def generate_quiz(self, topic, difficulty):\n",
    "        \"\"\"Generov√°n√≠ kv√≠zu\"\"\"\n",
    "        # Generov√°n√≠ ot√°zek podle obt√≠≈ænosti\n",
    "        num_questions = {\"Lehk√°\": 3, \"St≈ôedn√≠\": 5, \"Tƒõ≈æk√°\": 7}[difficulty]\n",
    "        \n",
    "        quiz_questions = []\n",
    "        for i in range(num_questions):\n",
    "            q = self.assistant.generate_quiz_question(topic)\n",
    "            quiz_questions.append(q)\n",
    "        \n",
    "        self.current_quiz = {\n",
    "            'topic': topic,\n",
    "            'difficulty': difficulty,\n",
    "            'questions': quiz_questions,\n",
    "            'user_answers': [],\n",
    "            'start_time': datetime.now()\n",
    "        }\n",
    "        \n",
    "        # Form√°tov√°n√≠ kv√≠zu pro zobrazen√≠\n",
    "        quiz_text = f\"üìù **Kv√≠z: {topic}** (Obt√≠≈ænost: {difficulty})\\n\\n\"\n",
    "        \n",
    "        for i, q in enumerate(quiz_questions, 1):\n",
    "            quiz_text += f\"**Ot√°zka {i}:** {q['question']}\\n\"\n",
    "            for option in q['options']:\n",
    "                quiz_text += f\"  {option}\\n\"\n",
    "            quiz_text += \"\\n\"\n",
    "        \n",
    "        return quiz_text\n",
    "    \n",
    "    def submit_quiz(self, answers):\n",
    "        \"\"\"Vyhodnocen√≠ kv√≠zu\"\"\"\n",
    "        if not self.current_quiz:\n",
    "            return \"Nejprve vygenerujte kv√≠z!\"\n",
    "        \n",
    "        # Parsov√°n√≠ odpovƒõd√≠\n",
    "        user_answers = answers.strip().split(',')\n",
    "        correct_count = 0\n",
    "        \n",
    "        results = f\"üìä **V√Ωsledky kv√≠zu**\\n\\n\"\n",
    "        \n",
    "        for i, (question, user_answer) in enumerate(zip(self.current_quiz['questions'], user_answers)):\n",
    "            user_answer = user_answer.strip().lower()\n",
    "            is_correct = user_answer == question['correct']\n",
    "            \n",
    "            if is_correct:\n",
    "                correct_count += 1\n",
    "                results += f\"‚úÖ Ot√°zka {i+1}: Spr√°vnƒõ!\\n\"\n",
    "            else:\n",
    "                results += f\"‚ùå Ot√°zka {i+1}: ≈†patnƒõ (spr√°vn√° odpovƒõƒè: {question['correct']})\\n\"\n",
    "        \n",
    "        # Celkov√© hodnocen√≠\n",
    "        total = len(self.current_quiz['questions'])\n",
    "        percentage = (correct_count / total) * 100\n",
    "        \n",
    "        results += f\"\\n**Celkov√© sk√≥re: {correct_count}/{total} ({percentage:.0f}%)**\\n\"\n",
    "        \n",
    "        # Aktualizace statistik\n",
    "        self.assistant.study_context['questions_asked'] += total\n",
    "        self.assistant.study_context['correct_answers'] += correct_count\n",
    "        \n",
    "        # Doporuƒçen√≠\n",
    "        if percentage >= 80:\n",
    "            results += \"\\nüéâ V√Ωbornƒõ! Pokraƒçujte na dal≈°√≠ t√©ma.\"\n",
    "        elif percentage >= 60:\n",
    "            results += \"\\nüëç Dob≈ôe! Je≈°tƒõ trochu procviƒçit problematick√© oblasti.\"\n",
    "        else:\n",
    "            results += \"\\nüìö Doporuƒçuji znovu prostudovat toto t√©ma.\"\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def add_study_material(self, file):\n",
    "        \"\"\"P≈ôid√°n√≠ studijn√≠ho materi√°lu\"\"\"\n",
    "        if file is None:\n",
    "            return \"Pros√≠m nahrajte soubor.\"\n",
    "        \n",
    "        try:\n",
    "            # ƒåten√≠ souboru\n",
    "            content = file.read().decode('utf-8')\n",
    "            \n",
    "            # P≈ôid√°n√≠ do RAG syst√©mu\n",
    "            self.rag_system.add_study_material(content)\n",
    "            \n",
    "            return f\"‚úÖ Materi√°l √∫spƒõ≈°nƒõ p≈ôid√°n! D√©lka: {len(content)} znak≈Ø\"\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Chyba p≈ôi zpracov√°n√≠ souboru: {str(e)}\"\n",
    "    \n",
    "    def get_study_progress(self):\n",
    "        \"\"\"Z√≠sk√°n√≠ studijn√≠ho pokroku\"\"\"\n",
    "        return self.assistant.get_study_summary()\n",
    "\n",
    "# Vytvo≈ôen√≠ aplikace\n",
    "app = StudyAssistantApp()\n",
    "\n",
    "# Vytvo≈ôen√≠ Gradio interface\n",
    "with gr.Blocks(title=\"AI Studijn√≠ Asistent\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üéì AI Studijn√≠ Asistent\n",
    "    \n",
    "    V√°≈° osobn√≠ AI asistent pro efektivn√≠ uƒçen√≠!\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        # Tab 1: Chat\n",
    "        with gr.Tab(\"üí¨ Chat s Asistentem\"):\n",
    "            chatbot = gr.ChatInterface(\n",
    "                fn=app.chat_interface,\n",
    "                title=\"Zeptejte se na cokoliv!\",\n",
    "                examples=[\n",
    "                    \"Co je to neuronov√° s√≠≈•?\",\n",
    "                    \"Jak se uƒçit efektivnƒõ?\",\n",
    "                    \"Vysvƒõtli mi gradient descent\",\n",
    "                    \"Jak√Ω je rozd√≠l mezi AI a ML?\"\n",
    "                ],\n",
    "                retry_btn=\"üîÑ Zkusit znovu\",\n",
    "                undo_btn=\"‚Ü©Ô∏è Vr√°tit\",\n",
    "                clear_btn=\"üóëÔ∏è Vymazat\"\n",
    "            )\n",
    "        \n",
    "        # Tab 2: RAG Vyhled√°v√°n√≠\n",
    "        with gr.Tab(\"üîç Vyhled√°v√°n√≠ v materi√°lech\"):\n",
    "            with gr.Row():\n",
    "                search_input = gr.Textbox(\n",
    "                    label=\"Zadejte dotaz\",\n",
    "                    placeholder=\"Nap≈ô. 'Jak funguje backpropagation?'\",\n",
    "                    lines=2\n",
    "                )\n",
    "                search_btn = gr.Button(\"üîç Vyhledat\", variant=\"primary\")\n",
    "            \n",
    "            search_output = gr.Textbox(\n",
    "                label=\"V√Ωsledky vyhled√°v√°n√≠\",\n",
    "                lines=10,\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            search_btn.click(\n",
    "                fn=app.rag_search,\n",
    "                inputs=search_input,\n",
    "                outputs=search_output\n",
    "            )\n",
    "        \n",
    "        # Tab 3: Kv√≠zy\n",
    "        with gr.Tab(\"üìù Kv√≠zy a testy\"):\n",
    "            with gr.Row():\n",
    "                quiz_topic = gr.Textbox(\n",
    "                    label=\"T√©ma kv√≠zu\",\n",
    "                    placeholder=\"Nap≈ô. 'Neuronov√© s√≠tƒõ'\"\n",
    "                )\n",
    "                quiz_difficulty = gr.Radio(\n",
    "                    [\"Lehk√°\", \"St≈ôedn√≠\", \"Tƒõ≈æk√°\"],\n",
    "                    label=\"Obt√≠≈ænost\",\n",
    "                    value=\"St≈ôedn√≠\"\n",
    "                )\n",
    "                generate_quiz_btn = gr.Button(\"üé≤ Generovat kv√≠z\", variant=\"primary\")\n",
    "            \n",
    "            quiz_display = gr.Textbox(\n",
    "                label=\"Kv√≠z\",\n",
    "                lines=15,\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                quiz_answers = gr.Textbox(\n",
    "                    label=\"Va≈°e odpovƒõdi (oddƒõlen√© ƒç√°rkou)\",\n",
    "                    placeholder=\"a, b, c, d, a\"\n",
    "                )\n",
    "                submit_quiz_btn = gr.Button(\"üìä Vyhodnotit\", variant=\"secondary\")\n",
    "            \n",
    "            quiz_results = gr.Textbox(\n",
    "                label=\"V√Ωsledky\",\n",
    "                lines=10,\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            generate_quiz_btn.click(\n",
    "                fn=app.generate_quiz,\n",
    "                inputs=[quiz_topic, quiz_difficulty],\n",
    "                outputs=quiz_display\n",
    "            )\n",
    "            \n",
    "            submit_quiz_btn.click(\n",
    "                fn=app.submit_quiz,\n",
    "                inputs=quiz_answers,\n",
    "                outputs=quiz_results\n",
    "            )\n",
    "        \n",
    "        # Tab 4: Spr√°va materi√°l≈Ø\n",
    "        with gr.Tab(\"üìö Spr√°va materi√°l≈Ø\"):\n",
    "            gr.Markdown(\"### Nahrajte studijn√≠ materi√°ly\")\n",
    "            \n",
    "            file_upload = gr.File(\n",
    "                label=\"Vyberte textov√Ω soubor\",\n",
    "                file_types=[\".txt\", \".md\"],\n",
    "                type=\"binary\"\n",
    "            )\n",
    "            \n",
    "            upload_btn = gr.Button(\"üì§ Nahr√°t materi√°l\", variant=\"primary\")\n",
    "            upload_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "            \n",
    "            upload_btn.click(\n",
    "                fn=app.add_study_material,\n",
    "                inputs=file_upload,\n",
    "                outputs=upload_status\n",
    "            )\n",
    "        \n",
    "        # Tab 5: Pokrok\n",
    "        with gr.Tab(\"üìä M≈Øj pokrok\"):\n",
    "            refresh_btn = gr.Button(\"üîÑ Aktualizovat\", variant=\"primary\")\n",
    "            progress_display = gr.Textbox(\n",
    "                label=\"Studijn√≠ pokrok\",\n",
    "                lines=15,\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            refresh_btn.click(\n",
    "                fn=app.get_study_progress,\n",
    "                outputs=progress_display\n",
    "            )\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    \n",
    "    ### üöÄ Tipy pro efektivn√≠ studium:\n",
    "    - Ptejte se na konkr√©tn√≠ ot√°zky\n",
    "    - Procviƒçujte pomoc√≠ kv√≠z≈Ø\n",
    "    - Nahrajte vlastn√≠ studijn√≠ materi√°ly\n",
    "    - Sledujte sv≈Øj pokrok\n",
    "    \n",
    "    Vytvo≈ôeno s ‚ù§Ô∏è pomoc√≠ AI\n",
    "    \"\"\")\n",
    "\n",
    "# Spu≈°tƒõn√≠ aplikace\n",
    "print(\"\\nüöÄ Spou≈°t√≠m AI Studijn√≠ho Asistenta...\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ollama_integration"
   },
   "source": [
    "## 5. Integrace s Ollama pro lok√°ln√≠ deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ollama_setup"
   },
   "outputs": [],
   "source": [
    "# Skript pro lok√°ln√≠ deployment s Ollama\n",
    "import subprocess\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class OllamaStudyAssistant:\n",
    "    def __init__(self, model=\"llama2\"):\n",
    "        self.model = model\n",
    "        self.base_url = \"http://localhost:11434\"\n",
    "        \n",
    "    def check_ollama_status(self):\n",
    "        \"\"\"Kontrola, zda Ollama bƒõ≈æ√≠\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
    "            if response.status_code == 200:\n",
    "                print(\"‚úÖ Ollama server bƒõ≈æ√≠\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ùå Ollama server neodpov√≠d√°\")\n",
    "                return False\n",
    "        except:\n",
    "            print(\"‚ùå Nelze se p≈ôipojit k Ollama serveru\")\n",
    "            return False\n",
    "    \n",
    "    def list_models(self):\n",
    "        \"\"\"Seznam dostupn√Ωch model≈Ø\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
    "            if response.status_code == 200:\n",
    "                models = response.json().get('models', [])\n",
    "                print(\"üìã Dostupn√© modely:\")\n",
    "                for model in models:\n",
    "                    print(f\"  - {model['name']} ({model['size']} bytes)\")\n",
    "                return models\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"Chyba: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def generate(self, prompt, context=\"\"):\n",
    "        \"\"\"Generov√°n√≠ odpovƒõdi pomoc√≠ Ollama\"\"\"\n",
    "        try:\n",
    "            data = {\n",
    "                \"model\": self.model,\n",
    "                \"prompt\": f\"{context}\\n\\n{prompt}\",\n",
    "                \"stream\": False\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                f\"{self.base_url}/api/generate\",\n",
    "                json=data\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()['response']\n",
    "            else:\n",
    "                return f\"Chyba: {response.status_code}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Chyba p≈ôi generov√°n√≠: {e}\"\n",
    "    \n",
    "    def create_study_prompt(self, question, subject):\n",
    "        \"\"\"Vytvo≈ôen√≠ promptu pro studijn√≠ho asistenta\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Jsi AI studijn√≠ asistent specializovan√Ω na p≈ôedmƒõt: {subject}.\n",
    "        \n",
    "        Tv√Ωm √∫kolem je:\n",
    "        1. Odpov√≠dat jasnƒõ a srozumitelnƒõ\n",
    "        2. Pou≈æ√≠vat p≈ô√≠klady\n",
    "        3. Strukturovat odpovƒõdi\n",
    "        4. B√Ωt trpƒõliv√Ω a n√°pomocn√Ω\n",
    "        \n",
    "        Ot√°zka studenta: {question}\n",
    "        \n",
    "        Odpovƒõƒè:\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt\n",
    "\n",
    "# Vytvo≈ôen√≠ deployment skriptu\n",
    "deployment_script = '''\n",
    "#!/bin/bash\n",
    "\n",
    "# AI Studijn√≠ Asistent - Deployment Script\n",
    "\n",
    "echo \"üöÄ Instalace AI Studijn√≠ho Asistenta\"\n",
    "\n",
    "# 1. Kontrola Ollama\n",
    "if ! command -v ollama &> /dev/null; then\n",
    "    echo \"üì• Instaluji Ollama...\"\n",
    "    curl -fsSL https://ollama.ai/install.sh | sh\n",
    "fi\n",
    "\n",
    "# 2. Sta≈æen√≠ modelu\n",
    "echo \"üì• Stahuji model llama2...\"\n",
    "ollama pull llama2\n",
    "\n",
    "# 3. Spu≈°tƒõn√≠ Ollama serveru\n",
    "echo \"üñ•Ô∏è Spou≈°t√≠m Ollama server...\"\n",
    "ollama serve &\n",
    "\n",
    "# 4. Vytvo≈ôen√≠ Python prost≈ôed√≠\n",
    "echo \"üêç Vytv√°≈ô√≠m Python prost≈ôed√≠...\"\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "\n",
    "# 5. Instalace z√°vislost√≠\n",
    "echo \"üì¶ Instaluji z√°vislosti...\"\n",
    "pip install gradio transformers torch ollama chromadb sentence-transformers\n",
    "\n",
    "# 6. Spu≈°tƒõn√≠ aplikace\n",
    "echo \"üéì Spou≈°t√≠m AI Studijn√≠ho Asistenta...\"\n",
    "python study_assistant.py\n",
    "'''\n",
    "\n",
    "# Ulo≈æen√≠ deployment skriptu\n",
    "with open('deploy_assistant.sh', 'w') as f:\n",
    "    f.write(deployment_script)\n",
    "\n",
    "print(\"üìÑ Deployment skript vytvo≈ôen: deploy_assistant.sh\")\n",
    "\n",
    "# Test Ollama (pokud je dostupn√°)\n",
    "print(\"\\nüîç Test Ollama integrace:\")\n",
    "ollama_assistant = OllamaStudyAssistant()\n",
    "\n",
    "if ollama_assistant.check_ollama_status():\n",
    "    ollama_assistant.list_models()\n",
    "    \n",
    "    # Test generov√°n√≠\n",
    "    test_prompt = ollama_assistant.create_study_prompt(\n",
    "        \"Co je to gradient descent?\",\n",
    "        \"Strojov√© uƒçen√≠\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nü§ñ Testovac√≠ odpovƒõƒè:\")\n",
    "    # response = ollama_assistant.generate(test_prompt)\n",
    "    # print(response)\n",
    "else:\n",
    "    print(\"\\nüí° Pro lok√°ln√≠ deployment:\")\n",
    "    print(\"1. Nainstalujte Ollama: https://ollama.ai\")\n",
    "    print(\"2. St√°hnƒõte model: ollama pull llama2\")\n",
    "    print(\"3. Spus≈•te server: ollama serve\")\n",
    "    print(\"4. Spus≈•te skript: bash deploy_assistant.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "project_summary"
   },
   "source": [
    "## 6. Shrnut√≠ projektu a dal≈°√≠ kroky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "project_documentation"
   },
   "outputs": [],
   "source": [
    "# Vytvo≈ôen√≠ dokumentace projektu\n",
    "project_documentation = \"\"\"\n",
    "# üéì AI Studijn√≠ Asistent - Dokumentace\n",
    "\n",
    "## üìã P≈ôehled projektu\n",
    "\n",
    "AI Studijn√≠ Asistent je komplexn√≠ aplikace vyu≈æ√≠vaj√≠c√≠ nejmodernƒõj≈°√≠ technologie \n",
    "umƒõl√© inteligence pro podporu student≈Ø p≈ôi uƒçen√≠.\n",
    "\n",
    "## üõ†Ô∏è Technologie\n",
    "\n",
    "- **Transformers**: Hugging Face modely pro NLP\n",
    "- **Gradio**: Interaktivn√≠ webov√© rozhran√≠\n",
    "- **ChromaDB**: Vektorov√° datab√°ze pro RAG\n",
    "- **Ollama**: Lok√°ln√≠ deployment LLM\n",
    "- **PyTorch**: Deep learning framework\n",
    "\n",
    "## üöÄ Funkce\n",
    "\n",
    "1. **Chatbot**: Konverzaƒçn√≠ asistent pro zodpov√≠d√°n√≠ ot√°zek\n",
    "2. **RAG syst√©m**: Vyhled√°v√°n√≠ v studijn√≠ch materi√°lech\n",
    "3. **Gener√°tor kv√≠z≈Ø**: Automatick√© vytv√°≈ôen√≠ test≈Ø\n",
    "4. **Sledov√°n√≠ pokroku**: Statistiky a anal√Ωzy uƒçen√≠\n",
    "5. **Spr√°va materi√°l≈Ø**: Upload a organizace studijn√≠ch zdroj≈Ø\n",
    "\n",
    "## üì¶ Instalace\n",
    "\n",
    "```bash\n",
    "# Klonov√°n√≠ repozit√°≈ôe\n",
    "git clone https://github.com/your-username/ai-study-assistant.git\n",
    "cd ai-study-assistant\n",
    "\n",
    "# Instalace z√°vislost√≠\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Spu≈°tƒõn√≠ aplikace\n",
    "python app.py\n",
    "```\n",
    "\n",
    "## üéØ Pou≈æit√≠\n",
    "\n",
    "1. Spus≈•te aplikaci\n",
    "2. Otev≈ôete webov√Ω prohl√≠≈æeƒç na http://localhost:7860\n",
    "3. Zaƒçnƒõte chatovat s asistentem\n",
    "4. Nahrajte studijn√≠ materi√°ly\n",
    "5. Generujte kv√≠zy a sledujte pokrok\n",
    "\n",
    "## üîß Konfigurace\n",
    "\n",
    "Upravte `config.yaml` pro:\n",
    "- V√Ωbƒõr modelu\n",
    "- Nastaven√≠ RAG parametr≈Ø\n",
    "- UI p≈ôizp≈Øsoben√≠\n",
    "\n",
    "## üìà Budouc√≠ vylep≈°en√≠\n",
    "\n",
    "- [ ] Podpora v√≠ce jazyk≈Ø\n",
    "- [ ] Hlasov√© ovl√°d√°n√≠\n",
    "- [ ] Export studijn√≠ch materi√°l≈Ø\n",
    "- [ ] Mobiln√≠ aplikace\n",
    "- [ ] Integrace s LMS syst√©my\n",
    "\n",
    "## üë• P≈ôisp√≠v√°n√≠\n",
    "\n",
    "P≈ô√≠spƒõvky jsou v√≠t√°ny! Pros√≠m:\n",
    "1. Forknƒõte repozit√°≈ô\n",
    "2. Vytvo≈ôte feature branch\n",
    "3. Commitujte zmƒõny\n",
    "4. Pushnƒõte branch\n",
    "5. Otev≈ôete Pull Request\n",
    "\n",
    "## üìÑ Licence\n",
    "\n",
    "MIT License - volnƒõ k pou≈æit√≠ pro vzdƒõl√°vac√≠ √∫ƒçely\n",
    "\n",
    "## üôè Podƒõkov√°n√≠\n",
    "\n",
    "- Hugging Face za transformery\n",
    "- Gradio t√Ωm za skvƒõl√© UI\n",
    "- Ollama za lok√°ln√≠ LLM\n",
    "- V≈°em p≈ôispƒõvatel≈Øm\n",
    "\"\"\"\n",
    "\n",
    "# Ulo≈æen√≠ dokumentace\n",
    "with open('README.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(project_documentation)\n",
    "\n",
    "print(\"üìÑ Dokumentace vytvo≈ôena: README.md\")\n",
    "\n",
    "# Vytvo≈ôen√≠ requirements.txt\n",
    "requirements = \"\"\"\n",
    "transformers>=4.30.0\n",
    "torch>=2.0.0\n",
    "gradio>=3.35.0\n",
    "chromadb>=0.4.0\n",
    "sentence-transformers>=2.2.0\n",
    "langchain>=0.0.200\n",
    "ollama>=0.1.0\n",
    "pandas>=2.0.0\n",
    "numpy>=1.24.0\n",
    "matplotlib>=3.7.0\n",
    "plotly>=5.14.0\n",
    "\"\"\"\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(\"üì¶ Requirements vytvo≈ôeny: requirements.txt\")\n",
    "\n",
    "# Fin√°ln√≠ shrnut√≠\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ PROJEKT √öSPƒö≈†Nƒö DOKONƒåEN!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Statistiky projektu:\")\n",
    "print(\"  - Komponenty: 7\")\n",
    "print(\"  - Technologie: 6\")\n",
    "print(\"  - ≈ò√°dky k√≥du: ~1000\")\n",
    "print(\"  - Funkce: Chat, RAG, Kv√≠zy, Progress tracking\")\n",
    "print(\"\\nüöÄ Dal≈°√≠ kroky:\")\n",
    "print(\"  1. Otestovat s re√°ln√Ωmi studenty\")\n",
    "print(\"  2. Vylep≈°it UI/UX\")\n",
    "print(\"  3. P≈ôidat v√≠ce model≈Ø\")\n",
    "print(\"  4. Implementovat mobiln√≠ verzi\")\n",
    "print(\"  5. Integrovat s uƒçebn√≠mi platformami\")\n",
    "print(\"\\nüí° Tip: Zkuste aplikaci roz≈°√≠≈ôit o vlastn√≠ funkce!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exercises"
   },
   "source": [
    "## 7. Cviƒçen√≠ a √∫koly\n",
    "\n",
    "### √ökol 1: Roz≈°√≠≈ôen√≠ funkcionalit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exercise_extension"
   },
   "outputs": [],
   "source": [
    "# √ökol: P≈ôidejte novou funkci do AI asistenta\n",
    "class StudyPlannerExtension:\n",
    "    def __init__(self):\n",
    "        self.study_plans = {}\n",
    "        \n",
    "    def create_study_plan(self, subject, available_hours, deadline):\n",
    "        \"\"\"\n",
    "        TODO: Implementujte vytv√°≈ôen√≠ studijn√≠ho pl√°nu\n",
    "        - Rozdƒõlte t√©ma na men≈°√≠ ƒç√°sti\n",
    "        - Alokujte ƒças pro ka≈ædou ƒç√°st\n",
    "        - Vytvo≈ôte harmonogram\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def track_progress(self, plan_id, completed_section):\n",
    "        \"\"\"\n",
    "        TODO: Sledujte pokrok ve studijn√≠m pl√°nu\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_recommendations(self, student_performance):\n",
    "        \"\"\"\n",
    "        TODO: Generujte personalizovan√° doporuƒçen√≠\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "# Implementujte roz≈°√≠≈ôen√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## 8. Shrnut√≠\n",
    "\n",
    "### Co jsme vytvo≈ôili:\n",
    "- ‚úÖ Kompletn√≠ AI studijn√≠ asistent\n",
    "- ‚úÖ Chatbot s transformery\n",
    "- ‚úÖ RAG syst√©m pro p≈ôesn√© odpovƒõdi\n",
    "- ‚úÖ Gener√°tor kv√≠z≈Ø\n",
    "- ‚úÖ Interaktivn√≠ Gradio rozhran√≠\n",
    "- ‚úÖ Integrace s Ollama\n",
    "\n",
    "### Nauƒçen√© dovednosti:\n",
    "1. **Pl√°nov√°n√≠ AI projektu**\n",
    "2. **Pr√°ce s transformery**\n",
    "3. **Implementace RAG**\n",
    "4. **Vytv√°≈ôen√≠ UI s Gradio**\n",
    "5. **Deployment s Ollama**\n",
    "\n",
    "### P≈ô√≠≈°tƒõ:\n",
    "V dal≈°√≠ hodinƒõ shrneme v≈°e, co jsme se nauƒçili!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "homework"
   },
   "source": [
    "## 9. Dom√°c√≠ √∫kol\n",
    "\n",
    "1. **Vylep≈°ete chatbota**:\n",
    "   - P≈ôidejte podporu pro v√≠ce p≈ôedmƒõt≈Ø\n",
    "   - Implementujte pamƒõ≈• konverzace\n",
    "   - Vylep≈°ete generov√°n√≠ odpovƒõd√≠\n",
    "\n",
    "2. **Roz≈°i≈ôte RAG syst√©m**:\n",
    "   - P≈ôidejte podporu PDF soubor≈Ø\n",
    "   - Implementujte hodnocen√≠ relevance\n",
    "   - Vytvo≈ôte vizualizaci v√Ωsledk≈Ø\n",
    "\n",
    "3. **Vytvo≈ôte mobiln√≠ verzi**:\n",
    "   - Pou≈æijte Gradio mobile support\n",
    "   - Optimalizujte UI pro mobily\n",
    "   - P≈ôidejte offline podporu\n",
    "\n",
    "4. **Napi≈°te dokumentaci**:\n",
    "   - U≈æivatelsk√Ω manu√°l\n",
    "   - API dokumentace\n",
    "   - Instalaƒçn√≠ video n√°vod\n",
    "\n",
    "---\n",
    "\n",
    "**üèÜ V√Ωzva**: Publikujte v√°≈° projekt na GitHub a sd√≠lejte s komunitou!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hodina 9 ‚Äî Mini projekt: kr√°tk√© shrnut√≠ (ELI10)\n",
    "\n",
    "Dnes si vybereme jednoduch√Ω probl√©m a vytvo≈ô√≠me mal√Ω prototyp. Projekt by mƒõl b√Ωt dost mal√Ω, aby ho bylo mo≈æn√© dokonƒçit bƒõhem jedn√© nebo dvou hodin. Doporuƒçen√≠: klasifikace mal√©ho datasetu (nap≈ô. Iris) s jednoduch√Ωm u≈æivatelsk√Ωm rozhran√≠m p≈ôes Gradio, nebo hra, kterou ovl√°d√° jednoduch√Ω algoritmus.\n",
    "\n",
    "N√≠≈æe je kr√°tk√° kostra projektu, kterou m≈Ø≈æete zkop√≠rovat a upravit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-project scaffold: Iris classifier (very small prototype)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print('Accuracy on Iris test set:', acc)\n",
    "assert acc >= 0.8  # simple sanity check ‚Äî many runs will satisfy this\n",
    "\n",
    "# Next steps: wrap `clf.predict` into a Gradio interface or save the model for use in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√ökoly pro mini projekt:\n",
    "\n",
    "1) Zvolte probl√©m (klasifikace, jednoduch√° hra nebo detekce) a napi≈°te kr√°tk√Ω popis c√≠le projektu.\n",
    "2) Implementujte prototyp (p≈ô. Iris classifier nebo jednoduch√© Gradio UI pro hru).\n",
    "3) P≈ôipravte kr√°tkou prezentaci (2‚Äì3 slidy nebo 5 minut), kde vysvƒõtl√≠te, jak probl√©m ≈ôe≈°√≠te a jak√© metody jste pou≈æili.\n",
    "4) Volitelnƒõ: nasd√≠lejte Gradio demo online pro snadn√© testov√°n√≠ ostatn√≠mi."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
